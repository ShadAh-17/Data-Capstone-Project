{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "Reviews.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a516df7d3fda4788abfba0efbae25b49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3c8baf96ba774c00942c4ab863f2643c",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 11,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 11,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fbfc25f21c27424a993dd15da84d7a8c"
          }
        },
        "3c8baf96ba774c00942c4ab863f2643c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fbfc25f21c27424a993dd15da84d7a8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd7b9c93254a4cfc9394d19ccb599b17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_249682b2413540138a5d8c123b47195f",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af9b553079e64805b671b2849841a9ac"
          }
        },
        "249682b2413540138a5d8c123b47195f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af9b553079e64805b671b2849841a9ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Oa-kZwUq168",
        "colab_type": "code",
        "outputId": "96def70f-d5f4-43fe-dae3-5e1c0180cfc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2SA9XB1q15n",
        "colab_type": "code",
        "outputId": "4f0f2dc7-90f3-42e7-b332-6ba39c13e6ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My\\ Drive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmlc4G31q139",
        "colab_type": "code",
        "outputId": "24a60216-d4f9-4422-e77d-b619dfa5a5f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd IIMA/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/IIMA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWom5YhaquSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5osUMRDuCw22",
        "colab_type": "code",
        "outputId": "f97ec215-ed11-46b6-9832-e39d9d76fb70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "250_Companies2.csv              latest_Model_2june.pkl  reviewers_rating_df.csv\n",
            "250_Companies2.csv_chunk0.hdf5  latestreview.csv        \u001b[0m\u001b[01;34mReviews\u001b[0m/\n",
            "combine_summary.csv             LightGBM.pkl            Reviews.csv\n",
            "df5.csv                         loss_han.png            Reviews.ipynb\n",
            "glove.6B.50d.txt                model_han_.hdf5         rev_test_pred_RF_df.csv\n",
            "Harvard_Modified.csv            model_review.pkl\n",
            "Indeed_Project.ipynb            Pickle_Model.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Fvh4s0jC2zD",
        "colab_type": "code",
        "outputId": "a227de6a-fdbf-409d-a181-b203e4f3b8a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df=pd.read_csv('latestreview.csv')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>review</th>\n",
              "      <th>helpful%</th>\n",
              "      <th>helpfulness_range</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog FoodI have bought several of ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it allThis is a confection that...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough MedicineIf you are looking for the secre...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>B000E7L2R4</td>\n",
              "      <td>A1MZYO9TZK0BBI</td>\n",
              "      <td>R. James</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1322006400</td>\n",
              "      <td>Yay BarleyRight now I'm mostly just sprouting ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>B0001PB9FE</td>\n",
              "      <td>A3HDKO7OW0QNK4</td>\n",
              "      <td>Canadian Fan</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1107820800</td>\n",
              "      <td>The Best Hot Sauce in the WorldI don't know if...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id   ProductId  ... helpful% helpfulness_range\n",
              "0   1  B001E4KFG0  ...      1.0               5.0\n",
              "1   3  B000LQOCH0  ...      1.0               5.0\n",
              "2   4  B000UA0QIQ  ...      1.0               5.0\n",
              "3   9  B000E7L2R4  ...      1.0               5.0\n",
              "4  11  B0001PB9FE  ...      1.0               5.0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2fmbSfWquSx",
        "colab_type": "code",
        "outputId": "bec5704b-9499-4562-f5f1-81007096bb24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df=pd.read_csv('Reviews.csv')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  ...                                               Text\n",
              "0   1  ...  I have bought several of the Vitality canned d...\n",
              "1   2  ...  Product arrived labeled as Jumbo Salted Peanut...\n",
              "2   3  ...  This is a confection that has been around a fe...\n",
              "3   4  ...  If you are looking for the secret ingredient i...\n",
              "4   5  ...  Great taffy at a great price.  There was a wid...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHgur3f4quS9",
        "colab_type": "code",
        "outputId": "c3759822-1b00-4b46-fae2-b8c55e6de6be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "df['review']=df['Summary']+df['Text']\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "      <td>Good Quality Dog FoodI have bought several of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "      <td>Not as AdvertisedProduct arrived labeled as Ju...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "      <td>\"Delight\" says it allThis is a confection that...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "      <td>Cough MedicineIf you are looking for the secre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "      <td>Great taffyGreat taffy at a great price.  Ther...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  ...                                             review\n",
              "0   1  ...  Good Quality Dog FoodI have bought several of ...\n",
              "1   2  ...  Not as AdvertisedProduct arrived labeled as Ju...\n",
              "2   3  ...  \"Delight\" says it allThis is a confection that...\n",
              "3   4  ...  Cough MedicineIf you are looking for the secre...\n",
              "4   5  ...  Great taffyGreat taffy at a great price.  Ther...\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xqc8J9iwquTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop(labels=['Summary','Text'],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzxBJp6yquTN",
        "colab_type": "code",
        "outputId": "9fe3c248-f28b-4e0f-e555-4570cbbfc651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id                          int64\n",
              "ProductId                  object\n",
              "UserId                     object\n",
              "ProfileName                object\n",
              "HelpfulnessNumerator        int64\n",
              "HelpfulnessDenominator      int64\n",
              "Score                       int64\n",
              "Time                        int64\n",
              "review                     object\n",
              "helpful%                  float64\n",
              "helpfulness_range         float64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddmeR4VvquTY",
        "colab_type": "code",
        "outputId": "31d3145e-ceb8-4cd9-b7d7-711852c57c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(262477, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L4nFWHpquTg",
        "colab_type": "code",
        "outputId": "821c984f-d063-4da0-dc70-889fa0050fbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.dropna(inplace=True)\n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(262475, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkMdyWJPquTq",
        "colab_type": "code",
        "outputId": "faaf425d-1d49-42d4-b971-06d340d5c264",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id                        0\n",
              "ProductId                 0\n",
              "UserId                    0\n",
              "ProfileName               0\n",
              "HelpfulnessNumerator      0\n",
              "HelpfulnessDenominator    0\n",
              "Score                     0\n",
              "Time                      0\n",
              "review                    0\n",
              "helpful%                  0\n",
              "helpfulness_range         2\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGJKXf_u5Xj8",
        "colab_type": "code",
        "outputId": "d581376a-9a02-49c0-a6f3-b2f290ffe635",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import calendar\n",
        "import string\n",
        "from scipy import sparse\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn import neighbors\n",
        "from sklearn import metrics\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import warnings\n",
        "with warnings.catch_warnings():\n",
        "  warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "from sklearn.model_selection import train_test_split\n",
        "    \n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVeeq9aeVQe6",
        "colab_type": "code",
        "outputId": "bc2c06fc-b7bf-41e9-bcbc-c826004ec4e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(262475, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "956edaobVbd1",
        "colab_type": "code",
        "outputId": "49e22edd-0a46-459d-ef98-6572bb0b6786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>review</th>\n",
              "      <th>helpful%</th>\n",
              "      <th>helpfulness_range</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog FoodI have bought several of ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it allThis is a confection that...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough MedicineIf you are looking for the secre...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>B000E7L2R4</td>\n",
              "      <td>A1MZYO9TZK0BBI</td>\n",
              "      <td>R. James</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1322006400</td>\n",
              "      <td>Yay BarleyRight now I'm mostly just sprouting ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>B0001PB9FE</td>\n",
              "      <td>A3HDKO7OW0QNK4</td>\n",
              "      <td>Canadian Fan</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1107820800</td>\n",
              "      <td>The Best Hot Sauce in the WorldI don't know if...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  Id  ... helpful% helpfulness_range\n",
              "0      0   1  ...      1.0               5.0\n",
              "1      1   3  ...      1.0               5.0\n",
              "2      2   4  ...      1.0               5.0\n",
              "3      3   9  ...      1.0               5.0\n",
              "4      4  11  ...      1.0               5.0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQEjzVaS5Xg1",
        "colab_type": "code",
        "outputId": "9911ea39-3bc5-4e38-d311-442d081c0e8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df = df[~pd.isnull(df['review'])] # Deleting all the lines that has no reviewText\n",
        "df.drop_duplicates(subset=['ProductId','UserId','Time'], inplace=True)\n",
        "df.reset_index(inplace=True)\n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(262475, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXTq-uL95Xdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop(labels=['index'],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "639RArNZ5XaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['helpful%'] = np.where(df['HelpfulnessDenominator'] > 0,df['HelpfulnessNumerator'] / df['HelpfulnessDenominator'], -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLhqtlpl5XW7",
        "colab_type": "code",
        "outputId": "36c46439-6b13-4abd-a6d9-62840bc71838",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Now to segment the values into bins\n",
        "df['helpfulness_range'] = pd.cut(x=df['helpful%'], bins=[-1, 0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
        "                                         labels=['empty', '1', '2', '3', '4', '5'], include_lowest=True)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>review</th>\n",
              "      <th>helpful%</th>\n",
              "      <th>helpfulness_range</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog FoodI have bought several of ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as AdvertisedProduct arrived labeled as Ju...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>empty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it allThis is a confection that...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough MedicineIf you are looking for the secre...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffyGreat taffy at a great price.  Ther...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>empty</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id   ProductId  ... helpful% helpfulness_range\n",
              "0   1  B001E4KFG0  ...      1.0                 5\n",
              "1   2  B00813GRG4  ...     -1.0             empty\n",
              "2   3  B000LQOCH0  ...      1.0                 5\n",
              "3   4  B000UA0QIQ  ...      1.0                 5\n",
              "4   5  B006K2ZZ7K  ...     -1.0             empty\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCSDJLMP5XTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2 = df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2s10NvE5XP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('latestreview.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4Dxc4g65XMk",
        "colab_type": "code",
        "outputId": "4c8fee5e-e652-4085-9fb9-e09f80ae1276",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.drop(df[df['helpfulness_range'] == 'empty'].index, inplace=True)\n",
        "df['helpfulness_range'] = df['helpfulness_range'].map({'1':1,'2':2,'3':3,'4':4,'5':5,'empty':1})\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>review</th>\n",
              "      <th>helpful%</th>\n",
              "      <th>helpfulness_range</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog FoodI have bought several of ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it allThis is a confection that...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough MedicineIf you are looking for the secre...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>B000E7L2R4</td>\n",
              "      <td>A1MZYO9TZK0BBI</td>\n",
              "      <td>R. James</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1322006400</td>\n",
              "      <td>Yay BarleyRight now I'm mostly just sprouting ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>B0001PB9FE</td>\n",
              "      <td>A3HDKO7OW0QNK4</td>\n",
              "      <td>Canadian Fan</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1107820800</td>\n",
              "      <td>The Best Hot Sauce in the WorldI don't know if...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id   ProductId  ... helpful% helpfulness_range\n",
              "0   1  B001E4KFG0  ...      1.0               5.0\n",
              "1   3  B000LQOCH0  ...      1.0               5.0\n",
              "2   4  B000UA0QIQ  ...      1.0               5.0\n",
              "3   9  B000E7L2R4  ...      1.0               5.0\n",
              "4  11  B0001PB9FE  ...      1.0               5.0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLseVLCp5XIA",
        "colab_type": "code",
        "outputId": "d3cebf94-8704-486e-e6bd-9da562639263",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        }
      },
      "source": [
        "#EDA\n",
        "df3 = pd.DataFrame(df.groupby('helpfulness_range')['Score'].mean().reset_index())\n",
        "fig = plt.figure(figsize=(10,7))\n",
        "sns.barplot(x=df3['helpfulness_range'], y=df3['Score']) # there is a connection between high overall score and review score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8681fe5da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMXLStO-5W_z",
        "colab_type": "code",
        "outputId": "93f9baed-c266-4622-e903-9fc6dcdb2b60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "source": [
        "df3 = df.groupby(['Score', 'helpfulness_range']).agg(UserId=('UserId','count'))\n",
        "df3 = df3.unstack()\n",
        "df3.columns = df3.columns.get_level_values(1)\n",
        "fig = plt.figure(figsize=(10,7))\n",
        "sns.heatmap(df3[df3.columns[::-1]].T, cmap = 'coolwarm', linewidths=.5, annot = True, fmt = 'd', cbar_kws={'label': '# reviews'})\n",
        "plt.title('How users helpfulness_range distributed over the user scores')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8j4dr1BY5W4x",
        "colab_type": "code",
        "outputId": "86c36deb-b61e-4d38-86fe-a2ad64a1cb2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# RRP based on Review Text Content\n",
        "# Feature Engineering\n",
        "\n",
        "df['helpfulness_range'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.0    196524\n",
              "3.0     26285\n",
              "4.0     24781\n",
              "2.0     10833\n",
              "1.0      4052\n",
              "Name: helpfulness_range, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3SpuagZ5Wnj",
        "colab_type": "code",
        "outputId": "3986516f-1204-4f56-dc60-1e216c3eb29f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "df['Score'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    163515\n",
              "4     33583\n",
              "1     31539\n",
              "3     18989\n",
              "2     14849\n",
              "Name: Score, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqbGP-ONDcPD",
        "colab_type": "code",
        "outputId": "1a2881a4-106c-48c1-a9cb-fb222eb8bfb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stopwords1 = set(stopwords.words('english'))\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer \n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "\n",
        "import lightgbm as lgbm\n",
        "from lightgbm import LGBMClassifier, LGBMRegressor"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwemoTYmD55V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(df['review'], df['Score'], random_state = 0, test_size=0.3, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiUE9FC5EAjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_vec = TfidfVectorizer(dtype=np.float32, sublinear_tf=True, use_idf=True, smooth_idf=True)\n",
        "X_data_tfidf = tfidf_vec.fit_transform(df['review'])\n",
        "X_train_tfidf = tfidf_vec.transform(X_train)\n",
        "X_test_tfidf = tfidf_vec.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4W30JVTFW0Y",
        "colab_type": "code",
        "outputId": "bd2b9703-b559-4499-c82c-05e4d4d03c3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "clf_LGBM = lgbm.LGBMClassifier(objective='multiclass', verbose=-1, learning_rate=0.5, max_depth=20, num_leaves=50, n_estimators=120, max_bin=2000,)\n",
        "clf_LGBM.fit(X_train_tfidf, Y_train, verbose=-1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
              "               importance_type='split', learning_rate=0.5, max_bin=2000,\n",
              "               max_depth=20, min_child_samples=20, min_child_weight=0.001,\n",
              "               min_split_gain=0.0, n_estimators=120, n_jobs=-1, num_leaves=50,\n",
              "               objective='multiclass', random_state=None, reg_alpha=0.0,\n",
              "               reg_lambda=0.0, silent=True, subsample=1.0,\n",
              "               subsample_for_bin=200000, subsample_freq=0, verbose=-1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkNC-5lZFbRe",
        "colab_type": "code",
        "outputId": "fae7f651-bff3-46e3-e53c-8ad82cbddec9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "predicted_LGBM = clf_LGBM.predict(X_test_tfidf)\n",
        "print(metrics.classification_report(Y_test, predicted_LGBM))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.78      0.79      0.78      9585\n",
            "           2       0.64      0.46      0.54      4455\n",
            "           3       0.66      0.50      0.57      5660\n",
            "           4       0.66      0.43      0.52     10083\n",
            "           5       0.85      0.96      0.90     48960\n",
            "\n",
            "    accuracy                           0.81     78743\n",
            "   macro avg       0.72      0.63      0.66     78743\n",
            "weighted avg       0.79      0.81      0.79     78743\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhTjeitpK56q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "Pkl_Filename = \"LightGBM.pkl\"  \n",
        "\n",
        "with open(Pkl_Filename, 'wb') as file:  \n",
        "    pickle.dump(predicted_LGBM, file)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBfxNZPpDcHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#--main code--#  \n",
        "\n",
        "\n",
        "count_vect = CountVectorizer(ngram_range=(1,2), stop_words=stopwords1)\n",
        "X_train_counts = count_vect.fit_transform(X_train)\n",
        "\n",
        "tfidf_transformer = TfidfTransformer(use_idf=True, smooth_idf=True, norm='l2', sublinear_tf=True)\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "\n",
        "lgbm_train = lgbm.Dataset(X_train_tfidf, Y_train)\n",
        "lgbm_eval = lgbm.Dataset(count_vect.transform(X_test), Y_test, reference=lgbm_train)\n",
        "\n",
        "params = {\n",
        "    'boosting_type':'gbdt',\n",
        "    'objective':'multiclass',\n",
        "    'learning_rate': 0.02,\n",
        "    'num_class': 3,\n",
        "    'early_stopping': 100,\n",
        "    'num_iteration': 2000, \n",
        "    'num_leaves': 31,\n",
        "    'is_enable_sparse': 'true',\n",
        "    'tree_learner': 'data',\n",
        "    'max_depth': 4, \n",
        "    'n_estimators': 50  \n",
        "    }\n",
        "\n",
        "clf_gbm = lgbm.train(params, valid_sets=lgbm_eval)\n",
        "predicted_LGBM = clf_gbm.predict(count_vect.transform(X_test))\n",
        "\n",
        "print(accuracy_score(Y_test, predicted_LGBM))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En4v6_xtDb-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_vec = TfidfVectorizer(dtype=np.float32, sublinear_tf=True, use_idf=True, smooth_idf=True)\n",
        "X_data_tfidf = tfidf_vec.fit_transform(df['contents'])\n",
        "X_train_tfidf = tfidf_vec.transform(X_train)\n",
        "X_test_tfidf = tfidf_vec.transform(X_test)\n",
        "\n",
        "clf_LGBM = lgbm.LGBMClassifier(objective='multiclass', verbose=-1, learning_rate=0.5, max_depth=20, num_leaves=50, n_estimators=120, max_bin=2000,)\n",
        "clf_LGBM.fit(X_train_tfidf, Y_train, verbose=-1)\n",
        "predicted_LGBM = clf_LGBM.predict(X_test_tfidf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-KUClHPDb1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwyLk85lDboi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lReDvE9DbfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhZW9E1BDbXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPVqEWVpDbPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuM0d6HEDbGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb_yc-9UDa_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Nexo2yGDa5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-pjWf1c5Wje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Notice that the data is really skewed, that means consider resampling!\n",
        "\n",
        "# Now to define our text processor\n",
        "\n",
        "def text_process(review):\n",
        "    nopunc = [i for i in review if i not in string.punctuation]\n",
        "    nopunc_text = ''.join(nopunc)\n",
        "    return [i for i in nopunc_text.split() if i.lower() not in stopwords.words('english')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WojJ98Treo82",
        "colab_type": "code",
        "outputId": "d6465f45-1d5d-46c4-8fa7-deb8ec02fb3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGhdIOhe5WfZ",
        "colab_type": "code",
        "outputId": "68078714-a393-4f37-b6bd-d2cca39752ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# RandomForest\n",
        "pipeline = Pipeline([\n",
        "    ('Tf-Idf', TfidfVectorizer(ngram_range=(1,2), analyzer=text_process)),\n",
        "    ('classifier', RandomForestClassifier())])\n",
        "X = df['review']\n",
        "y = df['helpfulness_range']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
        "pipeline.fit(X_train, y_train)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('Tf-Idf',\n",
              "                 TfidfVectorizer(analyzer=<function text_process at 0x7f899a4e7950>,\n",
              "                                 binary=False, decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 2), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 s...\n",
              "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                        class_weight=None, criterion='gini',\n",
              "                                        max_depth=None, max_features='auto',\n",
              "                                        max_leaf_nodes=None, max_samples=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=1, min_samples_split=2,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        n_estimators=100, n_jobs=None,\n",
              "                                        oob_score=False, random_state=None,\n",
              "                                        verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNcj027oeQbh",
        "colab_type": "code",
        "outputId": "efdce6ac-8e1f-4672-a706-db32ec9885c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "pip_pred4 = pipeline.predict(X_test)\n",
        "print(metrics.classification_report(y_test, pip_pred4))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.99      0.38      0.55      2015\n",
            "         2.0       0.98      0.38      0.54      5397\n",
            "         3.0       0.98      0.36      0.52     13091\n",
            "         4.0       0.97      0.32      0.48     12337\n",
            "         5.0       0.82      1.00      0.90     98398\n",
            "\n",
            "    accuracy                           0.84    131238\n",
            "   macro avg       0.95      0.49      0.60    131238\n",
            "weighted avg       0.86      0.84      0.80    131238\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHczpBXMtdEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "Pkl_Filename = \"latest_Model_2june.pkl\"  \n",
        "\n",
        "with open(Pkl_Filename, 'wb') as file:  \n",
        "    pickle.dump(pip_pred4, file)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQ5NpPrUtdBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the Model back from file\n",
        "with open(Pkl_Filename, 'rb') as file:  \n",
        "    Pickled_Model = pickle.load(file)\n",
        "\n",
        "Pickled_Model\n",
        "\n",
        "\n",
        "# Use the Reloaded Model to \n",
        "# Calculate the accuracy score and predict target values\n",
        "\n",
        "# Calculate the Score \n",
        "# score = Pickled_Model.score(x_test, y_test)  \n",
        "# # Print the Score\n",
        "# print(\"Test score: {0:.2f} %\".format(100 * score))  \n",
        "\n",
        "# Predict the Labels using the reloaded Model\n",
        "Ypredict = Pickled_Model.predict(x_test)  \n",
        "\n",
        "Ypredict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSxD5KMptc9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(pipeline, df['review'], df['helpfulness_range'], cv=5)\n",
        "print(scores.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki64v1Aktc6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Export\n",
        "rev_test_pred_RF_df = pd.DataFrame(data={'review_test': X_test,\n",
        "                                         'prediction': pip_pred4})\n",
        "rev_test_pred_RF_df.to_csv('rev_test_pred_RF_df.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwGRIla2tc3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoxiUp4Otcz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#RRP based on User Similarity\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaMMOvCgtcuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviewers_rating_df = df[['UserId', 'ProductId', 'Score', 'helpfulness_range']].copy()\n",
        "reviewers_rating_df['Score'] = reviewers_rating_df['Score'].apply(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyEGssp6NlDe",
        "colab_type": "code",
        "outputId": "3c2e28d6-4984-4e99-8bce-8549d0fe933b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "reviewers_rating_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>Score</th>\n",
              "      <th>helpfulness_range</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>4</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>2</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A1MZYO9TZK0BBI</td>\n",
              "      <td>B000E7L2R4</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A3HDKO7OW0QNK4</td>\n",
              "      <td>B0001PB9FE</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262472</th>\n",
              "      <td>A2TO5R8QLIITEF</td>\n",
              "      <td>B005ZC0RRO</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262473</th>\n",
              "      <td>A2SD7TY3IOX69B</td>\n",
              "      <td>B001EO7N10</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262474</th>\n",
              "      <td>A2E5C8TTAED4CQ</td>\n",
              "      <td>B001EO7N10</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262475</th>\n",
              "      <td>A121AA1GQV751Z</td>\n",
              "      <td>B004I613EE</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262476</th>\n",
              "      <td>A3IBEVCTXKNOH</td>\n",
              "      <td>B004I613EE</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>262477 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                UserId   ProductId  Score  helpfulness_range\n",
              "0       A3SGXH7AUHU8GW  B001E4KFG0      5                5.0\n",
              "1        ABXLMWJIXXAIN  B000LQOCH0      4                5.0\n",
              "2       A395BORC6FGVXV  B000UA0QIQ      2                5.0\n",
              "3       A1MZYO9TZK0BBI  B000E7L2R4      5                5.0\n",
              "4       A3HDKO7OW0QNK4  B0001PB9FE      5                5.0\n",
              "...                ...         ...    ...                ...\n",
              "262472  A2TO5R8QLIITEF  B005ZC0RRO      5                5.0\n",
              "262473  A2SD7TY3IOX69B  B001EO7N10      5                5.0\n",
              "262474  A2E5C8TTAED4CQ  B001EO7N10      5                5.0\n",
              "262475  A121AA1GQV751Z  B004I613EE      5                5.0\n",
              "262476   A3IBEVCTXKNOH  B004I613EE      5                5.0\n",
              "\n",
              "[262477 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXmdfRq0tcqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we need to convert the string names of reviewerID and asin to unique integers before we can generate a matrix\n",
        "\n",
        "temp_df = pd.DataFrame(np.unique(reviewers_rating_df['UserId']), columns=['unique_ID'])\n",
        "temp_df['unique_ProductId'] = pd.Series(np.unique(reviewers_rating_df['ProductId']))\n",
        "temp_df.reset_index(drop=True,inplace=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dN2g0J5otcm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp_df['unique_ID_int'] = range(len(temp_df),len(temp_df)*2)\n",
        "temp_df['unique_ProductId_int'] = range(0,len(temp_df))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyDtjXxmtch0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviewers_rating_df = pd.merge(reviewers_rating_df, temp_df.drop(['unique_ProductId', 'unique_ProductId_int'], axis=1),\n",
        "                               left_on='UserId', right_on='unique_ID')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKFRWN7mIZy-",
        "colab_type": "code",
        "outputId": "4845aa3c-555c-4dc2-d504-f2b984b3c4b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "reviewers_rating_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>Score</th>\n",
              "      <th>helpfulness_range</th>\n",
              "      <th>unique_ID</th>\n",
              "      <th>unique_ID_int</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>236539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>248105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>217355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>B002Y7526Y</td>\n",
              "      <td>2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>217355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>B000U9WZ54</td>\n",
              "      <td>2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>217355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262472</th>\n",
              "      <td>A3M89SF0SSOGBK</td>\n",
              "      <td>B000NY4SAG</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>A3M89SF0SSOGBK</td>\n",
              "      <td>230318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262473</th>\n",
              "      <td>A2TO5R8QLIITEF</td>\n",
              "      <td>B005ZC0RRO</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>A2TO5R8QLIITEF</td>\n",
              "      <td>201880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262474</th>\n",
              "      <td>A2SD7TY3IOX69B</td>\n",
              "      <td>B001EO7N10</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>A2SD7TY3IOX69B</td>\n",
              "      <td>200594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262475</th>\n",
              "      <td>A121AA1GQV751Z</td>\n",
              "      <td>B004I613EE</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>A121AA1GQV751Z</td>\n",
              "      <td>138494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262476</th>\n",
              "      <td>A3IBEVCTXKNOH</td>\n",
              "      <td>B004I613EE</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>A3IBEVCTXKNOH</td>\n",
              "      <td>226467</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>262477 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                UserId   ProductId  ...       unique_ID  unique_ID_int\n",
              "0       A3SGXH7AUHU8GW  B001E4KFG0  ...  A3SGXH7AUHU8GW         236539\n",
              "1        ABXLMWJIXXAIN  B000LQOCH0  ...   ABXLMWJIXXAIN         248105\n",
              "2       A395BORC6FGVXV  B000UA0QIQ  ...  A395BORC6FGVXV         217355\n",
              "3       A395BORC6FGVXV  B002Y7526Y  ...  A395BORC6FGVXV         217355\n",
              "4       A395BORC6FGVXV  B000U9WZ54  ...  A395BORC6FGVXV         217355\n",
              "...                ...         ...  ...             ...            ...\n",
              "262472  A3M89SF0SSOGBK  B000NY4SAG  ...  A3M89SF0SSOGBK         230318\n",
              "262473  A2TO5R8QLIITEF  B005ZC0RRO  ...  A2TO5R8QLIITEF         201880\n",
              "262474  A2SD7TY3IOX69B  B001EO7N10  ...  A2SD7TY3IOX69B         200594\n",
              "262475  A121AA1GQV751Z  B004I613EE  ...  A121AA1GQV751Z         138494\n",
              "262476   A3IBEVCTXKNOH  B004I613EE  ...   A3IBEVCTXKNOH         226467\n",
              "\n",
              "[262477 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP8GSm_tOBpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviewers_rating_df = pd.merge(reviewers_rating_df, temp_df.drop(['unique_ID', 'unique_ID_int'], axis=1),\n",
        "                               left_on='ProductId', right_on='unique_ProductId')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fmm87TYOOOFb",
        "colab_type": "code",
        "outputId": "e347119a-6b35-42b9-af95-f2f19a1f9641",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "reviewers_rating_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>Score</th>\n",
              "      <th>helpfulness_range</th>\n",
              "      <th>unique_ID</th>\n",
              "      <th>unique_ID_int</th>\n",
              "      <th>unique_ProductId</th>\n",
              "      <th>unique_ProductId_int</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>236539</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>20312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>248105</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>11542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>217355</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>14667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>B002Y7526Y</td>\n",
              "      <td>2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>217355</td>\n",
              "      <td>B002Y7526Y</td>\n",
              "      <td>31328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>B000U9WZ54</td>\n",
              "      <td>2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>217355</td>\n",
              "      <td>B000U9WZ54</td>\n",
              "      <td>14651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262472</th>\n",
              "      <td>A1RKKPSXF9QIZF</td>\n",
              "      <td>B000NY4SAG</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>A1RKKPSXF9QIZF</td>\n",
              "      <td>163803</td>\n",
              "      <td>B000NY4SAG</td>\n",
              "      <td>12960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262473</th>\n",
              "      <td>A3M89SF0SSOGBK</td>\n",
              "      <td>B000NY4SAG</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>A3M89SF0SSOGBK</td>\n",
              "      <td>230318</td>\n",
              "      <td>B000NY4SAG</td>\n",
              "      <td>12960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262474</th>\n",
              "      <td>A2TO5R8QLIITEF</td>\n",
              "      <td>B005ZC0RRO</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>A2TO5R8QLIITEF</td>\n",
              "      <td>201880</td>\n",
              "      <td>B005ZC0RRO</td>\n",
              "      <td>44256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262475</th>\n",
              "      <td>A121AA1GQV751Z</td>\n",
              "      <td>B004I613EE</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>A121AA1GQV751Z</td>\n",
              "      <td>138494</td>\n",
              "      <td>B004I613EE</td>\n",
              "      <td>39415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262476</th>\n",
              "      <td>A3IBEVCTXKNOH</td>\n",
              "      <td>B004I613EE</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>A3IBEVCTXKNOH</td>\n",
              "      <td>226467</td>\n",
              "      <td>B004I613EE</td>\n",
              "      <td>39415</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>262477 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                UserId   ProductId  ...  unique_ProductId  unique_ProductId_int\n",
              "0       A3SGXH7AUHU8GW  B001E4KFG0  ...        B001E4KFG0                 20312\n",
              "1        ABXLMWJIXXAIN  B000LQOCH0  ...        B000LQOCH0                 11542\n",
              "2       A395BORC6FGVXV  B000UA0QIQ  ...        B000UA0QIQ                 14667\n",
              "3       A395BORC6FGVXV  B002Y7526Y  ...        B002Y7526Y                 31328\n",
              "4       A395BORC6FGVXV  B000U9WZ54  ...        B000U9WZ54                 14651\n",
              "...                ...         ...  ...               ...                   ...\n",
              "262472  A1RKKPSXF9QIZF  B000NY4SAG  ...        B000NY4SAG                 12960\n",
              "262473  A3M89SF0SSOGBK  B000NY4SAG  ...        B000NY4SAG                 12960\n",
              "262474  A2TO5R8QLIITEF  B005ZC0RRO  ...        B005ZC0RRO                 44256\n",
              "262475  A121AA1GQV751Z  B004I613EE  ...        B004I613EE                 39415\n",
              "262476   A3IBEVCTXKNOH  B004I613EE  ...        B004I613EE                 39415\n",
              "\n",
              "[262477 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWUxxp6IIZti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviewers_rating_df['Score_rating'] = reviewers_rating_df['Score']\n",
        "id_ProductId_helpfulness_df = reviewers_rating_df[['UserId', 'unique_ID_int', 'helpfulness_range']].copy()\n",
        "reviewers_rating_df.drop(['ProductId', 'unique_ProductId', 'UserId', 'unique_ID', 'Score', 'helpfulness_range'], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLNYAdAtIZoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviewers_rating_df.drop_duplicates(subset=['unique_ID_int','unique_ProductId_int'],inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a78BAT0BPTHO",
        "colab_type": "code",
        "outputId": "d3c901c6-6cfe-44ae-e4df-689bf6919b78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "reviewers_rating_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_ID_int</th>\n",
              "      <th>unique_ProductId_int</th>\n",
              "      <th>Score_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>236539</td>\n",
              "      <td>20312</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>248105</td>\n",
              "      <td>11542</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>217355</td>\n",
              "      <td>14667</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>217355</td>\n",
              "      <td>31328</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>217355</td>\n",
              "      <td>14651</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262472</th>\n",
              "      <td>163803</td>\n",
              "      <td>12960</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262473</th>\n",
              "      <td>230318</td>\n",
              "      <td>12960</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262474</th>\n",
              "      <td>201880</td>\n",
              "      <td>44256</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262475</th>\n",
              "      <td>138494</td>\n",
              "      <td>39415</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262476</th>\n",
              "      <td>226467</td>\n",
              "      <td>39415</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>261250 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        unique_ID_int  unique_ProductId_int  Score_rating\n",
              "0              236539                 20312             5\n",
              "1              248105                 11542             4\n",
              "2              217355                 14667             2\n",
              "3              217355                 31328             2\n",
              "4              217355                 14651             2\n",
              "...               ...                   ...           ...\n",
              "262472         163803                 12960             5\n",
              "262473         230318                 12960             5\n",
              "262474         201880                 44256             5\n",
              "262475         138494                 39415             5\n",
              "262476         226467                 39415             5\n",
              "\n",
              "[261250 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg6fVT3tuMkO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviewers_rating_df.to_csv('reviewers_rating_df.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JONrFJJuMgW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviewers_rating_df=pd.read_csv('reviewers_rating_df.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PogT1rVLOSd4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Feature Engineering\n",
        "matrix = reviewers_rating_df.pivot(index='unique_ID_int', columns='unique_ProductId_int', values='Score_rating')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj4PdKKMOSa_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matrix = matrix.fillna(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGymfKz4OSVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user_item_matrix = sparse.csr_matrix(matrix.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZIZ2hvKOSQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D-GgvdpIZkf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9wCn9WEIZgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmAcXdt_IZcT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6XSBWsmVlVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop(labels=['ProfileName','Time','Summary','Text'],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4X43l9yquTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRSTaTG_quT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.multiclass import OneVsRestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7colRNcpquUB",
        "colab_type": "code",
        "outputId": "8b7cee5f-d6d8-4981-e4b0-28cfa8b45ad7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(568427, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ePGRgCpquUH",
        "colab_type": "code",
        "outputId": "b3de6ac0-ff44-45a9-f6c2-e2bf886e4542",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "set(df['Score'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1, 2, 3, 4, 5}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQBr-YjTquUP",
        "colab_type": "code",
        "outputId": "ea4f0287-fc10-4d58-c033-0b4bc808a229",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from collections import Counter\n",
        "Counter(df['Score'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({1: 52268, 2: 29744, 3: 42638, 4: 80655, 5: 363122})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiGchGHbquUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pre-processing\n",
        "import re \n",
        "def clean_str(string):\n",
        "    \"\"\"\n",
        "    Tokenization/string cleaning for dataset\n",
        "    Every dataset is lower cased except\n",
        "    \"\"\"\n",
        "    string = re.sub(r\"\\n\", \"\", string)    \n",
        "    string = re.sub(r\"\\r\", \"\", string) \n",
        "    string = re.sub(r\"[0-9]\", \"digit\", string)\n",
        "    string = re.sub(r\"\\'\", \"\", string)    \n",
        "    string = re.sub(r\"\\\"\", \"\", string)    \n",
        "    return string.strip().lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pEQwYHcquUc",
        "colab_type": "code",
        "outputId": "b708d562-37c1-4e15-834f-d6384be69248",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Id', 'ProductId', 'UserId', 'HelpfulnessNumerator',\n",
              "       'HelpfulnessDenominator', 'Score', 'review'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htIgbHd5quUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = []\n",
        "for i in range(df['review'].shape[0]):\n",
        "    X.append(clean_str(df.iloc[i][6]))\n",
        "y = np.array(df[\"Score\"])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MAaRLXSquUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#feature engineering and model selection\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOqNDlNOquU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pipeline of feature engineering and model\n",
        "model = Pipeline([('vectorizer', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', OneVsRestClassifier(LinearSVC(class_weight=\"balanced\")))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d_nJ92yquU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#paramater selection\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = {'vectorizer__ngram_range': [(1, 1), (1, 2),(2,2)],\n",
        "               'tfidf__use_idf': (True, False)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUuTGVL1quVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gs_clf_svm = GridSearchCV(model, parameters, n_jobs=-1)\n",
        "gs_clf_svm = gs_clf_svm.fit(X, y)\n",
        "print(gs_clf_svm.best_score_)\n",
        "print(gs_clf_svm.best_params_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PjUVQ4YquVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#preparing the final pipeline using the selected parameters\n",
        "model = Pipeline([('vectorizer', CountVectorizer(ngram_range=(1,2))),\n",
        "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
        "    ('clf', OneVsRestClassifier(LinearSVC(class_weight=\"balanced\")))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzEIphGsquVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fit model with training data\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJmVOjntquVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#evaluation on test data\n",
        "pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPlcMzhxquVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.classes_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RyUPRVkquVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "confusion_matrix(pred, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMrBya9mquVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_score(y_test, pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0Qe8aOoquVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save the model\n",
        "from sklearn.externals import joblib\n",
        "joblib.dump(model, 'model_question_topic.pkl', compress=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVox5LqpquV0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeIVk4Pc722i",
        "colab_type": "code",
        "outputId": "cdc420a6-7625-4bc3-e7a8-f62664e7f563",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAYZAs5J73X8",
        "colab_type": "code",
        "outputId": "9061ab9e-12a2-4105-a1ff-347f27d1eefd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dropout\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "from bs4 import BeautifulSoup\n",
        "import plotly.graph_objs as go\n",
        "import cufflinks\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "import plotly.figure_factory as ff\n",
        "InteractiveShell.ast_node_interactivity = 'all'\n",
        "from plotly.offline import iplot\n",
        "cufflinks.go_offline()\n",
        "cufflinks.set_config_file(world_readable=True, theme='pearl')\n",
        "\n",
        "\n",
        "import pickle\n",
        "from collections import defaultdict\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import sys\n",
        "import os\n",
        "os.environ['KERAS_BACKEND']='theano'\n",
        "from keras.preprocessing.text import Tokenizer,text_to_word_sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dense, Input, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout, LSTM, GRU, Bidirectional, TimeDistributed\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer, InputSpec\n",
        "from keras import initializers\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb1lzc-B73Vl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "        text: a string\n",
        "        \n",
        "        return: modified initial string\n",
        "    \"\"\"\n",
        "    text = text.lower() # lowercase text\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
        "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
        "    text = text.replace('x', '')\n",
        "#    text = re.sub(r'\\W+', '', text)\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
        "    return text\n",
        "df['review'] = df['review'].apply(clean_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79M7j8qJ73QP",
        "colab_type": "code",
        "outputId": "b496e1fb-f69c-4a55-c160-5202a463f142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>good quality dog foodi bought several vitality...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>advertisedproduct arrived labeled jumbo salted...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>delight says allthis confection around centuri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>cough medicineif looking secret ingredient rob...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>great taffygreat taffy great price wide assort...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id   ProductId  ... Score                                             review\n",
              "0   1  B001E4KFG0  ...     5  good quality dog foodi bought several vitality...\n",
              "1   2  B00813GRG4  ...     1  advertisedproduct arrived labeled jumbo salted...\n",
              "2   3  B000LQOCH0  ...     4  delight says allthis confection around centuri...\n",
              "3   4  B000UA0QIQ  ...     2  cough medicineif looking secret ingredient rob...\n",
              "4   5  B006K2ZZ7K  ...     5  great taffygreat taffy great price wide assort...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d-ssy2g73K7",
        "colab_type": "code",
        "outputId": "cd8f8c67-29a1-48e6-fc50-dd1432a323e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# The maximum number of words to be used. (most frequent)\n",
        "MAX_NB_WORDS = 50000\n",
        "# Max number of words in each complaint.\n",
        "MAX_SEQUENCE_LENGTH = 250\n",
        "MAX_SENT_LENGTH = 250\n",
        "# This is fixed.\n",
        "EMBEDDING_DIM = 50\n",
        "\n",
        "MAX_SENTS = 200\n",
        "MAX_NB_WORDS = 20000\n",
        "VALIDATION_SPLIT = 0.4\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tokenizer.fit_on_texts(df['review'].values)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "n_words=len(word_index)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 323350 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy0weIJv8ZSe",
        "colab_type": "code",
        "outputId": "18e23f7e-65cd-4e0a-b520-aecb89db24f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "from nltk import tokenize\n",
        "nltk.download('punkt')\n",
        "  \n",
        "max_features = 20000 #how many unique words to use (i.e num rows in embedding vector)\n",
        "maxlen = 1000  # max number of words in a tweet to use\n",
        "\n",
        "list_sentences = df['review'].values\n",
        "\n",
        "# Tokenize\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(list_sentences))\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P21emMmX92tL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_DIM = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXCFUrp58l5H",
        "colab_type": "code",
        "outputId": "1fb938a9-1986-4dc1-848c-cb416d638ca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#TEst2\n",
        "#test\n",
        "embeddings_index = {}\n",
        "f = open('glove.6B.50d.txt',encoding='utf8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Total %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "embedding_layer = Embedding(len(word_index) + 1,\n",
        "                            EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=MAX_SENT_LENGTH,\n",
        "                            trainable=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o7dDfli9eBY",
        "colab_type": "code",
        "outputId": "0f727fbb-0956-4eca-dd0a-557bc73db066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# Option2  (worked)\n",
        "x = tokenizer.texts_to_sequences(df['review'].values)\n",
        "x = pad_sequences(x, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', x.shape)\n",
        "y = pd.get_dummies(df['Score']).values\n",
        "print('Shape of label tensor:', y.shape)\n",
        "from sklearn.model_selection import KFold \n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "kf = RepeatedKFold(n_splits=2, n_repeats=5, random_state=None) \n",
        "\n",
        "for train_index, test_index in kf.split(x):\n",
        "    print(\"Train:\", train_index, \"Validation:\",test_index)\n",
        "    x_train, x_test = x[train_index], x[test_index] \n",
        "    y_train, y_test = y[train_index], y[test_index]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (568427, 250)\n",
            "Shape of label tensor: (568427, 5)\n",
            "Train: [     1      4      5 ... 568422 568423 568425] Validation: [     0      2      3 ... 568416 568424 568426]\n",
            "Train: [     0      2      3 ... 568416 568424 568426] Validation: [     1      4      5 ... 568422 568423 568425]\n",
            "Train: [     0      2      7 ... 568422 568423 568424] Validation: [     1      3      4 ... 568420 568425 568426]\n",
            "Train: [     1      3      4 ... 568420 568425 568426] Validation: [     0      2      7 ... 568422 568423 568424]\n",
            "Train: [     1      2      6 ... 568414 568417 568426] Validation: [     0      3      4 ... 568423 568424 568425]\n",
            "Train: [     0      3      4 ... 568423 568424 568425] Validation: [     1      2      6 ... 568414 568417 568426]\n",
            "Train: [     5      8     10 ... 568424 568425 568426] Validation: [     0      1      2 ... 568417 568420 568422]\n",
            "Train: [     0      1      2 ... 568417 568420 568422] Validation: [     5      8     10 ... 568424 568425 568426]\n",
            "Train: [     1      2      3 ... 568421 568423 568425] Validation: [     0      4      7 ... 568422 568424 568426]\n",
            "Train: [     0      4      7 ... 568422 568424 568426] Validation: [     1      2      3 ... 568421 568423 568425]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyDAZWnF9IIT",
        "colab_type": "code",
        "outputId": "9ccb130b-75f1-4d15-f637-49ea4c815728",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "#rnn\n",
        "sequence_input = Input(shape=(MAX_SENT_LENGTH,), dtype='int32')\n",
        "embedded_sequences = embedding_layer(sequence_input)\n",
        "l_lstm = Bidirectional(LSTM(50))(embedded_sequences)\n",
        "preds = Dense(5, activation='softmax')(l_lstm)\n",
        "model = Model(sequence_input, preds)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])\n",
        "\n",
        "print(\"model fitting - Bidirectional LSTM\")\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model fitting - Bidirectional LSTM\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 250, 50)           16167550  \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 100)               40400     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 505       \n",
            "=================================================================\n",
            "Total params: 16,208,455\n",
            "Trainable params: 16,208,455\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvc9h7099IDR",
        "colab_type": "code",
        "outputId": "e35ae072-76ad-4c83-ffb5-39a8dc80e4f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "cp=ModelCheckpoint('model_han_.hdf5',monitor='val_acc',verbose=2, save_best_only=True)\n",
        "history=model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=2, batch_size=1000, callbacks=[cp] )  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning:\n",
            "\n",
            "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 284214 samples, validate on 284213 samples\n",
            "Epoch 1/2\n",
            "284214/284214 [==============================] - 1344s 5ms/step - loss: 0.9310 - acc: 0.6717 - val_loss: 0.7674 - val_acc: 0.7165\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.71647, saving model to model_han_.hdf5\n",
            "Epoch 2/2\n",
            "284214/284214 [==============================] - 1344s 5ms/step - loss: 0.7119 - acc: 0.7332 - val_loss: 0.6996 - val_acc: 0.7377\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.71647 to 0.73770, saving model to model_han_.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P2TB5w-J7Bc",
        "colab_type": "code",
        "outputId": "24581f15-0ca0-406f-c3e8-15261f45db93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#save the model\n",
        "from sklearn.externals import joblib\n",
        "joblib.dump(model, 'model_review.pkl', compress=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning:\n",
            "\n",
            "sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model_review.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBRg4NHM9IA2",
        "colab_type": "code",
        "outputId": "91b5fc56-579e-4c63-af78-8ba29421a9c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "fig1 = plt.figure()\n",
        "plt.plot(history.history['loss'],'r',linewidth=3.0)\n",
        "plt.plot(history.history['val_loss'],'b',linewidth=3.0)\n",
        "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.title('Loss Curves: LSTM',fontsize=16)\n",
        "fig1.savefig('loss_han.png')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f06784a1668>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f0682228438>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f06784a1d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epochs ')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Loss Curves: LSTM')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEdCAYAAADwwTuSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deZyNdfvA8c9lxsyQ3ShblsiebFF6QpKkUqEnKZFElhYVZXlK0uYpLU9kKyIq6elJm6Jo+SWhQdmFylL2LYxmXL8/vveZc84snFnPLNf79TqvmfO973Of7z3DXOf+Xvf1/YqqYowxxoSiULg7YIwxJu+woGGMMSZkFjSMMcaEzIKGMcaYkFnQMMYYEzILGsYYY0JmQcNkORHpJSIqIjXD3ZfTEZFLRGSOiOwUkZMisk9EFohITxGJCHf/spuIVPN+T33OsF9rEZnv/ZxOiMh27/mt3vbF3nHO9KgmIm0CnrdPo0+nQumXCQ8LGqZAEpH7gf8DygAPA+2A3sBG4FXg2vD1LvcQkRuARcAJYBDQARgB7AU6ersNAC4JeHwC7EnWdgmwK+DQR4Aeqbzl7cDRrD4Pk3Uiw90BY3KaiLQCxgGvqOq9yTZ/ICLjgLOy4H0KAwmatytoHwDigBuTnccbIlIIQFXXBr5ARPYAJ1X1++QHExHft/8FuorIWar6V8AuPYD3gF5ZdgYmS9mVhgkLESksImNEZJs3NLTNe144YJ9IEXlCRH7xhkX2isi3IvKPgH26i0iciBwVkcMi8pOI9DvD2z8M7AeGprZRVX9R1dXe8UeJSIo/+iIyXUS2BTz3DfUMEJGxIrITiAeaee2dUjnGBBHZk+yc+4rIqoDzfU1EyiR73X0isk5EjovIARFZLiI3nuGcM6oMsDu1wKeqpzJx3P8CCnT2NYhIS6AGMDMTxzXZzIKGCZc3gEeAGbihoOm4P+ZvBOzzMDAYeBm4CrgD+AL3hwwveLwJfAXcAHQFpgCl0npTL1dxOfC5qp7IyhPyjABqAX2BG4GfgQ3Abcn6EQXcDLytqn97bc8A44GFQCdgCG446FNfjsXLIzwPvIUbHroVmIv3M/H28eWU2mTB+fwAtPcCekMJuFTIpGO4K4rAIarbcUOGW7LoPUw2sOEpk+NEpAFwC/C4qo7ymj8XkQTgCRF5xvukfwnuj/tLAS//MOD7i4GDqnp/QNvnZ3j7WKAI8GtmzuE0/iTZUI6IzARGikhJVT3kNXfE/aGf6e1TDRckHlfV0QGv3Qh8C1wH/A/3M1kduA8uhxDoFJCI+ySfWY8ANXHBcARwWEQWAbNVdU4mjz0DWCAiFYF9wD9xHxRMLmZXGiYcWnlf30zW7nve2vu6DOgoIk+KyD+8T+eBlgGlReRNEblWRNK8wshB/0tlKOdNIBq4KaCtB7BBVX/wnl+J+/84yxuWixSRSGApLmns+5ktAxqJyH9EpJ2IFE3eAVWdoaqRqvpVZk9GVXeraiugOfAo8A3upoF3RGRKJg+/CNiBu1q6DhfMMxuITDazoGHCwTeUsitZ+x/Jtj8FPIYbqvkG2Cci00QkFsD7o3gTcC7wPrBHRBaKSMPTvPc+4DhQNdNnkbrk54Sq/gp8jTcU4wW3awgeuz/b+7oZ+DvZozhQ1ts+A+gPtAA+A/aLyH+9K5Vso6rLVPUJVb0WqIwbJuzjXTVm9JiKC6g9gJ7AvIArMZNLWdAw4bDf+1o+WXv5wO2q+reqPquqFwAVcPmNLrhxf7x95qpqa6A0LodQAZjvu7MnOVVNABYDV4pIdAh9PQFJOYhAZVPZF9IeEpoJXCYiVXHDMFEEX2nt8762By5K5THK67+q6iRVbY4bauuJuwp4J4RzyRKqehCXZwKol8nDzQAuwA3XzcjksUwOsKBhwuFr72u3ZO23el8XJ3+Bqv6hqlNxSeIUn25V9aiqfgRMwgWOtP6oAzzjbR+b2kYRqR5wteLLfTQI2F4KaHma46fmXdzdVLfiPll/412B+CzA5SKqqOryVB5bkx9QVQ+o6ju4IZ0Mf+I/HRGpkMamOt7XFFdW6aGq63EfAubirpxMLmeJcJOdOojIH8naDqnqAhF5Cxjljdt/h0vw/gt4S1V/AhCRD4BVwI/AAaAx7m6iSd720cA5uLHxnbhhk3uBlaq6J61OqerXIvIAME5E6uHu3PoNd7VyBdAH6A6sBj4FDgFTROQxXG5iKOksQFPVw975DMQFtbuSbf9FRJ4FXhGR2rg7wk7ght6uBKaq6iIRmYzLcSwBduPu1OpBwA0AInI78DpwRYh5jaYicjCV9nm4q7bfve834PIOrXH1G0twdztliqoOyuwxTA5SVXvYI0sfuMIsTePxs7dPFDAG90n+b+/rGKBwwHEeBL7Hn4fYgBumKextvwb36XQX7lP878BrQMUQ+9kSdwWwy+vDftwf39uAQgH7/QOXgD6Gqxi/DRdotgXsU807vz6neb9rvH2OAyXT2KeHd85/4QLTOuAVoLK3vSfuSmy3d85bgReAEqn8/Nuc4fx9fU7rEYu7LXgO8It3/seBtbh8U/E0jjsd2J7GtjbesduF0K80f5b2CN9DvF+SMcYYc0aW0zDGGBMyCxrGGGNCZkHDGGNMyCxoGGOMCVm+vuU2NjZWq1WrFu5uGGNMnrJixYq9qloutW35OmhUq1aN5cuXh7sbxhiTp4hImhN62vCUMcaYkFnQMMYYEzILGsYYY0JmQcMYY0zILGgYY4wJmQUNY4wxIbOgkZo//4T+/WFPmrNrG2NMgZSv6zQy7MEHYdYseOcdGDsWeveGQhZf85r4+Hj279/PkSNHSExMDHd3jAmrqKgoYmNjKVmyZKaOY0EjuZ9+cgED4MABuOsueP11mDgRGp5u6WmTm8THx/Pbb79RunRpqlWrRuHChRGRcHfLmLBQVY4fP8727duJjo4mJiYmw8eyj8/JXXABfPwxVK/ub1uyBJo0gYcegqPpWrDNhMn+/fspXbo0sbGxREVFWcAwBZqIULRoUWJjY9mTyWF3Cxqp6dgRfv4ZRoyAwoVdW2IiPP881K0L778PtnhVrnbkyBFKlCgR7m4Yk6sUL16cEydOZOoYFjTSUrQojBkDq1dDmzb+9u3boXNnuO462Lo1bN0zp5eYmEhhX8A3xgAQGRlJQkJCpo5hQeNM6tSBL7+EmTOhXMCkjx9/DPXrw9NPw8mT4eufSZMNSRkTLCv+T1jQCIUI3HYbbNgAd9/tngMcPw7Dh0OjRvDVV+HtozHG5AALGulRujS8+qpLjDdq5G9ft84NYfXsCbt3h617xhiT3SxoZESLFrBsGbz4IhQr5m+fMcMNZ02eDKdOha9/xmSTbdu2ISKMGjUqw8fo1atXrhg6FBF69eoV7m7kORY0MioyEu67D9avh5tu8rcfOAD9+sE//gGrVoWvf6ZAEJGQH9u2bQt3d00+YMV9mVWpEsyZA/Pnw8CBsGWLa1+yBJo2hXvvhccfh+LFw9tPky/NnDkz6Pk333zD5MmT6du3L5dddlnQtnLlUl29M12qVq3K8ePHiYzM+J+OKVOmMHHixEz3xYSHBY2s0qGDq+14+ml45hn4+29X2/HCCy6ovPSSu1U3F1yWm/zjtttuC3qekJDA5MmTueSSS1JsS+7IkSMUT+eHGRHJVDUxQOHChe126DzMhqeyUpEiMHq0m4qkbVt/+44d0LUrXHut/0rEmBxUrVo12rRpQ1xcHFdddRUlS5akoTctzpEjRxg5ciQtWrQgNjaW6OhoatasySOPPMKxY8eCjpNaTiOw7aOPPuKiiy4iJiaGChUqMGTIkBR1AanlNHxthw4don///px99tnExMRw6aWXsnTp0hTns2/fPnr37k3ZsmUpVqwYbdu2JS4ujjZt2lCtWrVM/aymTp1KkyZNKFKkCCVLlqR9+/Z8++23Kfb7+OOPad26NbGxsRQpUoQqVarQuXNnNm7cmLTP77//Tu/evalatSrR0dGcffbZtGzZkjfeeCNTfQwnu9LIDrVrw8KFMHs2PPCA/46qTz5xNR8jR7opSaKjw9tPU6D89ttvtG3blptuuokuXbpw1JsSZ8eOHUydOpUuXbrQvXt3IiMj+eqrrxg7dixxcXF89tlnIR3/k08+YcKECdx999307t2bDz74gOeee47SpUszfPjwkI5x1VVXUa5cOR599FH27dvHuHHjuOaaa9i6dWvSVVF8fDzt2rVj5cqV9OrVi+bNm7N69WratWtHmTJlMvbD8Tz88MOMHTuW5s2b89RTT3HkyBEmT57M5ZdfzgcffEDHjh0B+Oqrr+jUqRMNGjRg2LBhlCpVip07d7Jw4UI2b95MrVq1SEhI4Morr2THjh0MGDCAWrVqcejQIVavXs0333xDz549M9XXsFHVfPto2rSpht3+/ar9+6uKqLrJR9yjTh3VRYvC3bt8a+3atalvCPwd5LZHFpg2bZoCOm3atKD2qlWrKqBTpkxJ8Zr4+Hg9efJkivaRI0cqoEuXLk1q27p1qwL62GOPpWgrWrSobt26Nan91KlTWr9+fS1fvnzQcXv27KkkO19fW//+/YPa58yZo4BOnDgxqW38+PEK6JgxY4L29bVXrVo1xbmkBtCePXsmPV+/fr2KiF566aUaHx+f1L5jxw4tWbKkVq1aVRMSElRVdfDgwQron3/+mebxV61apYA+++yzIfUnp6T5fyMAsFzT+Ltqw1PZrXRpmDABvv8eGjf2t69fD5dfDrffbrUdJkeUKVOGO+64I0V7VFRUUo4hISGBAwcOsHfvXtq1aweQ6vBQam644YagoSER4fLLL+ePP/5Iuqo5k8GDBwc9b+sN827atCmp7cMPPyQiIoL77rsvaN8+ffpkatrvDz74AFVl6NChREVFJbVXrFiRO+64g19//ZW4uDiApPd577330pyWw7fPokWL2J2P/o9b0MgpzZvDDz+4hHhg8nHmTDecNWmS1XaYbFWjRg0iIiJS3TZhwgQaNmxIdHQ0ZcqUoVy5crTx5lw7cOBASMc/77zzUrSVLVsWcDmIjBwjtddv3bqVihUrUiywRgoX/KoHzk6dTlu9ueTq16+fYpuvbYuXkxw0aBCNGzdmwIABlClTho4dO/Lyyy8HzSBbtWpVRowYweeff06FChVo2rQpQ4cOZdmyZRnuY25gQSMnRUa6W3DXr4d//tPffvCgm56kZUtYuTJ8/SsIwj8IlfYjmxUtWjTV9nHjxjFw4EAqVKjApEmT+Pjjj1mwYAHTp08H4FSIH2bSCkjghsEzc4xQX59TypYty7Jly1i0aBH33HMPR44cYfDgwdSqVYslS5Yk7TdmzBg2bdrEiy++SI0aNZg6dSrNmzfn4YcfDmPvM8eCRjhUrOhWBfzsM6hRw9++dKmr7Rg8GI4cCV//TIEyc+ZMqlWrxqeffkqfPn3o2LEj7dq145xzzgl311JVrVo1du7cmWLI6++//066WsgI31XOmjVrUmxbu3Zt0D7gAlybNm148skn+eabb4iLi+Po0aOMGTMmxXHvuece5syZw86dO2nVqhVjx47Ns0NWFjTCqX17d3vuo4+Cbwz11Ck3PUmdOjB3rq3bYbJdREQEIhL0aT4hIYFnnnkmjL1K23XXXUdiYiIvvfRSUPuUKVM4dOhQho/bqVMnRIR///vf/P3330ntu3btYtq0aVStWpXGXl5y7969KV5fp04dihQpwv79+wE4dOhQ0HEAYmJiqFu3LhD6sF9uY7fchluRIq5i/NZbYcAA+OIL175zp5uepEMHeOWV4CsSY7JQ165dGTZsGFdffTWdO3fm8OHDzJ49O9cW4PXp04dJkyYxcuRINm/enHTL7Zw5c6hZs2aG14uoXbs2Q4YMYezYsbRq1Yqbb7456Zbbo0ePMmvWrKThs7vuuovt27fTvn37pCr5d955hyNHjnD77bcDLgHet29funTpQu3atSlWrBgrVqxg6tSptGjRgtq1a2fZzyQnWdDILWrVggUL4K23XG3Hn3+69vnzoUEDt4rgkCFW22Gy3JAhQ1BVXnvtNe677z7Kly/PzTffzB133EG9evXC3b0UoqOj+eKLLxgyZAgffPABc+bMoUWLFnzxxRf06dMnRUFiejz77LPUrFmTCRMm8MgjjxAVFUWLFi2YPXt20LQsPXr0YPr06bzxxhvs2bOHEiVKUK9ePebOnUuXLl0AuPDCC+ncuTOLFy9m1qxZJCYmUqVKFYYPH86DDz6Y6Z9DuEhuSzBlpWbNmuny5cvD3Y30O3jQFQBOmBA8PFW7tpua/fLLw9e3PGLdunVJwwCmYEhMTCQ2NpYWLVowf/78cHcn1wrl/4aIrFDVZqlts5xGblSqlBuSWroUmjTxt2/Y4KYnue02/5WIMQXQ8ePHU7RNnDiRgwcPcuWVV4ahRwWHDU/lZhdd5Go7Jkxww1O+O6pmzYKPPnKTI/btC6e51dGY/Oiuu+7ixIkTtGzZkujoaJYsWcLs2bOpWbMmffv2DXf38rUcv9IQkQ4iskFENovII6lsryoiX4jIahFZLCKVA7b1FJFN3iOPTtySThERcM89rrbj5pv97YcOucR5y5bgVakaU1C0b9+e33//nSeeeIL777+fxYsX06dPH7799tt0z9xr0idHcxoiEgFsBK4EtgPLgFtUdW3APu8CH6nqGyLSFrhDVXuISBlgOdAMUGAF0FRV07xvLc/mNE5nwQIXLDZv9rcVKgSDBsETT0CJEuHrWy5iOQ1jUpfXchrNgc2qukVVTwJvA9cn26ce8KX3/aKA7VcBC1R1vxcoFgAdcqDPucuVV7rajsceC67tePllV9sxZ47Vdhhjsk1OB41KwO8Bz7d7bYFWAZ29728EiotI2RBfi4j0FZHlIrI8cB6YfCUmBkaNcsHDm1QOgF273BDW1VfDL7+ErXvGmPwrN9499RDQWkTigNbADiAx1Ber6mRVbaaqzbJiectcrVYt+PxzV9tRvry//bPPoH59N1wVHx++/hlj8p2cDho7gHMDnlf22pKo6k5V7ayqjYERXtvBUF5bIIlAt24uUT5okH852fh4Nz1Jw4b+KnNjjMmknA4ay4DzRaS6iEQB3YB5gTuISKyI+Po1DHjd+/4zoL2IlBaR0kB7r80AlCwJ//mPu0W3aVN/+8aNbgjr1lvhjz/C1z9jTL6Qo0FDVROAQbg/9uuAOaq6RkRGi0gnb7c2wAYR2QicAzzpvXY/8AQu8CwDRnttJlCzZq4o8JVXgu+kmj3bJconTIDEkEf7jDEmiE0jkp/t2gUPPuhyHoEuuggmTgyuNs9n7JZbY1KX1265NTmpQgV3hbFgAZx/vr992TIXOO691xUJGmNMiCxoFATt2sHq1W4Kdt8suadOuRxI3bpuQah8fMVpMmbbtm2ICKNGjQpqFxF69eoV0jFGjRqFiLBt27Ys79/06dMRERYvXpzlxzZps6BRUMTEuLupfv7ZLf7ks2uXu/uqQ4fgKnOTJ9x0002ICCtPs0ywqlK9enVKlSqV6kR/udnixYsZNWoUBw8eDHdXUuULrIMGDQp3V3KMBY2CpmZNt0bH22+74Sufzz9363Y8/jicOBG+/pl0ufPOOwGYNm1amvssWrSIbdu20a1bN4oUKZLp9zx+/DhTpkzJ9HFCsXjxYh5//PFUg0aPHj04fvw4rVq1ypG+GMeCRkEk4irH161zkyEW8v4ZxMe7SvOGDWHhwrB20YSmffv2nHvuucyaNYuTJ0+muo8voPgCTGbFxMTkilX9IiIiiImJoVAh+zOWk+ynXZCVLOnmrPrhB5cY99m0yc1x1b271XbkcoUKFaJXr17s27ePefPmpdh++PBh3nvvPRo0aMBFF13EkSNHGDlyJC1atCA2Npbo6Ghq1qzJI488EvKKd6nlNE6dOsXTTz9N9erViYmJoUGDBsyaNSvV169fv54BAwZQv359ihcvTtGiRWnatClTp04N2q9Xr148/vjjAFSvXh0RCcqxpJXT2Lt3LwMHDuTcc88lKiqKc889l4EDB7Jv376g/Xyv//LLL3nuueeoUaMG0dHR1KpVizfeeCOkn0V6rF69mhtvvJGyZcsSExNDvXr1GDt2LInJboH//fff6d27N1WrViU6Opqzzz6bli1bBvXp1KlTvPjiizRs2JDixYtTokQJateuzZ133pliXfKsZutpGFcMuGQJTJoEw4f776h66y34+GN46im4+25btyOXuuOOOxgzZgzTpk2ja9euQdvefvttjh8/nnSVsWPHDqZOnUqXLl3o3r07kZGRfPXVV4wdO5a4uDg++yxj9bIPPPAAL730Eq1atWLw4MHs3r2bgQMHct5556XYd/HixXz99ddce+21VK9enb/++ot3332Xu+66iz179jBs2DAA+vXrx+HDh3n//fd54YUXiI2NBaBhw4Zp9uPQoUO0bNmSzZs307t3b5o0aUJcXByvvvoqX375JT/88EOKqdOHDx/O8ePH6devH9HR0bz66qv06tWLmjVrcumll2bo55Hc8uXLad26NYULF2bgwIGUL1+eDz/8kIcffphVq1YlBdiEhASuvPJKduzYwYABA6hVqxaHDh1i9erVfPPNN/Ts6VaEePLJJ3n00Ue57rrruPvuu4mIiGDr1q3MmzeP+Pj47L0SVNV8+2jatKmadNq1S7V7d1V3P5X/0ayZ6rJl4e5dyNauXZtqe/LTyk2PzGjbtq1GRETozp07g9ovvvhijYqK0j179qiqanx8vJ48eTLF60eOHKmALl26NKlt69atCuhjjz2W7GeI9uzZM+n5+vXrVUS0bdu2mpCQkNS+YsUKFREFdOvWrUntR48eTfH+iYmJ2rp1ay1RokRQ/x577LEUr/eZNm2aArpo0aKktuHDhyug48ePD9r3lVdeUUBHjhyZ4vWNGjXS+Pj4pPbt27drVFSUduvWLcV7Juf7GQ0cOPC0+7Vs2VIjIiJ01apVSW2nTp3Sm266SQFduHChqqquWrVKAX322WdPe7zGjRtr3bp1z9i/1KT1fyMQsFzT+Ltqw1MmWPnybmXAhQvdhIg+y5dD8+YuB2K1HbnOnXfeSWJiIjNmzEhqW79+Pd9//z2dOnVK+pQeFRWV9Ck0ISGBAwcOsHfvXtp5syUvXbo03e/9wQcfoKo88MADRARcjTZp0iTVpVfPOuuspO9PnDjBvn372L9/P+3bt+fw4cOsX78+3X3wef/99ylXrlyK1fv69etHuXLleP/991O8ZsCAAUT5lhkAKlWqRK1atdi0aVOG+xFo9+7dfPfdd3Tq1CnoKklEGDFiRFK/AUqWLAm4mxd2796d5jFLlizJjh07+Pbbb7Okj+lhQcOk7oorXG3H6NH+2g5VNz1JnTru7iur7cg1OnfuTKlSpYLuonr9dTdtW+/evYP2nTBhAg0bNiQ6OpoyZcpQrlw52rRpA8CBA2muaZamLVu2AFCnTp0U2+rVq5ei7ejRozz00ENUqVKFIkWKEBsbS7ly5ZL+gGakDz5bt26ldu3aREYGj7xHRkZSq1atpL4GSm0IrWzZsilyIJnpE0D9+vVTbKtbty6FChVK6lfVqlUZMWIEn3/+ORUqVKBp06YMHTqUZcuWBb3uqaeeIiYmhssuu4xKlSpx6623Mnv27DRvhshKFjRM2qKj4V//crUdV13lb//jD7jlFlfvkUWfxnJK+Aeh0n5kRkxMDN27d2fDhg189913JCYmMnPmTCpXrsxVAb+7cePGMXDgQCpUqMCkSZP4+OOPWbBgAdOnTwdcgjW7de/enXHjxtGxY0dmzZrF/PnzWbBgAYMHD86xPgSKSCNXp2H6UDRmzBg2bdrEiy++SI0aNZg6dSrNmzfn4YcfTtrnkksu4ZdffmHu3LnceOONrFy5kltvvZVGjRqxf3/2TslnQcOcWc2a8OmnblXAwNqOhQtdbceoUVbbkQsE1mx8+umn/PHHH/Ts2TPoltSZM2dSrVo1Pv30U/r06UPHjh1p164d55xzTobf1/dJPbVhpbVr1wY9P3jwIB999BE9evRg4sSJdO/enauuuop27doFDRH5iG+q/3T0ZcOGDSQkJAS1JyQksHHjxlSvKrJb9erVAVizZk2KbevXr+fUqVMp+nXeeedxzz33MGfOHHbu3EmrVq0YO3Zs0JBVsWLF6NKlC6+88gpr1qxh/PjxrFu3jtdeey1bz8eChgmNCNx0k1u34777/LUdJ0+6gsALLnAFgiZsmjRpQqNGjXjnnXcYP348IpJiaCoiIgIRCfoUnZCQwDPPPJPh9+3UqRMiwrhx44JuH/3xxx9ZmKzex/epPvmn+F27dqW45RbcH0Yg5E/PN9xwA3v27ElxrClTprBnzx5uvPHGkI6TlXy3zH744Yf8/PPPSe2qytNPPw2Q1K9Dhw6luGU2JiYmaYJB39Dd3r17U7xPE28C0uy+0rBbbk36lCgBL74IPXu623B/+MG1b97shrC6dYNx44KvSEyOufPOO7nnnnuYP38+bdq0SfEJtmvXrgwbNoyrr76azp07c/jwYWbPnp2pWzTr1KnDwIEDeeWVV2jbti1dunRh9+7dvPLKK1x44YXExcUl7Vu8eHHat2/Pm2++SZEiRbjooov49ddfmTRpEtWrV0+RR7j44osBePjhh7n11luTakAaNGiQal+GDh3Ku+++y8CBA/nxxx9p3LgxcXFxvPbaa9SuXZuhQ4dm+DxPZ/ny5YwZMyZFe2RkJI888ggvvfQSrVu35rLLLku65fajjz7is88+o3v37lxxxRWAS4D37duXLl26ULt2bYoVK8aKFSuYOnUqLVq0oHbt2oDLhVx88cW0aNGCihUrsmvXLiZPnkxUVBTdunXLlnNMktZtVfnhYbfcZrOEBNVXX1UtWTJ4eL5ECdWXX3bbwySU2wrzo/3792tMTIwCOmPGjBTbExIS9KmnntIaNWpoVFSUVqlSRYcMGaJr165NcXttqLfcqrpbZseMGaNVqlTRqKgorV+/vr755pup3jK7Z88evfPOO7VChQoaHR2tDRo00MmTJ6d6C62q6rPPPqvVq1fXyMjIoP6ktf/u3bu1f//+WqlSJY2MjNRKlSrpgAEDkuDXlyAAACAASURBVG479knr9aqqrVu31qpVq6byEw7m+xml9YiOjk7ad+XKlXr99ddr6dKlNSoqSuvUqaPPPvts0G3KW7Zs0X79+mmdOnW0ePHiWrRoUa1Tp47+61//0oMHDybt9/TTT+tll12m5cqV06ioKK1cubJ27dpVV6xYccY+Z/aWW1tPw2Ten3/CQw/Bm28Gtzdt6tbtaJbqtPzZytbTMCZ1tp6GCb9zzoGZM91a5N7lMwArVrjajkGDIJfOUmqMSR8LGibrtG0Lq1bBmDFuKnZwA1bjx7vajrfestoOY/I4Cxoma0VHw4gRrrajQwd/+59/ugkQr7wSNm4MX/+MMZliQcNkjxo14JNP4N13oWJFf/sXX7jbcx97zGo7jMmDLGiY7CMCXbu62o777w+u7Rg92hUGZnBWVWNMeFjQMNmveHF44QU36WGLFv72X35xQ1g33ww7d4avf8aYkFnQMDmncWP47jt3G26pUv72OXNcovzllyHZ9A+ZkZ9vJzcmI7Li/4QFDZOzChWCfv3ckFWPHv72I0fc9CTNm/urzDMhIiIi21cwMyavSUhISDEDcHpZ0DDhcc45MGMGfPmlu8rwiYuDiy+GAQMyVdtRvHhxDh8+nAUdNSb/OHLkCDG+2+EzyIKGCa/LL3e1HU8+GVzb8eqrLpjMmpWh2o4yZcokLTB08uRJG6oyBZqqcuzYMfbu3Uu5cuUydSybRsTkHlu2uJUBP/kkuL1tW5gwIbjaPATx8fHs37+fI0eOBM2+akxBFB0dTdmyZZNWBzyd000jYkHD5C6q8P77cO+9sGOHvz0qCoYOheHDoUiR8PXPmALA5p4yeYcIdO4M69bBAw+Ab1W1kyfd9CQNGsD8+eHtozEFmAUNkzsVLw7PP+8mPfTWVADcENbVV7sFoQKvRIwxOcKChsndLrwQ/u//YNIkKF3a3z53rkuUv/RSltZ2GGNOz4KGyf0KFYK+fV1tR8+e/vajR930JBddBEuXhq9/xhQgFjRM3nH22TB9OixeDIGLyKxcCZdcAv37g7eGsjEme+R40BCRDiKyQUQ2i8gjqWyvIiKLRCRORFaLSEevvZqIHBeRld5jYk733eQSrVu7QPHUU8G1HRMnuiGrN9+0dTuMySY5GjREJAIYD1wN1ANuEZF6yXYbCcxR1cZAN2BCwLZfVLWR97g7RzptcqeoKBg2DNauhWuu8bfv3u2mJ7niCjecZYzJUjl9pdEc2KyqW1T1JPA2cH2yfRQo4X1fErDpT03aqleHDz+E//4XKlf2ty9aBA0bwsiRcPx4+PpnTD6T00GjEvB7wPPtXlugUcBtIrId+AS4J2BbdW/Y6isRuSy1NxCRviKyXESW79mzJwu7bnItEbjxRlfb8eCD/tqOv/9205PUr5+yytwYkyG5MRF+CzBdVSsDHYGZIlII2AVU8YatHgBmi0iJ5C9W1cmq2kxVm2V2jhWTxxQrBs89Bz/+6BLjPlu3uiGsrl1h+/bw9c+YfCCng8YO4NyA55W9tkB3AnMAVHUJEAPEqmq8qu7z2lcAvwC1sr3HJu9p2BC+/RamTAmu7XjvPXfX1QsvWG2HMRmU00FjGXC+iFQXkShcontesn1+A64AEJG6uKCxR0TKeYl0ROQ84HxgS4713OQthQpBnz6wYQP06uVvP3rUTU/SrBl8/33YumdMXpWjQUNVE4BBwGfAOtxdUmtEZLSIdPJ2exC4S0RWAW8BvdTNqtgKWC0iK4G5wN2quj8n+2/yoHLlYNo0+OorqBdwo96qVdCypVsQar/9MzImVDbLrSk4Tp6EceNg9OjgO6rKlXO5kB49XFLdmALOZrk1BlxtxyOPuNqOa6/1t+/Z46YnadvW3YFljEmTBQ1T8FSrBvPmuXU7zg24L2PxYjdB4vDhcOxYuHpnTK5mQcMUTCJwww3uquOhh4JrO55+2tV2fPxxePtoTC5kQcMUbMWKwb//DXFxcOml/vZt29wQVpcuVtthTAALGsYAXHABfP01TJ0KZcr42//7XzcJ4rhxVtthDBY0jPErVAjuvNPVdtxxh7/9r7/c9CRNm8KSJeHrnzG5gAUNY5KLjYXXX3dXHvXr+9tXr3a1HX37Wm2HKbAsaBiTlssuc7mOZ5+FokX97VOmQO3a8MYbtm6HKXAsaBhzOoULw9Ch7i6rTp387Xv3uulJ2rRx24wpICxoGBOKqlXhgw/gf/8Lru34+mtX2zFsmNV2mAIhS4KGiJTNiuMYk+tdf72rGh86FCIjXVtCAjzzjMt/fPRRePtnTDZLV9AQkbtEZEjA8wu8xZJ2ewsflc/yHhqT25x1lstzxMXBP/7hb9+2Da67zi0I9dtvYeueMdkpvVca9wCBa2eOAw4C9+OWZh2dRf0yJvdr0MDNnvvaa1A24GL7f/9zM+o+95yrMDcmH0lv0KgKrAcQkZJAa2Coqv4HeAy4Kmu7Z0wuV6gQ9O4N69e7Gg+fv/6CIUNcbcd334Wvf8ZksfQGjULAKe/7fwAKLPae/w6cnTXdMiaPiY111eTffuuuQHx++slNT3LXXbBvX/j6Z0wWSW/Q2ARc433fDfhOVX23jFQErOLJFGyXXurWKB87Nri2Y+pUNx3JtGlW22HytPQGjeeA+0VkL9Ad+E/AtsuB1VnVMWPyrMKF3dDUunXubiufvXvdUFbr1rBmTfj6Z0wmpCtoqOpsXB7jaeByVf1vwOY/CQ4ixhRsVaq4pPi8ea7Ow+ebb6BRI7cg1F9/ha9/xmSALfdqTE746y944gl4/vng2XKrVoX//MfdqmtMLpFly72KSEsRuTbgeVkReUtEfhKR50QkIrOdNSZfOussVwC4cqWb08rn11/d9CQ33GC1HSZPSG9O4xmgacDzfwMdgY1Af2B4FvXLmPypfn1X2zFtmrvjyueDD6BuXbcglNV2mFwsvUGjLrAcQEQKA12BwaraBRiBS44bY05HxE12uH499Onjbz92zE1P0qQJ/N//ha17xpxOeoNGMeCw931z4CzAN9nOj0CVLOqXMflf2bJumvVvv3UrB/r8/LObnuTOO90dV8bkIukNGjuAC73vrwZ+VtXd3vPSgE3zaUx6XXoprFjhph056yx/++uvu9qO11+HU6fSfr0xOSi9QeMt4CkRmQs8ALwZsK0JrvjPGJNehQu7JWXXrXMTHvrs2+euOFq3dlcgxoRZeoPGKOBZIBqXFH8hYNuFwLtZ0y1jCqhzz4X//hc+/DC4tuPbb6FxY3j4YavtMGFldRrG5FbHjrnajueeC67tqFIFXn45uNrcmCyUZXUaAQdsICIDReRf3tf6meuiMSaFokXh6adh1Spo1crf/ttvrq7j+utdnYcxOSi9xX2RIvImsAo3Zcjj3tfVIjLTivuMyQb16sHixTB9enBtx7x5btvYsVbbYXJMeq80HgP+CTwKVAeKeF8fBW72vhpjspoI9OwJGza4adZ9jh1zeY7Gjd2cVsZks/QGjduAMar6pKr+qqrx3tcngTHA7VnfRWNMkjJlYPJkV/zXsKG/fc0aN4TVu7fVdphsld6gURFIaxmy77ztxpjs1rKlq+14/vng2o5p06B2bbcErdV2mGyQ3qCxE7g0jW0tve3GmJwQGQkPPOBqOzp39rfv3++mJ7nsMrdyoDFZKL1BYxYwwrtr6jwRKSIi1UVkGG7uqZlZ30VjzGmdey689x589BFUq+Zv/+47l+sYMgSOHg1b90z+kpHivrm4u6Y2AUeBzcCTuMK+0Wc6gIh0EJENIrJZRB5JZXsVEVkkInEislpEOgZsG+a9boOIXJXOvhuTv11zjcttDB/uKswBEhNdnUe9em5BqHxcl2VyRoaK+7y6jFZAGdy64F8DFYBxqtrwNK+LwE2jfiWwHVgG3KKqawP2mQzEqeqrIlIP+ERVq3nfv4WbKLEisBCopaqJab2fFfeZAmvdOujf303DHujaa92iT4FXJMYkk+XFfaq6RlVf9e6ielVV1wAlgTMV+TUHNqvqFlU9CbwNJC9rVaCE931J/HmS64G3vTu2tuKucJpnpP/G5Ht168KiRTBjBpQr52//6CN31fHss3DyZPj6Z/KsDAWNTKgE/B7wfLvXFmgUcJuIbAc+Ae5Jx2sRkb4islxElu/Zsyer+m1M3iMCPXq4dTv69fO3Hz/u1idv3Bi+/jp8/TN5Uk4HjVDcAkxX1cq4VQFnikjI/VTVyaraTFWblQv8hGVMQVWmDEycCEuWwIUX+tvXrnWz595xB9gHLBOinA4aO4BzA55X9toC3QnMAVDVJUAMEBvia40xabn4Yli+HF54AYoV87dPn+5qO6ZOtdoOc0ZnDBrerbVnfADlQ3i/ZcD53m26UUA3YF6yfX4DrvDeuy4uaOzx9usmItEiUh04H/gh5DM1xrjajvvvd4nyrl397QcOuOlJ/vEPWL06fP0zuV5kCPtsxiWnz0TOtJ+qJojIIOAzIAJ4XVXXiMhoYLmqzgMeBKaIyGDveL3U3eK1RkTmAGuBBGDg6e6cMsacRuXK8O678MknMGgQbN3q2pcscWuU338/jBoVfEViDCHccisiPdNzQFV9I1M9ykJ2y60xITh2DJ56KuVsuZUru3U7brjBJdVNgXG6W25tESZjjLN+vavtWLw4uP2aa1xtR/XqYemWyXlZXqdhjMmH6tSBL7+EmTODazs+/hjq13cLQlltR4FnQcMY4ycCt93m1u24+27/sNTx4256kkaNUlaZmwLFgoYxJqXSpeHVV11ivFEjf/u6ddCmjVsQavfusHXPhI8FDWNM2lq0gGXL4MUXg++kmjHDDWdNnmy1HQWMBQ1jzOlFRsJ997lE+U03+dsPHHDTk1x6KaxaFb7+mRxlQcMYE5pKlWDOHPj0UzjvPH/7999D06ZuQagjR8LXP5MjLGgYY9KnQwf4+Wf417+C1+144QU3u+5779m6HfmYBQ1jTPoVKQKjR7vlZNu29bfv2OGmJ7n2WtiyJXz9M9nGgoYxJuNq14aFC+HNN+Hss/3tn3ziajuefBLi48PXP5PlLGgYYzJHBG691V9R7qvtOHECRo50t+wmrzI3eZYFDWNM1ihdGiZMcInxxo397evXw+WXw+23W21HPmBBwxiTtZo3hx9+gJdeguLF/e0zZ7rhrEmTrLYjD7OgYYzJepGRcO+97irjn//0tx886KYnadkSVq4MX/9MhlnQMMZkn4oV4Z134LPPoEYNf/vSpa62Y/Bgq+3IYyxoGGOyX/v27vbcRx+FqCjXduqUm56kTh2YO9dqO/IICxrGmJxRpAg8/rgLHldc4W/fudNNT9KxI/zyS/j6Z0JiQcMYk7Nq1YIFC2DWLDjnHH/7/PnQoAGMGWO1HbmYBQ1jTM4Tge7dXaJ84MDg2o5//QsuvBAWLQpvH02qLGgYY8KnVCl45RWXGG/SxN++YYObnuS22+DPP8PXP5OCBY1UPPcc9O3r1qD5/nv4669w98iYfO6ii1xtx8svQ4kS/vZZs1xtx6uvukkRTdiJ5uM7Fpo1a6bLly9P9+tatnQLlvkUKuSGYRs3do9GjdzX2Ngs7Kwxxtm1y02z/vbbwe3Nm8PEicHV5iZbiMgKVW2W6jYLGsESE90HnWPHzrxv5crBQaRxY6ha1T88a4zJhAULYMAA2LzZ31aoEAwaBE88EXxFYrKUBY10SEhwc6vFxfkfGzaEfgt5qVLBQaRxY3cbemRk+vtvTIF34gQ88ww8/TScPOlvr1DB1XjcdJN9SssGFjQy6a+/3K3lgYHkp59CvyswOhouuCB4eKthQzjrrEx3zZiCYeNGd5fVwoXB7VddBePHB1ebm0yzoJENEhLc3YJxcW4KHV8wOXgwtNcH5kkCr0wsT2JMGlTdlCSDB8Mff/jbo6NhxAgYOtR9bzLNgkYOUYVffw0OInFxsH176MeoVCl4aMvyJMYkc+iQW6dj/PjgceNatdzU7IHV5iZDLGiE2d69wYFk5UqXJwl1dujAPInva506/uWZjSmQli93M+auWBHc3r07PP88lC8fnn7lAxY0cqHAPIkvoPz0k8v7hcKXJwkc2rI8iSlwEhPdbbjDh8Phw/72kiXhqaegXz+IiAhf//IoCxp5hC9Pknx4K9Q8iUhwPYnvyqRcuezttzFht2sXPPggvPVWcPtFF7nCwKZNw9OvPMqCRh6mCr/9FhxEVq6E338P/RiBeRLflUm1apYnMfnQwoWutmPTJn9boULuzqsnnnBXIOaMLGjkQ4F5Et/XjORJAoe3LE9i8oUTJ2DsWDc8FXhffIUK8MILbiVB+8R0WhY0Cohjx2D16uDhrfTmSRo0CB7esjyJybM2b3ZXGJ9/Htzevr2786pmzfD0Kw+woFGAJSS4K5DAoa24ODhwILTXJ8+T+K5MLE9i8gRVmDPH1Xbs2uVvj46GYcPg4YchJiZ8/culclXQEJEOwEtABDBVVZ9Jtv0F4HLvaVHgbFUt5W1LBH7ytv2mqp1O914WNFIXmCcJvCrJSJ4kcHjL8iQm1zp0yK3TMX588Bju+ee72o527cLXt1wo1wQNEYkANgJXAtuBZcAtqro2jf3vARqram/v+VFVLRbq+1nQSB9fniQwkKQnT1KyZOrzblmexOQaK1ZA//6wbFlw+y23wLhxVtvhyU1B4xJglKpe5T0fBqCqT6ex/3fAY6q6wHtuQSOHHTsWPO/WypUub5LRPIlv3q1iIf8WjcliiYkwaZKr7Th0yN9eooRLnt99d4Gv7chNQaMr0EFV+3jPewAtVHVQKvtWBb4HKqtqoteWAKwEEoBnVPV/qbyuL9AXoEqVKk1//fXX7DqdAiswTxJ4VZLePEnyqxLLk5gc9ccfrrZj9uzg9mbNXG1Hs1T/ZhYIeTVoPIwLGPcEtFVS1R0ich7wJXCFqv6S1vvZlUbO8eVJkhcmpidPUrFiysLE6tUtT2Ky2RdfuNqOjRv9bSLuzqsxYwpkbUduChohD0+JSBwwUFW/S+NY04GPVHVuWu9nQSP89u1LOe/W+vUZy5P4vtata3kSk8Xi411tx5NPBtd2lC/vajtuvrlAfXrJTUEjEpcIvwLYgUuEd1fVNcn2qwPMB6qr10ERKQ0cU9V4EYkFlgDXp5VEBwsauVVgnsQXUDKSJ0k+75blSUymbd7sVgb87LPg9nbt3F1W558fnn7lsFwTNLzOdARexN1y+7qqPikio4HlqjrP22cUEKOqjwS8riUwCTgFFAJeVNXXTvdeFjTyDl+eJPnwVnryJOefn3J46+yzs7ffJh9Shblz4b77gms7oqJcbccjj+T72o5cFTRykgWNvE3V5USSFyb+9lvoxwjMk/iuTCxPYkJy+DA8+ij85z/B46k1a7p6j/btw9e3bGZBw+QrgXkS39eM5EkCh7csT2LSFBfnbsP94Yfg9m7dXG1HhQrh6Vc2sqBh8r1jx+Dnn4OHttKTJ4mKSn3eLcuTGMDVdkyZ4oamktd2jBnj7r7KR7UdFjRMgZSQ4O6iTD68tX9/aK9PnifxXZlYnqQA+/NPeOghePPN4PamTd1iUPmktsOChjGewDxJYNI9I3mSwOEty5MUMF9+6a4uNmzwt4m4tjFj3NoDeZgFDWPOYN8+WLUqeHgrPXmSEiWCg0ijRlCvnuVJ8rX4eHjuORckAsdBzznH5TpuuSXPfpKwoGFMBhw/nvq8W8ePh/b6wDyJL6BceKHlSfKdX35xtR3z5we3X3GFq+2oVSs8/coECxrGZJHAPEng8FZG8iSBVyaWJ8njVOG991xtx86d/vaoKJc8HzYsT9V2WNAwJhv58iTJCxPTmydJPrx13nl5dnSj4DpyxNV2vPxy8NhmjRqutuOqq8LXt3SwoGFMGOzfn3LerXXrMpYn8X21PEkeERfn1u1YujS4/Z//dHNZVawYnn6FyIKGMblEYJ4kcN6t9OZJAq9KLE+SS5065a/tOHjQ3168uL+2IzIyfP07DQsaxuRivjxJ8uGt9ORJatZMOe/WOedkb79NiP78E4YMgZkzg9sbN3a1Hc2bh6dfp2FBw5g8RhW2bw8OIitXQnrWFKtQIWVhouVJwmjRInd1sX69v03ETVHy1FO5qrbDgoYx+YQvTxJ4VbJ+vZvlIhS+PEng8JblSXLQyZOutuOJJ1LWdjz/PHTvniuiugUNY/Kx48dTn3crPXmS+vVTzrtVvHj29rtA27IF7rkHPvkkuL1tW1fbUbt2ePrlsaBhTAGTmJj6vFv79oX2+uR5Et+VieVJspAqvP8+3Hsv7Njhb4+KgqFDYfhwKFIkLF2zoGGMCcqTBA5vZSRPknzerUKFsq/f+d6RIzBqFLz0UvA443nnudqODh1yvEsWNIwxadq/P/V5t9KTJ7nwwuDhrbp13Qdmkw6rVrmk+PffB7d37QovvgiVKuVYVyxoGGPSJXmeZOVK9zcto3mSRo1cYLE8yRmcOgVTp7rajsC1josVc7UdAwfmSG2HBQ1jTKYF5kkCh7cykicJHN6yPEkqdu92eY033ghub9TI1Xa0aJGtb29BwxiTLXx5kuSFienJk5Qvn7Iw8bzzLE8CwFdfuelI1q3zt4lAv36utqN06Wx5WwsaxpgcdeBA6vNuhZonKV489Xm3CmSe5ORJV8PxxBPB44Nnn+3ab701y2s7LGgYY8IuME8SOO/WsWOhvb5w4dTn3SoweZKtW11tx8cfB7dffrmr7ahTJ8veyoKGMSZXSkyETZuCh7bSkyeB1OfdKl8++/ocVqrwv/+52o7t2/3thQu7HMiIEVlS22FBwxiTZ6i6WrfkhYnbtoV+jMA8SeC8W/kmT3L0qKvtePHF4DG/6tXhlVegY8dMHd6ChjEmz/PlSQJzJRnJkySfdytP50lWr3a1HUuWBLd36eICSuXKGTqsBQ1jTL50/DisWZNy3q305ElSm3erRIns7XeWOnUKXn/dDU8lr+0YPdoNZUVEpOuQFjSMMQVG8jyJ78pk797Qj5HavFu5Pk+yZ48LHNOn+9vatoWFC9N9d5UFDWNMgRaYJwkc3spIniRweCtX5km+/trVdmze7C67MjBjrgUNY4xJxYEDKefdSm+eJPm8W7kiT3LypFuf/LLLMvRyCxrGGBOiEydSn3crI3kS31XJhRfmrTyJBQ1jjMmEwDxJ4PBWevMkgUNbuTlPYkHDGGOymC9PknzerfTkSc45J2VhYo0a4c+TWNAwxpgccvCgP5D4vq5dm7E8ie/KpH79nM2T5KqgISIdgJeACGCqqj6TbPsLwOXe06LA2apaytvWExjpbRujqsnmDQ5mQcMYkxv48iSBVyUZyZMkn3cru/IkuSZoiEgEsBG4EtgOLANuUdW1aex/D9BYVXuLSBlgOdAMUGAF0FRVD6T2WrCgYYzJvRIT3V2xyefdSk+epEaNlMNbFSpkvm+nCxrZvwRUsObAZlXdAiAibwPXA6kGDeAW4DHv+6uABaq633vtAqAD8Fa29tgYY7JBRIQroahdG7p1c22qsHNnysLErVtTP8Yvv7jH3Ln+tsA8SZs20L591vY7p4NGJeD3gOfbgVSXoBKRqkB14MvTvDbnFs01xphsJuKWAq9UCa691t/uy5MEDm+llSf580+YP989fv897weN9OgGzFXVENNHjoj0BfoCVKlSJTv6ZYwxOapUKXfV0KaNv+3EiZTzbiXPkzRqlPV9yemgsQM4N+B5Za8tNd2Agcle2ybZaxcnf5GqTgYmg8tpZLyrxhiTe8XEQNOm7uETmCdZudJNPZXVcjoRHolLhF+BCwLLgO6quibZfnWA+UB19TroJcJXAE283X7EJcL3p/V+lgg3xpj0yzWJcFVNEJFBwGe4W25fV9U1IjIaWK6q87xduwFva0BEU9X9IvIELtAAjD5dwDDGGJP1rLjPGGNMkNNdaeS2SX2NMcbkYhY0jDHGhMyChjHGmJBZ0DDGGBMyCxrGGGNClq/vnhKRPcCvmThELJCO6cPyhYJ2zgXtfMHOuaDIzDlXVdVyqW3I10Ejs0RkeVq3neVXBe2cC9r5gp1zQZFd52zDU8YYY0JmQcMYY0zILGic3uRwdyAMCto5F7TzBTvngiJbztlyGsYYY0JmVxrGGGNCZkHDGGNMyAp80BCRDiKyQUQ2i8gjqWyPFpF3vO1LRaRazvcya4Vwzg+IyFoRWS0iX3hL7+ZpZzrngP26iIiKSJ6/PTOUcxaRf3q/6zUiMjun+5jVQvi3XUVEFolInPfvu2M4+plVROR1EdktIj+nsV1E5GXv57FaRJqktl+6qGqBfeDW9PgFOA+IAlYB9ZLtMwCY6H3fDXgn3P3OgXO+HCjqfd+/IJyzt19x4Gvge6BZuPudA7/n84E4oLT3/Oxw9zsHznky0N/7vh6wLdz9zuQ5t8ItTPdzGts7Ap8CAlwMLM3sexb0K43mwGZV3aKqJ4G3geuT7XM98Ib3/VzgChGRHOxjVjvjOavqIlX1rTT8PW5p3bwslN8zwBPAs8CJnOxcNgnlnO8CxqvqAQBV3Z3DfcxqoZyzAiW870sCO3Owf1lOVb8GTrcY3fXADHW+B0qJSIXMvGdBDxqVgN8Dnm/32lLdR1UTgENA2RzpXfYI5ZwD3Yn7pJKXnfGcvcv2c1X145zsWDYK5fdcC6glIv8nIt+LSIcc6132COWcRwG3ich24BPgnpzpWtik9//7GeXocq8mbxGR24BmQOtw9yU7iUghYBzQK8xdyWmRuCGqNrirya9F5AJVPRjWXmWvW4Dpqvq8iFwCzBSRBqp6KtwdyysK+pXGDuDcgOeVvbZU9xGRSNwl7b4c6V32COWcEZF2wAigk6rG51DfssuZzrk40ABYLCLbcGO/8/J4MjyU3/N2YJ6q/q2qW4GNuCCSV4VyzncCcwBUdQkQg5vYL78K6f97ehT0oLEMOF9EqotIFC7RPS/ZPvOAnt73XYEv1cswEA5GsAAABDVJREFU5VFnPGcRaQxMwgWMvD7ODWc4Z1U9pKqxqlpNVavh8jidVDUvLzAfyr/t/+GuMhCRWNxw1Zac7GQWC+WcfwOuABCRurigsSdHe5mz5gG3e3dRXQwcUtVdmTlggR6eUtUEERkEfIa78+J1VV0jIqOB5ao6D3gNdwm7GZdw6ha+HmdeiOf8b6AY8K6X8/9NVTuFrdOZFOI55yshnvNnQHsRWQskAkNUNc9eRYd4zg8CU0RkMC4p3isvfwgUkbdwgT/Wy9M8BhQGUNWJuLxNR2AzcAy4I9PvmYd/XsYYY3JYQR+eMsYYkw4WNIwxxoTMgoYxxpiQWdAwxhgTMgsaxhhjQmZBwxR4ItLLm9k2tUdYq6NFZLp3K6UxuUKBrtMwJpmbcFXSgRLC0RFjcisLGsb4rVTVzeHuhDG5mQ1PGROigGGsViLyPxE5KiL7RGS8iBRJtm8FEZkhIntFJN5bAOe2VI5ZXURmisgf3n5bROSlVPZrLCLfiMgxEdkkIncn215eRN4QkZ3ecXaJyEcicnbW/yRMQWZXGsb4RXiTUgY6lcoMqG/iJr2bgFvD4VHgLLxZckXkLOAroDQwHDc19W246WiKqupkb7/qwA+46R0eBTYBVYD2yd6vBDAbeBEYjZsK4lUR2aCqi7x9ZgJVgSHe+52Dm2OpaEZ+EMakKdwrT9nDHuF+4P7YaxqPj1LZb2Ky14/Azd1Uy3s+yNuvTbL9FgK7gQjv+QzgKFDxNH2b7h3r8oC2aNxMy5MD2o4C94b7Z2mP/P+wKw1j/G4kZSI8tbun5iR7/jYwBnfVsRG3BOcOVV2cbL83gWm4ZUZ/wl1RfKSqZ1o97pj6ryhQ1XgR2Yi7KvFZBgzxVpX8Erf8p00sZ7KcBQ1j/H7W0BLhf6bx3LciWhkgtemn/wjYDm4FyFBupz2QSls8blpvn5txM5wOxQ1j7RKRicAYtQWGTBayRLgx6XdOGs99i9vsB8qn8rryAdsB9pLJpTd9VHW3qg5U1UpAHdyw1uNAv6w4vjE+FjSMSb9/JnveDTgFLPWefwVUFpFLk+3XHZfTWOs9/xy4VkQqZGXnVHWDqg7HXaE0yMpjG2PDU8b4NfJWsEtuuaoGFvl1FJF/4/7oN8cNC81Q1U3e9unAfcB/RWQEbgjqVuBKoJ+qJnr7PYZbIOc7EXkKt1BOJaCDqqa4PTctIlISl2SfBawH/gaux9299XmoxzEmFBY0jPF7N432crihJJ/bcCvA9QdOAlOAh3wbVfUvEWkNjAWewa1BvgHooapvBuy3zVuCcwzwNG61xB3AB+ns9wngR+Au3G23p7z3u1VV03ssY07LVu4zJkQi0gt399P5ISbMjcl3LKdhjDEmZBY0jDHGhMyGp4wxxoTMrjSMMcaEzIKGMcaYkFnQMMYYEzILGsYYY0JmQcMYY0zI/h8LhbtMQSOieQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5SAIfi4LXRn",
        "colab_type": "code",
        "outputId": "d7f0d7ce-5d48-4807-82f3-22aec33b3e82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "accr = model.evaluate(x_test,y_test)\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "284213/284213 [==============================] - 378s 1ms/step\n",
            "Test set\n",
            "  Loss: 0.700\n",
            "  Accuracy: 0.738\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmE4cD7rLXOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "Pkl_Filename = \"Pickle_Model.pkl\"  \n",
        "\n",
        "with open(Pkl_Filename, 'wb') as file:  \n",
        "    pickle.dump(model, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytnuhQeya8_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CD6ZO_gLyHf",
        "colab_type": "code",
        "outputId": "ea9324db-a6ea-4769-a123-3be38daf1d97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Load the Model back from file\n",
        "with open(Pkl_Filename, 'rb') as file:  \n",
        "    Pickled_Model = pickle.load(file)\n",
        "\n",
        "Pickled_Model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning:\n",
            "\n",
            "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.training.Model at 0x7f06784855f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "movK538pLy0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the Reloaded Model to \n",
        "# Calculate the accuracy score and predict target values\n",
        "\n",
        "# Calculate the Score \n",
        "# score = Pickled_Model.score(x_test, y_test)  \n",
        "# # Print the Score\n",
        "# print(\"Test score: {0:.2f} %\".format(100 * score))  \n",
        "\n",
        "# Predict the Labels using the reloaded Model\n",
        "Ypredict = Pickled_Model.predict(x_test)  \n",
        "\n",
        "Ypredict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGZTiolmLyww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S193hYU9H75",
        "colab_type": "code",
        "outputId": "50f85fb5-f12d-49c4-b6fc-424f8e54c5a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "review_ = input()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I really liked the product. it was good, but not so good\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuA6Oyt1LNFS",
        "colab_type": "code",
        "outputId": "2649896d-160f-4a2c-d3f5-84634d4e1602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "review"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I really liked the product. it was good, but not so good'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0dl6NTtK29N",
        "colab_type": "code",
        "outputId": "aa2dc447-4a3c-46a4-d020-85b86f691b55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "model.predict([review])[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-d4401cca6731>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_single_array\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 'Got tensor with shape: %s' % str(shape))\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'ndim'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qwozw53KLE9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6wVjPAkKom6",
        "colab_type": "code",
        "outputId": "ef89a17f-3fb8-4e43-dc45-122937d4b3b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install pycaret"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycaret\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/41/f7fa05b6ce3cb3096a35fb5ac6dc0f2bb23e8304f068618fb2501be0a562/pycaret-1.0.0-py3-none-any.whl (188kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 3.4MB/s \n",
            "\u001b[?25hCollecting shap==0.32.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/43/08f152a59a1d60f0328b476bdd58c791498989981ab9c6d595ec5448a86a/shap-0.32.1.tar.gz (259kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 40.3MB/s \n",
            "\u001b[?25hCollecting datetime\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/22/a5297f3a1f92468cc737f8ce7ba6e5f245fcfafeae810ba37bd1039ea01c/DateTime-4.3-py2.py3-none-any.whl (60kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from pycaret) (7.5.1)\n",
            "Collecting scikit-learn==0.22\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/d0/860c4f6a7027e00acff373d9f5327f4ae3ed5872234b3cbdd7bcb52e5eff/scikit_learn-0.22-cp36-cp36m-manylinux1_x86_64.whl (7.0MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 20.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly==4.4.1 in /usr/local/lib/python3.6/dist-packages (from pycaret) (4.4.1)\n",
            "Collecting lightgbm==2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/9d/ddcb2f43aca194987f1a99e27edf41cf9bc39ea750c3371c2a62698c509a/lightgbm-2.3.1-py2.py3-none-manylinux1_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 40.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pycaret) (1.0.3)\n",
            "Collecting kmodes==0.10.1\n",
            "  Downloading https://files.pythonhosted.org/packages/79/c0/f7d8a0eb41ac6f302b4bc100f91b6e0f2558425ccfefaa0ec0430f77ee97/kmodes-0.10.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: xgboost==0.90 in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.90)\n",
            "Collecting pandas-profiling==2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/2f/aae19e2173c10a9bb7fee5f5cad35dbe53a393960fc91abc477dcc4661e8/pandas-profiling-2.3.0.tar.gz (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 50.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: wordcloud in /usr/local/lib/python3.6/dist-packages (from pycaret) (1.5.0)\n",
            "Collecting datefinder==0.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/16/2b/af8efaee30c0ba4238cb4d0645a07100d33d11d20a8783c443ed8b813eb9/datefinder-0.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from pycaret) (2.2.4)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.15.3)\n",
            "Collecting pyLDAvis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/3a/af82e070a8a96e13217c8f362f9a73e82d61ac8fff3a2561946a97f96266/pyLDAvis-2.1.2.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 35.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (from pycaret) (3.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pycaret) (1.18.4)\n",
            "Collecting pyod\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/68/99df05e5666248e9c10359457e2da1b89943f5ac96749ceb1c131001eb88/pyod-0.8.0.tar.gz (93kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from pycaret) (3.2.1)\n",
            "Collecting catboost==0.20.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/c4/586923de4634f88a31fd1b4966e15707a912b98b6f4566651b5ef58f36b5/catboost-0.20.2-cp36-none-manylinux1_x86_64.whl (63.9MB)\n",
            "\u001b[K     |████████████████████████████████| 63.9MB 119kB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.10.1)\n",
            "Collecting cufflinks==0.17.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/79/1b8673b2723e02919307d558896dbcedcb46807c4e29acd25cfe43a36c8b/cufflinks-0.17.0.tar.gz (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: IPython in /usr/local/lib/python3.6/dist-packages (from pycaret) (5.5.0)\n",
            "Collecting yellowbrick==1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/cf/6d6ab47c0759d246262f9bdb53e89be3814bf1774bc51fffff995f5859f9/yellowbrick-1.0.1-py3-none-any.whl (378kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 40.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from pycaret) (3.2.5)\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.14.0)\n",
            "Collecting awscli\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/26/2bf03cd24e42550e0487b2f78202cd4aa8b9e2fe859f09335c9c2ab1b2c5/awscli-1.18.69-py2.py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 38.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.15.1)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.4.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from shap==0.32.1->pycaret) (1.4.1)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.6/dist-packages (from shap==0.32.1->pycaret) (4.41.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from datetime->pycaret) (2018.9)\n",
            "Collecting zope.interface\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/33/565274c28a11af60b7cfc0519d46bde4125fcd7d32ebc0a81b480d0e8da6/zope.interface-5.1.0-cp36-cp36m-manylinux2010_x86_64.whl (234kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 47.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret) (5.0.6)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret) (3.5.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret) (4.10.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret) (4.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly==4.4.1->pycaret) (1.12.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly==4.4.1->pycaret) (1.3.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->pycaret) (2.8.1)\n",
            "Requirement already satisfied: jinja2>=2.8 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.3.0->pycaret) (2.11.2)\n",
            "Requirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.3.0->pycaret) (0.4.2)\n",
            "Collecting htmlmin>=0.1.12\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/e7/fcd59e12169de19f0131ff2812077f964c6b960e7c09804d30a7bf2ab461/htmlmin-0.1.12.tar.gz\n",
            "Collecting phik>=0.9.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/5a/7ef1c04ce62cd72f900c06298dc2385840550d5c653a0dbc19109a5477e6/phik-0.10.0-py3-none-any.whl (599kB)\n",
            "\u001b[K     |████████████████████████████████| 604kB 41.2MB/s \n",
            "\u001b[?25hCollecting confuse>=1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/64/85dbcea372efee5cba13eaa10a3bfa7019b8fe0c3c8314d8e189116e477a/confuse-1.1.0.tar.gz\n",
            "Requirement already satisfied: astropy in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.3.0->pycaret) (4.0.1.post1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from wordcloud->pycaret) (7.0.0)\n",
            "Requirement already satisfied: regex>=2017.02.08 in /usr/local/lib/python3.6/dist-packages (from datefinder==0.7.0->pycaret) (2019.12.20)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (2.0.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (46.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (0.6.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (2.23.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (3.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (1.0.0)\n",
            "Requirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (0.34.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (2.7.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (3.6.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (0.16.0)\n",
            "Collecting funcy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/4b/6ffa76544e46614123de31574ad95758c421aae391a1764921b8a81e1eae/funcy-1.14.tar.gz (548kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 48.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim->pycaret) (2.0.0)\n",
            "Collecting combo\n",
            "  Downloading https://files.pythonhosted.org/packages/78/52/e880bd923eba122515307d29ab43c1c356bad60610c27bed2cdec25d0240/combo-0.1.0.tar.gz\n",
            "Requirement already satisfied: numba>=0.35 in /usr/local/lib/python3.6/dist-packages (from pyod->pycaret) (0.48.0)\n",
            "Collecting suod\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/87/9170cabe1b5e10a7d095c0e28f2e30e7c1886a13f063de85d3cfacc06f4b/suod-0.0.4.tar.gz (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 35.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pycaret) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pycaret) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pycaret) (0.10.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost==0.20.2->pycaret) (0.10.1)\n",
            "Collecting chart-studio>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/ce/330794a6b6ca4b9182c38fc69dd2a9cbff60fd49421cb8648ee5fee352dc/chart_studio-1.1.0-py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: colorlover>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from cufflinks==0.17.0->pycaret) (0.3.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (2.1.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (1.0.18)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (4.8.0)\n",
            "Collecting botocore==1.16.19\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/8c/b8d7e77d9e5a373124dc5817901e454fdde03efcfeadab519dc7be74e3ae/botocore-1.16.19-py2.py3-none-any.whl (6.2MB)\n",
            "\u001b[K     |████████████████████████████████| 6.2MB 32.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from awscli->pycaret) (0.15.2)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from awscli->pycaret) (0.3.3)\n",
            "Collecting colorama<0.4.4,>=0.2.5; python_version != \"3.4\"\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Collecting rsa<=3.5.0,>=3.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/ae/baedc9cb175552e95f3395c43055a6a5e125ae4d48a1d7a924baca83e92e/rsa-3.4.2-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML<5.4,>=3.10; python_version != \"3.4\" in /usr/local/lib/python3.6/dist-packages (from awscli->pycaret) (3.13)\n",
            "Requirement already satisfied: tbb in /usr/local/lib/python3.6/dist-packages (from umap-learn->pycaret) (2020.0.133)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (4.6.3)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (2.6.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.2.2)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (4.5.3)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.3.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.8->pandas-profiling==2.3.0->pycaret) (1.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pycaret) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pycaret) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pycaret) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pycaret) (2.9)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->pycaret) (1.6.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (1.8.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (8.3.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (1.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (19.3.0)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim->pycaret) (2.49.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim->pycaret) (1.13.13)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.35->pyod->pycaret) (0.31.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->pycaret) (0.1.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->IPython->pycaret) (0.6.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from botocore==1.16.19->awscli->pycaret) (0.10.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<=3.5.0,>=3.1.2->awscli->pycaret) (0.4.8)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.8.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.6.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->pycaret) (19.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->pycaret) (3.1.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.4.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (3.1.5)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (20.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.1)\n",
            "Building wheels for collected packages: shap, pandas-profiling, pyLDAvis, pyod, cufflinks, htmlmin, confuse, funcy, combo, suod\n",
            "  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shap: filename=shap-0.32.1-cp36-cp36m-linux_x86_64.whl size=376806 sha256=125bdb0f0dea20e11f9702c15dc373057de954bb231545909cae1d33fd18955d\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/b2/50/8fadb5a59789cb5bdeb01b800223be540651ae92915172050b\n",
            "  Building wheel for pandas-profiling (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas-profiling: filename=pandas_profiling-2.3.0-py2.py3-none-any.whl size=145035 sha256=6b42fcd846ae91d171ffd262287f006ac2d2590e951b09f1c40002c6be05e4c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/c7/f1/dbfef4848ebb048cb1d4a22d1ed0c62d8ff2523747235e19fe\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-2.1.2-py2.py3-none-any.whl size=97711 sha256=5e34470dc8008c1708a091175c7676822792b39a25fbc8b85669d904d1916842\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/71/24/513a99e58bb6b8465bae4d2d5e9dba8f0bef8179e3051ac414\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-0.8.0-cp36-none-any.whl size=105563 sha256=1efb9c2813e9ec9b6825f67b4c8bcfafcc1cad4b5ecceecf9674793671f7283f\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/a6/81/2dd042e240090f3603a686b897d03402219a86e3f61bc71184\n",
            "  Building wheel for cufflinks (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cufflinks: filename=cufflinks-0.17.0-cp36-none-any.whl size=67744 sha256=3bdb472c2d8c839a26782d5d329035f143461d67277d0d122001b6496ac98270\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/d7/dc/e830ab00bc2dd3b2731295103baa070f8cbdda8891f71a7a8d\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-cp36-none-any.whl size=27084 sha256=453a92c0ce5e114389639777b1600d4f56653cdd2974839450ff8d7e17e2974a\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/07/ac/7c5a9d708d65247ac1f94066cf1db075540b85716c30255459\n",
            "  Building wheel for confuse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for confuse: filename=confuse-1.1.0-cp36-none-any.whl size=17574 sha256=287c373ad4f446a531c6a6841b95e7b0dea32508c2f73a0350cdd53a7f97f7e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/8b/23/41a1b516f6d8d4cc81f5bdb55394a47cdbe9659c53668d3c9e\n",
            "  Building wheel for funcy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for funcy: filename=funcy-1.14-py2.py3-none-any.whl size=32042 sha256=5cfbfbdaedc466767171967cf99f32c8920397186156558bfb344bfb19273a92\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/5a/d8/1d875df03deae6f178dfdf70238cca33f948ef8a6f5209f2eb\n",
            "  Building wheel for combo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for combo: filename=combo-0.1.0-cp36-none-any.whl size=42043 sha256=6e4a5aaa47eaa58a1d5855ce727f1029f2e831085013aba16e8fe2dc69662b8c\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/fd/6c/8da495ef08ce61844a646df2423c2b8ecda377a89c90ecd88e\n",
            "  Building wheel for suod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for suod: filename=suod-0.0.4-cp36-none-any.whl size=2167157 sha256=013fbe606a1e748a5d11030289f6d4ba7a356afa7164b77f66e1bef30b03ef34\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/55/e5/a4fca65bba231f6d0115059b589148774b41faea25b3f2aa27\n",
            "Successfully built shap pandas-profiling pyLDAvis pyod cufflinks htmlmin confuse funcy combo suod\n",
            "Installing collected packages: scikit-learn, shap, zope.interface, datetime, lightgbm, kmodes, htmlmin, phik, confuse, pandas-profiling, datefinder, funcy, pyLDAvis, combo, suod, pyod, catboost, chart-studio, cufflinks, yellowbrick, botocore, colorama, rsa, awscli, pycaret\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "  Found existing installation: pandas-profiling 1.4.1\n",
            "    Uninstalling pandas-profiling-1.4.1:\n",
            "      Successfully uninstalled pandas-profiling-1.4.1\n",
            "  Found existing installation: cufflinks 0.17.3\n",
            "    Uninstalling cufflinks-0.17.3:\n",
            "      Successfully uninstalled cufflinks-0.17.3\n",
            "  Found existing installation: yellowbrick 0.9.1\n",
            "    Uninstalling yellowbrick-0.9.1:\n",
            "      Successfully uninstalled yellowbrick-0.9.1\n",
            "  Found existing installation: botocore 1.16.13\n",
            "    Uninstalling botocore-1.16.13:\n",
            "      Successfully uninstalled botocore-1.16.13\n",
            "  Found existing installation: rsa 4.0\n",
            "    Uninstalling rsa-4.0:\n",
            "      Successfully uninstalled rsa-4.0\n",
            "Successfully installed awscli-1.18.69 botocore-1.16.19 catboost-0.20.2 chart-studio-1.1.0 colorama-0.4.3 combo-0.1.0 confuse-1.1.0 cufflinks-0.17.0 datefinder-0.7.0 datetime-4.3 funcy-1.14 htmlmin-0.1.12 kmodes-0.10.1 lightgbm-2.3.1 pandas-profiling-2.3.0 phik-0.10.0 pyLDAvis-2.1.2 pycaret-1.0.0 pyod-0.8.0 rsa-3.4.2 scikit-learn-0.22 shap-0.32.1 suod-0.0.4 yellowbrick-1.0.1 zope.interface-5.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "rsa"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x0-jf2BKo_w",
        "colab_type": "code",
        "outputId": "c8cf9eba-ac3e-4409-cf08-7c413f371dbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwrMOwmVKo9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pycaret.nlp import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McfnwQXhKo6B",
        "colab_type": "code",
        "outputId": "6cd74f4f-3a27-4379-8c9f-cefd0830510f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "a516df7d3fda4788abfba0efbae25b49",
            "3c8baf96ba774c00942c4ab863f2643c",
            "fbfc25f21c27424a993dd15da84d7a8c"
          ]
        }
      },
      "source": [
        "%time su_1 = setup(data = df, target = 'review', custom_stopwords=stop_words, session_id=21)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "</style><table id=\"T_3845d770_a3f0_11ea_8926_0242ac1c0002\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Description</th>        <th class=\"col_heading level0 col1\" >Value</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                                <td id=\"T_3845d770_a3f0_11ea_8926_0242ac1c0002row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
              "                        <td id=\"T_3845d770_a3f0_11ea_8926_0242ac1c0002row0_col1\" class=\"data row0 col1\" >21</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                                <td id=\"T_3845d770_a3f0_11ea_8926_0242ac1c0002row1_col0\" class=\"data row1 col0\" ># Documents</td>\n",
              "                        <td id=\"T_3845d770_a3f0_11ea_8926_0242ac1c0002row1_col1\" class=\"data row1 col1\" >568427</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                                <td id=\"T_3845d770_a3f0_11ea_8926_0242ac1c0002row2_col0\" class=\"data row2 col0\" >Vocab Size</td>\n",
              "                        <td id=\"T_3845d770_a3f0_11ea_8926_0242ac1c0002row2_col1\" class=\"data row2 col1\" >133772</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                                <td id=\"T_3845d770_a3f0_11ea_8926_0242ac1c0002row3_col0\" class=\"data row3 col0\" >Custom Stopwords</td>\n",
              "                        <td id=\"T_3845d770_a3f0_11ea_8926_0242ac1c0002row3_col1\" class=\"data row3 col1\" >True</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f1d4e0b3da0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 52min 30s, sys: 11.3 s, total: 52min 41s\n",
            "Wall time: 52min 46s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVCAElp8Ko3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Stage 2 : Embedding on the processed text data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZyIzW8AKo0d",
        "colab_type": "code",
        "outputId": "5bc4b75c-c1cb-4d49-9b1b-f3aee3ed1ed5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fd7b9c93254a4cfc9394d19ccb599b17",
            "249682b2413540138a5d8c123b47195f",
            "af9b553079e64805b671b2849841a9ac"
          ]
        }
      },
      "source": [
        "%time m1 = create_model(model='lda', multi_core=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd7b9c93254a4cfc9394d19ccb599b17",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "IntProgress(value=0, description='Processing: ', max=4)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Initiated</th>\n",
              "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
              "      <td>10:20:45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Status</th>\n",
              "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
              "      <td>Fitting Topic Model</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                   \n",
              "                                                                   \n",
              "Initiated  . . . . . . . . . . . . . . . . . .             10:20:45\n",
              "Status     . . . . . . . . . . . . . . . . . .  Fitting Topic Model"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Process ForkPoolWorker-2:\n",
            "Process ForkPoolWorker-4:\n",
            "Process ForkPoolWorker-1:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
            "    initializer(*initargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
            "    initializer(*initargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/gensim/models/ldamulticore.py\", line 330, in worker_e_step\n",
            "    chunk_no, chunk, worker_lda = input_queue.get()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/gensim/models/ldamulticore.py\", line 330, in worker_e_step\n",
            "    chunk_no, chunk, worker_lda = input_queue.get()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 94, in get\n",
            "    res = self._recv_bytes()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
            "    initializer(*initargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/gensim/models/ldamulticore.py\", line 330, in worker_e_step\n",
            "    chunk_no, chunk, worker_lda = input_queue.get()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
            "    buf = self._recv_bytes(maxlength)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
            "    with self._rlock:\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 411, in _recv_bytes\n",
            "    return self._recv(size)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
            "    chunk = read(handle, remaining)\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFull\u001b[0m                                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    287\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m                         \u001b[0mjob_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m                         \u001b[0mchunk_put\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mput\u001b[0;34m(self, obj, block, timeout)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFull\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFull\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-ac7f5d20e393>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"time m1 = create_model(model='lda', multi_core=True)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2079\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pycaret/nlp.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(model, multi_core, num_topics, verbose)\u001b[0m\n\u001b[1;32m    682\u001b[0m                                 \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m                                 \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'symmetric'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m                                 per_word_topics=True)\n\u001b[0m\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_every\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mgamma_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimum_probability\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_word_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_dir_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    297\u001b[0m                         \u001b[0;31m# in case the input job queue is full, keep clearing the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                         \u001b[0;31m# result queue, to make sure we don't deadlock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                         \u001b[0mprocess_result_queue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0mprocess_result_queue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mprocess_result_queue\u001b[0;34m(force)\u001b[0m\n\u001b[1;32m    271\u001b[0m                     \u001b[0mmerged_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmerged_new\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mqueue_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumdocs\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mupdateafter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpass_\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m                     \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_every\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mdo_mstep\u001b[0;34m(self, rho, other, extra_pass)\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_Elogbeta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0;31m# print out some debug info at the end of each EM iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36msync_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    591\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msync_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;34m\"\"\"Propagate the states topic probabilities to the inner object's attribute.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpElogbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_Elogbeta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpElogbeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mget_Elogbeta\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mPosterior\u001b[0m \u001b[0mprobabilities\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \"\"\"\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdirichlet_expectation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "Process ForkPoolWorker-5:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
            "    initializer(*initargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/gensim/models/ldamulticore.py\", line 330, in worker_e_step\n",
            "    chunk_no, chunk, worker_lda = input_queue.get()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 113, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "EOFError: Ran out of input\n",
            "Process ForkPoolWorker-7:\n",
            "Process ForkPoolWorker-3:\n",
            "Process ForkPoolWorker-6:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
            "    initializer(*initargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
            "    initializer(*initargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
            "    initializer(*initargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/gensim/models/ldamulticore.py\", line 330, in worker_e_step\n",
            "    chunk_no, chunk, worker_lda = input_queue.get()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/gensim/models/ldamulticore.py\", line 330, in worker_e_step\n",
            "    chunk_no, chunk, worker_lda = input_queue.get()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/gensim/models/ldamulticore.py\", line 330, in worker_e_step\n",
            "    chunk_no, chunk, worker_lda = input_queue.get()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 94, in get\n",
            "    res = self._recv_bytes()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
            "    buf = self._recv_bytes(maxlength)\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 411, in _recv_bytes\n",
            "    return self._recv(size)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
            "    chunk = read(handle, remaining)\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 261, in _bootstrap\n",
            "    util._exit_function()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 322, in _exit_function\n",
            "    _run_finalizers()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 262, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 186, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 191, in _finalize_join\n",
            "    thread.join()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1056, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1072, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3xzWhltLVM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%time lda_data = assign_model(m1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lu2652mLVKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hCQH4kxLVFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluate_model(m1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Dq3BEciLVCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%time m2 = create_model(model='nmf', multi_core=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuMeEAGWLdJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%time nmf_data = assign_model(m2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbsh1aNXLdHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEd-aNl1LdEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda_data.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekf82lOSLdA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda_data.drop(['review', 'Dominant_Topic', 'Perc_Dominant_Topic'], axis=1, inplace = True)\n",
        "lda_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3XUoABzLc-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNSbCPsCLc7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#NEw model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Bydn4TXVr5o",
        "colab_type": "code",
        "outputId": "4bc9d57e-aff5-4a68-bf84-328e639b35df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "df.groupby('Score').review.count().plot.bar(ylim=0)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl-1kS7IVzBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Text representation\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
        "features = tfidf.fit_transform(df.review).toarray()\n",
        "labels = df.Score\n",
        "features.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2qJ_mrpWo4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ydfqhx-ynjKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing libraries\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from sklearn.datasets import load_breast_cancer,load_boston,load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import mean_squared_error,roc_auc_score,precision_score\n",
        "pd.options.display.max_columns = 999"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SO5T9Q6njG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loading the dataset\n",
        "X1=load_wine()\n",
        "df_1=pd.DataFrame(X1.data,columns=X1.feature_names)\n",
        "Y_1=X1.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBIaL6jeni-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRZ-DlKKytYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Recommendation system kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76jHUwbmytUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import nltk\n",
        "\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn import neighbors\n",
        "from scipy.spatial.distance import cosine\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "\n",
        "import re\n",
        "import string\n",
        "from wordcloud import WordCloud, STOPWORDS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9Ef9YriytQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import data\n",
        "df = pd.read_csv(\"Reviews.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iQoPBmAytM1",
        "colab_type": "code",
        "outputId": "c2bace05-aa25-42c5-ed7a-6bb30e631eef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#Basic Information shape and columns\n",
        "print(df.columns)\n",
        "print(df.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
            "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
            "      dtype='object')\n",
            "(568454, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8QN2tXRytI1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. Product based collaborative filtering"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vA8WuxwytET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compute the count and mean value as group by the products\n",
        "count = df.groupby(\"ProductId\", as_index=False).count()\n",
        "mean = df.groupby(\"ProductId\", as_index=False).mean()\n",
        "\n",
        "#merge two dataset create df1\n",
        "df1 = pd.merge(df, count, how='right', on=['ProductId'])\n",
        "\n",
        "#rename column\n",
        "df1[\"Count\"] = df1[\"UserId_y\"]\n",
        "df1[\"Score\"] = df1[\"Score_x\"]\n",
        "df1[\"Summary\"] = df1[\"Summary_x\"]\n",
        "\n",
        "#Create New datafram with selected variables\n",
        "df1 = df1[['ProductId','Summary','Score',\"Count\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NXJ4TNlys_K",
        "colab_type": "code",
        "outputId": "12f1978c-eebb-4800-a2a7-a165be934e71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ProductId</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Score</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568449</th>\n",
              "      <td>B001EO7N10</td>\n",
              "      <td>Will not do without</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568450</th>\n",
              "      <td>B003S1WTCU</td>\n",
              "      <td>disappointed</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568451</th>\n",
              "      <td>B004I613EE</td>\n",
              "      <td>Perfect for our maltipoo</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568452</th>\n",
              "      <td>B004I613EE</td>\n",
              "      <td>Favorite Training and reward treat</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568453</th>\n",
              "      <td>B001LR2CU2</td>\n",
              "      <td>Great Honey</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>568454 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         ProductId                             Summary  Score  Count\n",
              "0       B001E4KFG0               Good Quality Dog Food      5      1\n",
              "1       B00813GRG4                   Not as Advertised      1      1\n",
              "2       B000LQOCH0               \"Delight\" says it all      4      1\n",
              "3       B000UA0QIQ                      Cough Medicine      2      1\n",
              "4       B006K2ZZ7K                         Great taffy      5      4\n",
              "...            ...                                 ...    ...    ...\n",
              "568449  B001EO7N10                 Will not do without      5      6\n",
              "568450  B003S1WTCU                        disappointed      2      1\n",
              "568451  B004I613EE            Perfect for our maltipoo      5      2\n",
              "568452  B004I613EE  Favorite Training and reward treat      5      2\n",
              "568453  B001LR2CU2                         Great Honey      5      1\n",
              "\n",
              "[568454 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Y9kJnk-HjCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#choose only products have over 100 reviews\n",
        "df1 = df1.sort_values(by=['Count'], ascending=False)\n",
        "df2 = df1[df1.Count >= 50]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY7vO0HxIDIm",
        "colab_type": "code",
        "outputId": "b8481611-572b-4ed3-c174-a35cc7658dc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ProductId</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Score</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>563881</th>\n",
              "      <td>B007JFMH8M</td>\n",
              "      <td>yummy</td>\n",
              "      <td>5</td>\n",
              "      <td>913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>563615</th>\n",
              "      <td>B007JFMH8M</td>\n",
              "      <td>Healthy and yummy too</td>\n",
              "      <td>5</td>\n",
              "      <td>913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>563629</th>\n",
              "      <td>B007JFMH8M</td>\n",
              "      <td>Soft and chewy but a bit too sweet!</td>\n",
              "      <td>4</td>\n",
              "      <td>913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>563628</th>\n",
              "      <td>B007JFMH8M</td>\n",
              "      <td>Pretty Good Cookie</td>\n",
              "      <td>4</td>\n",
              "      <td>913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>563627</th>\n",
              "      <td>B007JFMH8M</td>\n",
              "      <td>Good Taste and Flavor But a Little on the Dry ...</td>\n",
              "      <td>3</td>\n",
              "      <td>913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49196</th>\n",
              "      <td>B0015UX574</td>\n",
              "      <td>Wine gums are habit forming</td>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49197</th>\n",
              "      <td>B0015UX574</td>\n",
              "      <td>Danger: highly addictive</td>\n",
              "      <td>5</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49198</th>\n",
              "      <td>B0015UX574</td>\n",
              "      <td>Nice</td>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53985</th>\n",
              "      <td>B000EGZ2L2</td>\n",
              "      <td>Great !</td>\n",
              "      <td>5</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49185</th>\n",
              "      <td>B0015UX574</td>\n",
              "      <td>Classic Wine Gums</td>\n",
              "      <td>5</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>243111 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         ProductId  ... Count\n",
              "563881  B007JFMH8M  ...   913\n",
              "563615  B007JFMH8M  ...   913\n",
              "563629  B007JFMH8M  ...   913\n",
              "563628  B007JFMH8M  ...   913\n",
              "563627  B007JFMH8M  ...   913\n",
              "...            ...  ...   ...\n",
              "49196   B0015UX574  ...    50\n",
              "49197   B0015UX574  ...    50\n",
              "49198   B0015UX574  ...    50\n",
              "53985   B000EGZ2L2  ...    50\n",
              "49185   B0015UX574  ...    50\n",
              "\n",
              "[243111 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPhB7EvEIsxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create new dataframe as combining all summary with same product Id\n",
        "df4 = df.groupby(\"ProductId\", as_index=False).mean()\n",
        "combine_summary = df2.groupby(\"ProductId\")[\"Summary\"].apply(list)\n",
        "combine_summary = pd.DataFrame(combine_summary)\n",
        "combine_summary.to_csv(\"combine_summary.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hxywC6SJF5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create with certain columns\n",
        "df3 = pd.read_csv(\"combine_summary.csv\")\n",
        "df3 = pd.merge(df3, df4, on=\"ProductId\", how='inner')\n",
        "df3 = df3[['ProductId','Summary','Score']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUmpOiI9JJE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df3['Score_']=0\n",
        "df3['Score_']=df3.Score.round()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbfOK3lw2mn2",
        "colab_type": "code",
        "outputId": "66fce647-7e65-4aa1-fb84-8637f90718c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df3"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ProductId</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Score</th>\n",
              "      <th>Score_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7310172001</td>\n",
              "      <td>['The Only Treat My Dog Will Eat!', 'Great for...</td>\n",
              "      <td>4.751445</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7310172101</td>\n",
              "      <td>['very good', 'Dogs Love These!', 'Great for t...</td>\n",
              "      <td>4.751445</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B00004CI84</td>\n",
              "      <td>['Blueray:  Great movie.  Blue-Ray-Okay', 'Bee...</td>\n",
              "      <td>4.486772</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B00004CXX9</td>\n",
              "      <td>['Great Movie...But NOT Given DELUXE Treatment...</td>\n",
              "      <td>4.405128</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B00004RAMY</td>\n",
              "      <td>['It worked!', 'Finally, a trap that works', '...</td>\n",
              "      <td>4.104651</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1839</th>\n",
              "      <td>B009B87SAC</td>\n",
              "      <td>['Only food my cats can agree on', 'vomiting c...</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1840</th>\n",
              "      <td>B009E7YC54</td>\n",
              "      <td>['A wonderful product', 'I love PB2', 'LOVE', ...</td>\n",
              "      <td>4.642857</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1841</th>\n",
              "      <td>B009GHI5Q4</td>\n",
              "      <td>['Five stars and an Eight paw Salute', 'the on...</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1842</th>\n",
              "      <td>B009M2LUEW</td>\n",
              "      <td>['Great substitute for side', 'Yum', 'Zevia Ro...</td>\n",
              "      <td>4.159420</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1843</th>\n",
              "      <td>B009RB4GO4</td>\n",
              "      <td>['YUM!', 'Terrible! The cups were empty!', 'Au...</td>\n",
              "      <td>3.143426</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1844 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       ProductId  ... Score_\n",
              "0     7310172001  ...    5.0\n",
              "1     7310172101  ...    5.0\n",
              "2     B00004CI84  ...    4.0\n",
              "3     B00004CXX9  ...    4.0\n",
              "4     B00004RAMY  ...    4.0\n",
              "...          ...  ...    ...\n",
              "1839  B009B87SAC  ...    4.0\n",
              "1840  B009E7YC54  ...    5.0\n",
              "1841  B009GHI5Q4  ...    4.0\n",
              "1842  B009M2LUEW  ...    4.0\n",
              "1843  B009RB4GO4  ...    3.0\n",
              "\n",
              "[1844 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyln5gTL3Z5C",
        "colab_type": "code",
        "outputId": "3a1ede99-bced-4e9b-9071-ec252ee7ae9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "df3['Summary']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       ['The Only Treat My Dog Will Eat!', 'Great for...\n",
              "1       ['very good', 'Dogs Love These!', 'Great for t...\n",
              "2       ['Blueray:  Great movie.  Blue-Ray-Okay', 'Bee...\n",
              "3       ['Great Movie...But NOT Given DELUXE Treatment...\n",
              "4       ['It worked!', 'Finally, a trap that works', '...\n",
              "                              ...                        \n",
              "1839    ['Only food my cats can agree on', 'vomiting c...\n",
              "1840    ['A wonderful product', 'I love PB2', 'LOVE', ...\n",
              "1841    ['Five stars and an Eight paw Salute', 'the on...\n",
              "1842    ['Great substitute for side', 'Yum', 'Zevia Ro...\n",
              "1843    ['YUM!', 'Terrible! The cups were empty!', 'Au...\n",
              "Name: Summary, Length: 1844, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osGyvCjm2NbC",
        "colab_type": "code",
        "outputId": "349e651a-88e7-4698-e4c7-18461ed4af5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "df3.groupby('Score_').ProductId.count().plot.bar(ylim=0)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8fsLZJJJKIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1.a Text Clean process - Summary column"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBvUUQd2Jcn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function for tokenizing summary\n",
        "cleanup_re = re.compile('[^a-z]+')\n",
        "def cleanup(sentence):\n",
        "    sentence = sentence.lower()\n",
        "    sentence = cleanup_re.sub(' ', sentence).strip()\n",
        "    sentence = \" \".join(nltk.word_tokenize(sentence))\n",
        "    return sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPYuC0J9JnDr",
        "colab_type": "code",
        "outputId": "fa99b941-728c-4ca1-ea4b-b50a63e47905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw66ELu4JfcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reset index and drop duplicate rows\n",
        "df3[\"Summary_Clean\"] = df3[\"Summary\"].apply(cleanup)\n",
        "df3 = df3.drop_duplicates(['Score'], keep='last')\n",
        "df3 = df3.reset_index()\n",
        "from pandas import DataFrame \n",
        "\n",
        "docs = df3[\"Summary_Clean\"] \n",
        "vect = CountVectorizer(max_features = 100, stop_words='english') \n",
        "X = vect.fit_transform(docs) \n",
        "\n",
        "df5 = DataFrame(X.A, columns=vect.get_feature_names())\n",
        "df5 = df5.astype(int)\n",
        "#save \n",
        "df5.to_csv(\"df5.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_Vw0myx3r3U",
        "colab_type": "code",
        "outputId": "fa5a1819-b31e-47b6-ee70-5d82a295b1d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "df5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alternative</th>\n",
              "      <th>amazing</th>\n",
              "      <th>amazon</th>\n",
              "      <th>awesome</th>\n",
              "      <th>baby</th>\n",
              "      <th>bad</th>\n",
              "      <th>bar</th>\n",
              "      <th>bars</th>\n",
              "      <th>best</th>\n",
              "      <th>better</th>\n",
              "      <th>bold</th>\n",
              "      <th>bread</th>\n",
              "      <th>breakfast</th>\n",
              "      <th>butter</th>\n",
              "      <th>buy</th>\n",
              "      <th>cat</th>\n",
              "      <th>cats</th>\n",
              "      <th>cereal</th>\n",
              "      <th>chips</th>\n",
              "      <th>chocolate</th>\n",
              "      <th>coconut</th>\n",
              "      <th>coffee</th>\n",
              "      <th>cookie</th>\n",
              "      <th>cookies</th>\n",
              "      <th>cup</th>\n",
              "      <th>cups</th>\n",
              "      <th>dark</th>\n",
              "      <th>deal</th>\n",
              "      <th>delicious</th>\n",
              "      <th>does</th>\n",
              "      <th>dog</th>\n",
              "      <th>dogs</th>\n",
              "      <th>don</th>\n",
              "      <th>drink</th>\n",
              "      <th>easy</th>\n",
              "      <th>energy</th>\n",
              "      <th>excellent</th>\n",
              "      <th>fantastic</th>\n",
              "      <th>favorite</th>\n",
              "      <th>flavor</th>\n",
              "      <th>...</th>\n",
              "      <th>nice</th>\n",
              "      <th>oil</th>\n",
              "      <th>ok</th>\n",
              "      <th>okay</th>\n",
              "      <th>organic</th>\n",
              "      <th>packaging</th>\n",
              "      <th>peanut</th>\n",
              "      <th>perfect</th>\n",
              "      <th>popcorn</th>\n",
              "      <th>pretty</th>\n",
              "      <th>price</th>\n",
              "      <th>product</th>\n",
              "      <th>quality</th>\n",
              "      <th>real</th>\n",
              "      <th>really</th>\n",
              "      <th>smooth</th>\n",
              "      <th>snack</th>\n",
              "      <th>strong</th>\n",
              "      <th>stuff</th>\n",
              "      <th>sugar</th>\n",
              "      <th>sweet</th>\n",
              "      <th>taste</th>\n",
              "      <th>tastes</th>\n",
              "      <th>tasting</th>\n",
              "      <th>tasty</th>\n",
              "      <th>tea</th>\n",
              "      <th>time</th>\n",
              "      <th>treat</th>\n",
              "      <th>treats</th>\n",
              "      <th>use</th>\n",
              "      <th>value</th>\n",
              "      <th>vanilla</th>\n",
              "      <th>ve</th>\n",
              "      <th>water</th>\n",
              "      <th>way</th>\n",
              "      <th>wonderful</th>\n",
              "      <th>work</th>\n",
              "      <th>works</th>\n",
              "      <th>yum</th>\n",
              "      <th>yummy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>851</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>852</th>\n",
              "      <td>7</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>853</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>29</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>854</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>855</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>13</td>\n",
              "      <td>25</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>856 rows × 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     alternative  amazing  amazon  awesome  ...  work  works  yum  yummy\n",
              "0              0        0       1        6  ...     0      0    0      0\n",
              "1              0        0       0        3  ...     8     31    0      0\n",
              "2              0        0       0        0  ...     7     17    0      0\n",
              "3              0        0       1        6  ...     0      0    0      0\n",
              "4              0        1       0        0  ...     1      0    0      0\n",
              "..           ...      ...     ...      ...  ...   ...    ...  ...    ...\n",
              "851            2        0       0        1  ...     0      0    0      0\n",
              "852            7       20       2       11  ...     1      0    5      8\n",
              "853            0        0       0        0  ...     0      2    0      0\n",
              "854            3        1       0        2  ...     0      0    1      0\n",
              "855            2        1       0        2  ...     0      0    7      6\n",
              "\n",
              "[856 rows x 100 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPL84WHSJkw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First let's create a dataset called X\n",
        "X = np.array(df5)\n",
        " # create train and test\n",
        "tpercent = 0.9\n",
        "tsize = int(np.floor(tpercent * len(df5)))\n",
        "df5_train = X[:tsize]\n",
        "df5_test = X[tsize:]\n",
        "#len of train and test\n",
        "lentrain = len(df5_train)\n",
        "lentest = len(df5_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gFNsKjYJvHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1.b KNN classifier to find similar products\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTFot5OJJyO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Next we will instantiate a nearest neighbor object, and call it nbrs. Then we will fit it to dataset X.\n",
        "nbrs = NearestNeighbors(n_neighbors=3, algorithm='ball_tree').fit(df5_train)\n",
        "\n",
        "# Let's find the k-neighbors of each point in object X. To do that we call the kneighbors() function on object X.\n",
        "distances, indices = nbrs.kneighbors(df5_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCk1MEUfJ1NA",
        "colab_type": "code",
        "outputId": "7447416e-a0a3-4da1-e3f5-62962f4c045d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(lentest):\n",
        "    a = nbrs.kneighbors([df5_test[i]])\n",
        "    related_product_list = a[1]\n",
        "    \n",
        "    first_related_product = [item[0] for item in related_product_list]\n",
        "    first_related_product = str(first_related_product).strip('[]')\n",
        "    first_related_product = int(first_related_product)\n",
        "    second_related_product = [item[1] for item in related_product_list]\n",
        "    second_related_product = str(second_related_product).strip('[]')\n",
        "    second_related_product = int(second_related_product)\n",
        "    \n",
        "    print (\"Based on product reviews, for \", df3[\"ProductId\"][lentrain + i] ,\" and this average Score is \",df3[\"Score\"][lentrain + i])\n",
        "    print (\"The first similar product is \", df3[\"ProductId\"][first_related_product] ,\" and this average Score is \",df3[\"Score\"][first_related_product])\n",
        "    print (\"The second similar product is \", df3[\"ProductId\"][second_related_product] ,\" and this average Score is \",df3[\"Score\"][second_related_product])\n",
        "    print (\"-----------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Based on product reviews, for  B007OXJK3Y  and this average Score is  3.5660377358490565\n",
            "The first similar product is  B007OXJJQ2  and this average Score is  4.44\n",
            "The second similar product is  B002QGK2V8  and this average Score is  3.4484848484848483\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007OXJKF2  and this average Score is  3.576923076923077\n",
            "The first similar product is  B007OXJJQ2  and this average Score is  4.44\n",
            "The second similar product is  B004I3Y4IE  and this average Score is  4.317073170731708\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007OXJL0G  and this average Score is  4.139344262295082\n",
            "The first similar product is  B004IRGD3O  and this average Score is  4.1688311688311686\n",
            "The second similar product is  B007OXJJQ2  and this average Score is  4.44\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007PA30ZU  and this average Score is  4.4907063197026025\n",
            "The first similar product is  B0001ES9FI  and this average Score is  4.410891089108911\n",
            "The second similar product is  B0029XDZDK  and this average Score is  4.14207650273224\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007PA32L2  and this average Score is  3.9681274900398407\n",
            "The first similar product is  B002QGK2V8  and this average Score is  3.4484848484848483\n",
            "The second similar product is  B005GXHKSG  and this average Score is  4.40625\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007PA33NY  and this average Score is  4.205980066445183\n",
            "The first similar product is  B001D0GV90  and this average Score is  4.437837837837838\n",
            "The second similar product is  B0045IO37Y  and this average Score is  4.054054054054054\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007PE7ANY  and this average Score is  4.401234567901234\n",
            "The first similar product is  B00503DP0O  and this average Score is  4.079646017699115\n",
            "The second similar product is  B00503DOWS  and this average Score is  4.069306930693069\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007POT6RM  and this average Score is  3.692982456140351\n",
            "The first similar product is  B000FFIEL2  and this average Score is  4.189473684210526\n",
            "The second similar product is  B003LECIDE  and this average Score is  4.811320754716981\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007R1PGVS  and this average Score is  4.342465753424658\n",
            "The first similar product is  B001BBXP7M  and this average Score is  3.7261904761904763\n",
            "The second similar product is  B0021L9XK4  and this average Score is  3.8\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007R900WA  and this average Score is  4.823529411764706\n",
            "The first similar product is  B005HGAV8I  and this average Score is  3.7651821862348176\n",
            "The second similar product is  B005PXZ6JM  and this average Score is  4.4113924050632916\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007RLRCLK  and this average Score is  4.251461988304094\n",
            "The first similar product is  B000CQIDJM  and this average Score is  3.966386554621849\n",
            "The second similar product is  B006N08SPA  and this average Score is  4.1976744186046515\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007RTR898  and this average Score is  3.548076923076923\n",
            "The first similar product is  B007K449CE  and this average Score is  4.175257731958763\n",
            "The second similar product is  B007JT7ARQ  and this average Score is  4.481481481481482\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007RTR89S  and this average Score is  3.8613861386138613\n",
            "The first similar product is  B007K449CE  and this average Score is  4.175257731958763\n",
            "The second similar product is  B007JT7AEY  and this average Score is  4.309523809523809\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007RTR8A2  and this average Score is  4.183673469387755\n",
            "The first similar product is  B007K449CE  and this average Score is  4.175257731958763\n",
            "The second similar product is  B007JT7AIA  and this average Score is  4.172043010752688\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007RTR8AC  and this average Score is  3.968421052631579\n",
            "The first similar product is  B007K449CE  and this average Score is  4.175257731958763\n",
            "The second similar product is  B007JT7AIA  and this average Score is  4.172043010752688\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007RTR8AM  and this average Score is  3.8214285714285716\n",
            "The first similar product is  B007K449CE  and this average Score is  4.175257731958763\n",
            "The second similar product is  B001XSMANI  and this average Score is  4.160714285714286\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007RTR8T8  and this average Score is  4.1313131313131315\n",
            "The first similar product is  B007JT7AIA  and this average Score is  4.172043010752688\n",
            "The second similar product is  B007JT7AEY  and this average Score is  4.309523809523809\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007RTR8TS  and this average Score is  4.021505376344086\n",
            "The first similar product is  B007K449CE  and this average Score is  4.175257731958763\n",
            "The second similar product is  B0078EZHZE  and this average Score is  4.616438356164384\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007RTR8UC  and this average Score is  4.031578947368421\n",
            "The first similar product is  B007K449CE  and this average Score is  4.175257731958763\n",
            "The second similar product is  B007JT7AIA  and this average Score is  4.172043010752688\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007RTR8UM  and this average Score is  4.065934065934066\n",
            "The first similar product is  B007K449CE  and this average Score is  4.175257731958763\n",
            "The second similar product is  B007JT7AEY  and this average Score is  4.309523809523809\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007RTR8UW  and this average Score is  3.847826086956522\n",
            "The first similar product is  B007K449CE  and this average Score is  4.175257731958763\n",
            "The second similar product is  B007JT7AIA  and this average Score is  4.172043010752688\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007RTR9DS  and this average Score is  2.7795698924731185\n",
            "The first similar product is  B007K449CE  and this average Score is  4.175257731958763\n",
            "The second similar product is  B007JT7AIA  and this average Score is  4.172043010752688\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007RTR9E2  and this average Score is  3.86734693877551\n",
            "The first similar product is  B007K449CE  and this average Score is  4.175257731958763\n",
            "The second similar product is  B007JT7AEY  and this average Score is  4.309523809523809\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007RTR9FQ  and this average Score is  4.197916666666667\n",
            "The first similar product is  B007K449CE  and this average Score is  4.175257731958763\n",
            "The second similar product is  B007JT7AIA  and this average Score is  4.172043010752688\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007RTR9G0  and this average Score is  3.043010752688172\n",
            "The first similar product is  B007K449CE  and this average Score is  4.175257731958763\n",
            "The second similar product is  B002VLZ8D0  and this average Score is  4.730769230769231\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007TGDXMK  and this average Score is  4.143540669856459\n",
            "The first similar product is  B005ZBZLPI  and this average Score is  4.0\n",
            "The second similar product is  B00451WLYI  and this average Score is  4.517647058823529\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007TGDXMU  and this average Score is  4.517006802721088\n",
            "The first similar product is  B005ZBZLPI  and this average Score is  4.0\n",
            "The second similar product is  B000SDKDM4  and this average Score is  4.08252427184466\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007TGDXNO  and this average Score is  4.3478260869565215\n",
            "The first similar product is  B00451WLYI  and this average Score is  4.517647058823529\n",
            "The second similar product is  B002AQ0OL2  and this average Score is  4.058035714285714\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007TGO1U8  and this average Score is  3.532258064516129\n",
            "The first similar product is  B0054I4LTO  and this average Score is  4.298245614035087\n",
            "The second similar product is  B004OQ257M  and this average Score is  3.980769230769231\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007TJGY5K  and this average Score is  4.119496855345912\n",
            "The first similar product is  B007L3NVKU  and this average Score is  4.355072463768116\n",
            "The second similar product is  B0027Z8VES  and this average Score is  4.341269841269841\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007TJGZ0Y  and this average Score is  4.384615384615385\n",
            "The first similar product is  B001CHJ01A  and this average Score is  4.364485981308412\n",
            "The second similar product is  B002QGK2V8  and this average Score is  3.4484848484848483\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007TJGZ54  and this average Score is  4.243801652892562\n",
            "The first similar product is  B006N3I29E  and this average Score is  4.245689655172414\n",
            "The second similar product is  B002AQ0OL2  and this average Score is  4.058035714285714\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B007TJGZ5E  and this average Score is  4.412790697674419\n",
            "The first similar product is  B005GXHKSG  and this average Score is  4.40625\n",
            "The second similar product is  B001E50THY  and this average Score is  4.044642857142857\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B008114GDW  and this average Score is  4.435483870967742\n",
            "The first similar product is  B003P02EGU  and this average Score is  4.269230769230769\n",
            "The second similar product is  B007GYQ6LA  and this average Score is  3.8208955223880596\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B0081X097M  and this average Score is  4.766990291262136\n",
            "The first similar product is  B005XPKYUI  and this average Score is  4.670588235294118\n",
            "The second similar product is  B00507A02Q  and this average Score is  2.8412698412698414\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B0081XIAUK  and this average Score is  3.549618320610687\n",
            "The first similar product is  B0009XSXZM  and this average Score is  3.7610619469026547\n",
            "The second similar product is  B0012Y0HA6  and this average Score is  3.9393939393939394\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B0081XPTBS  and this average Score is  4.181518151815181\n",
            "The first similar product is  B0032CJPOK  and this average Score is  4.184210526315789\n",
            "The second similar product is  B005PXZ6JM  and this average Score is  4.4113924050632916\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B0083QJU72  and this average Score is  4.696969696969697\n",
            "The first similar product is  B000VK08OC  and this average Score is  4.491379310344827\n",
            "The second similar product is  B005P0NLJ2  and this average Score is  4.445255474452555\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B0083QJUL8  and this average Score is  4.415094339622642\n",
            "The first similar product is  B000E7QYNG  and this average Score is  4.339622641509434\n",
            "The second similar product is  B001EQ4HVC  and this average Score is  4.2631578947368425\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B0083T5TAQ  and this average Score is  3.0454545454545454\n",
            "The first similar product is  B005HGAV8I  and this average Score is  3.7651821862348176\n",
            "The second similar product is  B005HUVI40  and this average Score is  3.9917355371900825\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B0083T6HC0  and this average Score is  3.6123348017621146\n",
            "The first similar product is  B005HGAV8I  and this average Score is  3.7651821862348176\n",
            "The second similar product is  B000KSPX7C  and this average Score is  4.140625\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B0085E7B8W  and this average Score is  4.323529411764706\n",
            "The first similar product is  B0007XPS98  and this average Score is  4.803921568627451\n",
            "The second similar product is  B000GFYRJE  and this average Score is  4.607843137254902\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B0085MLY5A  and this average Score is  2.4390243902439024\n",
            "The first similar product is  B001LUM1ZU  and this average Score is  3.4473684210526314\n",
            "The second similar product is  B000LL0R92  and this average Score is  3.3\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B0085YB4DU  and this average Score is  4.23404255319149\n",
            "The first similar product is  B001EQ5ERI  and this average Score is  4.215686274509804\n",
            "The second similar product is  B0002E2GQU  and this average Score is  3.7288135593220337\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B00866AM2G  and this average Score is  3.6621621621621623\n",
            "The first similar product is  B001VDXO3K  and this average Score is  3.7916666666666665\n",
            "The second similar product is  B002Z04ZNQ  and this average Score is  4.114942528735632\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B0089SPDUW  and this average Score is  4.550724637681159\n",
            "The first similar product is  B007OSBEV0  and this average Score is  4.051724137931035\n",
            "The second similar product is  B001CHH3QY  and this average Score is  3.9661016949152543\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B0089SPENI  and this average Score is  4.181034482758621\n",
            "The first similar product is  B000CQIDJM  and this average Score is  3.966386554621849\n",
            "The second similar product is  B003CK7MME  and this average Score is  4.445544554455446\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B0089SPEO2  and this average Score is  4.5\n",
            "The first similar product is  B000GFYRJE  and this average Score is  4.607843137254902\n",
            "The second similar product is  B006N3I8PC  and this average Score is  4.238095238095238\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B008ATDIDE  and this average Score is  3.8859649122807016\n",
            "The first similar product is  B001E5E060  and this average Score is  4.297297297297297\n",
            "The second similar product is  B006W5WAL4  and this average Score is  4.1558441558441555\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B008AV5HLS  and this average Score is  4.697368421052632\n",
            "The first similar product is  B0002PSOJW  and this average Score is  4.753846153846154\n",
            "The second similar product is  B004HCBKJ2  and this average Score is  4.410714285714286\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B008BLFFAK  and this average Score is  4.203703703703703\n",
            "The first similar product is  B001E5E08S  and this average Score is  3.9682539682539684\n",
            "The second similar product is  B001EQ5KHC  and this average Score is  4.392857142857143\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B008BLFJXI  and this average Score is  4.080645161290323\n",
            "The first similar product is  B000E123IC  and this average Score is  3.48\n",
            "The second similar product is  B001EQ5KHC  and this average Score is  4.392857142857143\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B008CTBK7S  and this average Score is  4.455696202531645\n",
            "The first similar product is  B001E4S8GO  and this average Score is  4.235294117647059\n",
            "The second similar product is  B002OK6E6I  and this average Score is  4.693333333333333\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B008EG58V8  and this average Score is  3.90625\n",
            "The first similar product is  B006BXUZVO  and this average Score is  4.224719101123595\n",
            "The second similar product is  B006BXV14E  and this average Score is  4.011111111111111\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B008EG5ADY  and this average Score is  4.314285714285714\n",
            "The first similar product is  B001E5E060  and this average Score is  4.297297297297297\n",
            "The second similar product is  B001EO5RFE  and this average Score is  4.4393939393939394\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B008EM51FA  and this average Score is  4.476923076923077\n",
            "The first similar product is  B001E5E3LW  and this average Score is  3.8846153846153846\n",
            "The second similar product is  B005P0NA7U  and this average Score is  4.202702702702703\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B008FHUCNU  and this average Score is  4.3931623931623935\n",
            "The first similar product is  B005HUVI40  and this average Score is  3.9917355371900825\n",
            "The second similar product is  B002QGK2V8  and this average Score is  3.4484848484848483\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B008FHUDW0  and this average Score is  4.3515625\n",
            "The first similar product is  B005HUVI40  and this average Score is  3.9917355371900825\n",
            "The second similar product is  B000UBH9YE  and this average Score is  4.347368421052631\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B008FHUFAU  and this average Score is  4.314465408805032\n",
            "The first similar product is  B001D0GV90  and this average Score is  4.437837837837838\n",
            "The second similar product is  B0045IO37Y  and this average Score is  4.054054054054054\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B008FHUGNQ  and this average Score is  4.258205689277899\n",
            "The first similar product is  B006N3IG4K  and this average Score is  3.934065934065934\n",
            "The second similar product is  B005VOONM6  and this average Score is  3.8472222222222223\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B008FHUKE6  and this average Score is  4.188976377952756\n",
            "The first similar product is  B005ZBZLPI  and this average Score is  4.0\n",
            "The second similar product is  B0001ES9F8  and this average Score is  4.302083333333333\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B008FHUS3O  and this average Score is  4.420289855072464\n",
            "The first similar product is  B001ELL68Y  and this average Score is  4.2388059701492535\n",
            "The second similar product is  B007OSBEV0  and this average Score is  4.051724137931035\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B008GRIB0A  and this average Score is  3.88953488372093\n",
            "The first similar product is  B002QGK2V8  and this average Score is  3.4484848484848483\n",
            "The second similar product is  B005HUVI40  and this average Score is  3.9917355371900825\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B008GRONV6  and this average Score is  4.598540145985401\n",
            "The first similar product is  B001P3PR54  and this average Score is  4.527272727272727\n",
            "The second similar product is  B001P3NU30  and this average Score is  4.138297872340425\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B008I1XPKA  and this average Score is  3.7152317880794703\n",
            "The first similar product is  B005HUVI40  and this average Score is  3.9917355371900825\n",
            "The second similar product is  B0000V8IOE  and this average Score is  3.9274193548387095\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B008J1HO4C  and this average Score is  4.682584269662922\n",
            "The first similar product is  B000EVOSE4  and this average Score is  4.414110429447852\n",
            "The second similar product is  B000H7LVKY  and this average Score is  4.55625\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B008JKU2CO  and this average Score is  4.361038961038961\n",
            "The first similar product is  B0034EFIYC  and this average Score is  4.4879518072289155\n",
            "The second similar product is  B004GW6O9E  and this average Score is  4.410852713178294\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B008K9TJDM  and this average Score is  4.4523809523809526\n",
            "The first similar product is  B007OSBEV0  and this average Score is  4.051724137931035\n",
            "The second similar product is  B001E530IE  and this average Score is  4.56\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B008K9TQPS  and this average Score is  4.203389830508475\n",
            "The first similar product is  B006N3I79Y  and this average Score is  4.409836065573771\n",
            "The second similar product is  B001D0IZBW  and this average Score is  4.132352941176471\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B008O3G2K2  and this average Score is  3.5060240963855422\n",
            "The first similar product is  B001P3NU44  and this average Score is  4.1652892561983474\n",
            "The second similar product is  B001Q9EFW8  and this average Score is  3.908256880733945\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B008RWUKXK  and this average Score is  4.15593220338983\n",
            "The first similar product is  B004BKLHOS  and this average Score is  4.274834437086093\n",
            "The second similar product is  B003XDH6M6  and this average Score is  4.023489932885906\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B008YA1DZE  and this average Score is  3.925925925925926\n",
            "The first similar product is  B001D0KG5K  and this average Score is  3.262295081967213\n",
            "The second similar product is  B001D0IZBW  and this average Score is  4.132352941176471\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B008YA1LQK  and this average Score is  4.363636363636363\n",
            "The first similar product is  B001D0KG5K  and this average Score is  3.262295081967213\n",
            "The second similar product is  B004GWSWCQ  and this average Score is  4.253968253968254\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B008YA1NWC  and this average Score is  4.458064516129032\n",
            "The first similar product is  B001CHJ01A  and this average Score is  4.364485981308412\n",
            "The second similar product is  B002QGK2V8  and this average Score is  3.4484848484848483\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B008ZRKZSM  and this average Score is  4.467741935483871\n",
            "The first similar product is  B001E4S8GO  and this average Score is  4.235294117647059\n",
            "The second similar product is  B002OK6E6I  and this average Score is  4.693333333333333\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B0090X8IPM  and this average Score is  3.8132075471698115\n",
            "The first similar product is  B005VOONM6  and this average Score is  3.8472222222222223\n",
            "The second similar product is  B006N3IG4K  and this average Score is  3.934065934065934\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B00954NYVY  and this average Score is  4.561797752808989\n",
            "The first similar product is  B001D0GV90  and this average Score is  4.437837837837838\n",
            "The second similar product is  B002AQ0OS0  and this average Score is  3.911392405063291\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B0095KATS4  and this average Score is  3.566666666666667\n",
            "The first similar product is  B002OMV09W  and this average Score is  2.896551724137931\n",
            "The second similar product is  B001O17I36  and this average Score is  3.3773584905660377\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B0096EZHM2  and this average Score is  4.317460317460317\n",
            "The first similar product is  B002C1Y150  and this average Score is  4.092592592592593\n",
            "The second similar product is  B0010B6IFY  and this average Score is  4.241379310344827\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B0098WV8F2  and this average Score is  4.390697674418605\n",
            "The first similar product is  B001E4S8GO  and this average Score is  4.235294117647059\n",
            "The second similar product is  B002OK6E6I  and this average Score is  4.693333333333333\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B009AFH6Y4  and this average Score is  3.74\n",
            "The first similar product is  B0044MTGHI  and this average Score is  4.88\n",
            "The second similar product is  B0030HSFW0  and this average Score is  4.266666666666667\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B009AFJ3I6  and this average Score is  4.508474576271187\n",
            "The first similar product is  B0025UC2DQ  and this average Score is  4.105263157894737\n",
            "The second similar product is  B000FL521G  and this average Score is  4.649122807017544\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B009E7YC54  and this average Score is  4.642857142857143\n",
            "The first similar product is  B001E4S8GO  and this average Score is  4.235294117647059\n",
            "The second similar product is  B002OK6E6I  and this average Score is  4.693333333333333\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B009GHI5Q4  and this average Score is  3.6\n",
            "The first similar product is  B001GVIUXQ  and this average Score is  4.079365079365079\n",
            "The second similar product is  B002C1Y150  and this average Score is  4.092592592592593\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B009M2LUEW  and this average Score is  4.159420289855072\n",
            "The first similar product is  B001EO5RF4  and this average Score is  4.350877192982456\n",
            "The second similar product is  B005YYFHCS  and this average Score is  3.3529411764705883\n",
            "-----------------------------------------------------------\n",
            "Based on product reviews, for  B009RB4GO4  and this average Score is  3.143426294820717\n",
            "The first similar product is  B005A1LGIY  and this average Score is  3.9731182795698925\n",
            "The second similar product is  B000EVQWKC  and this average Score is  2.8803418803418803\n",
            "-----------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poK-rGhQJ42G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1.c Predicting Review Score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nJZsCXpKCUV",
        "colab_type": "code",
        "outputId": "b609c851-fc68-44b2-9b79-de1641741a51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "df5_train_target = df3[\"Score\"][:lentrain]\n",
        "df5_test_target = df3[\"Score\"][lentrain:lentrain+lentest]\n",
        "df5_train_target = df5_train_target.astype(int)\n",
        "df5_test_target = df5_test_target.astype(int)\n",
        "\n",
        "n_neighbors = 3\n",
        "knnclf = neighbors.KNeighborsClassifier(n_neighbors, weights='distance')\n",
        "knnclf.fit(df5_train, df5_train_target)\n",
        "knnpreds_test = knnclf.predict(df5_test)\n",
        "print (knnpreds_test)\n",
        "\n",
        "print(classification_report(df5_test_target, knnpreds_test))\n",
        "print (accuracy_score(df5_test_target, knnpreds_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3 4 4 4 4 4 4 4 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 4 3 4 4 3 4 3 4\n",
            " 4 4 3 4 4 3 4 3 4 4 4 4 4 3 3 4 4 4 4 3 4 4 3 4 4 3 4 3 4 4 4 4 4 4 4 4 4\n",
            " 4 3 4 2 4 4 4 4 4 4 4 3]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         2\n",
            "           3       0.53      0.33      0.41        27\n",
            "           4       0.74      0.88      0.80        57\n",
            "\n",
            "    accuracy                           0.69        86\n",
            "   macro avg       0.42      0.40      0.40        86\n",
            "weighted avg       0.65      0.69      0.66        86\n",
            "\n",
            "0.686046511627907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KpAqrVfKFmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2. User based collaborative filtering"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aj1Kjo038M2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count = df.groupby(\"UserId\", as_index=False).count()\n",
        "mean = df.groupby(\"UserId\", as_index=False).mean()\n",
        "\n",
        "#merge two dataset create df1\n",
        "df1 = pd.merge(df, count, how='right', on=[\"UserId\"])\n",
        "#rename column\n",
        "df1[\"Count\"] = df1[\"ProductId_y\"]\n",
        "df1[\"Score\"] = df1[\"Score_x\"]\n",
        "df1[\"Summary\"] = df1[\"Summary_x\"]\n",
        "\n",
        "#Create New datafram with selected variables\n",
        "df1 = df1[[\"UserId\",'Summary','Score',\"Count\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8VMXCjh3_Dm",
        "colab_type": "code",
        "outputId": "2b0018b4-8944-4b44-9573-129da3aa9b6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserId</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Score</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Fast, Easy and organic</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Awesome service and great products</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568449</th>\n",
              "      <td>A2SD7TY3IOX69B</td>\n",
              "      <td>Best Value for Chinese 5 Spice</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568450</th>\n",
              "      <td>A2P9W8T7NTLG2Z</td>\n",
              "      <td>Mixed wrong</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568451</th>\n",
              "      <td>A28KG5XORO54AY</td>\n",
              "      <td>Will not do without</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568452</th>\n",
              "      <td>A121AA1GQV751Z</td>\n",
              "      <td>Perfect for our maltipoo</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568453</th>\n",
              "      <td>A3LGQPJCZVL9UC</td>\n",
              "      <td>Great Honey</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>568454 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                UserId                             Summary  Score  Count\n",
              "0       A3SGXH7AUHU8GW               Good Quality Dog Food      5      1\n",
              "1       A1D87F6ZCVE5NK                   Not as Advertised      1      1\n",
              "2        ABXLMWJIXXAIN               \"Delight\" says it all      4      3\n",
              "3        ABXLMWJIXXAIN              Fast, Easy and organic      4      3\n",
              "4        ABXLMWJIXXAIN  Awesome service and great products      5      3\n",
              "...                ...                                 ...    ...    ...\n",
              "568449  A2SD7TY3IOX69B      Best Value for Chinese 5 Spice      5      1\n",
              "568450  A2P9W8T7NTLG2Z                         Mixed wrong      2      1\n",
              "568451  A28KG5XORO54AY                 Will not do without      5      1\n",
              "568452  A121AA1GQV751Z            Perfect for our maltipoo      5      1\n",
              "568453  A3LGQPJCZVL9UC                         Great Honey      5      1\n",
              "\n",
              "[568454 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT2oFTXk4Ax_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#choose only products have over 100 reviews\n",
        "df1 = df1.sort_values(by=['Count'], ascending=False)\n",
        "df2 = df1[df1.Count >=50]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrECr87r4Fuc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4 = df.groupby(\"UserId\", as_index=False).mean()\n",
        "combine_summary = df2.groupby(\"UserId\")[\"Summary\"].apply(list)\n",
        "combine_summary = pd.DataFrame(combine_summary)\n",
        "combine_summary.to_csv(\"combine_summary.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gymkOTnA4aC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df3 = pd.read_csv(\"combine_summary.csv\")\n",
        "df3 = pd.merge(df3, df4, on=\"UserId\", how='inner')\n",
        "df3 = df3[['UserId','Summary','Score']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08bv4NFb4d8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df3[\"Summary_Clean\"] = df3[\"Summary\"].apply(cleanup)\n",
        "df3 = df3.drop_duplicates(['Score'], keep='last')\n",
        "df3 = df3.reset_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf_tNoTs4hHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pandas import DataFrame \n",
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "docs = df3[\"Summary_Clean\"] \n",
        "vect = CountVectorizer(max_features = 100, stop_words='english') \n",
        "X = vect.fit_transform(docs) \n",
        "#print(DataFrame(X.A, columns=vect.get_feature_names()).to_string()) \n",
        "df5 = DataFrame(X.A, columns=vect.get_feature_names())\n",
        "df5 = df5.astype(int)\n",
        "df5.to_csv(\"df5.csv\")\n",
        "kkk  = df.drop_duplicates(['Summary'], keep='last')\n",
        "kkk = kkk.reset_index()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O5Gby-14j0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2.b KNN classifier to find similar user and find their interesting products\n",
        "# First let's create a dataset called X, with 6 records and 2 features each.\n",
        "X = np.array(df5)\n",
        "\n",
        "tpercent = 0.95\n",
        "tsize = int(np.floor(tpercent * len(df5)))\n",
        "df5_train = X[:tsize]\n",
        "df5_test = X[tsize:]\n",
        "\n",
        "lentrain = len(df5_train)\n",
        "lentest = len(df5_test)\n",
        "\n",
        "# Next we will instantiate a nearest neighbor object, and call it nbrs. Then we will fit it to dataset X.\n",
        "nbrs = NearestNeighbors(n_neighbors=3, algorithm='ball_tree').fit(df5_train)\n",
        "\n",
        "# Let's find the k-neighbors of each point in object X. To do that we call the kneighbors() function on object X.\n",
        "distances, indices = nbrs.kneighbors(df5_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKPKXb2Z4pEn",
        "colab_type": "code",
        "outputId": "82aeca86-913c-4f93-9a2b-f33aac76d6c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#finding similar user and intereting products\n",
        "for i in range(lentest):\n",
        "    a = nbrs.kneighbors([df5_test[i]])\n",
        "    related_product_list = a[1]\n",
        "    \n",
        "    first_related_product = [item[0] for item in related_product_list]\n",
        "    first_related_product = str(first_related_product).strip('[]')\n",
        "    first_related_product = int(first_related_product)\n",
        "    second_related_product = [item[1] for item in related_product_list]\n",
        "    second_related_product = str(second_related_product).strip('[]')\n",
        "    second_related_product = int(second_related_product)\n",
        "    \n",
        "    print (\"Based on  reviews, for user is \", df3[\"UserId\"][lentrain + i])\n",
        "    print (\"The first similar user is \", df3[\"UserId\"][first_related_product], \".\") \n",
        "    print (\"He/She likes following products\")\n",
        "    for i in range(295743):\n",
        "        if (kkk[\"UserId\"][i] == df3[\"UserId\"][first_related_product]) & (kkk[\"Score\"][i] == 5):\n",
        "            aaa= kkk[\"ProductId\"][i]\n",
        "        \n",
        "            print (aaa),\n",
        "    print (\"--------------------------------------------------------------------\")\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Based on  reviews, for user is  AR7TAEEUDHMUB\n",
            "The first similar user is  ALL9XFM0Q1N4E .\n",
            "He/She likes following products\n",
            "B001SITZFY\n",
            "B001IZEJ76\n",
            "B0009VZP6Y\n",
            "B001E52Z58\n",
            "B005Y111BW\n",
            "B004DBTSMI\n",
            "B001E5DWW8\n",
            "B000EVT08S\n",
            "B000SARHDK\n",
            "B006VC0ZYM\n",
            "B002P1K1C4\n",
            "B0045XB47Q\n",
            "B002Q7U94W\n",
            "B00142I7BM\n",
            "B000MTM0WK\n",
            "B000F9XBIE\n",
            "B001FSK3SU\n",
            "B006HYLW32\n",
            "B002KXY8VM\n",
            "--------------------------------------------------------------------\n",
            "Based on  reviews, for user is  ARYSDAZNRXN6G\n",
            "The first similar user is  A3NHUQ33CFH3VM .\n",
            "He/She likes following products\n",
            "B0041NYV8E\n",
            "B002IEZJMA\n",
            "B000ER3FD8\n",
            "B001O2F5XA\n",
            "B000BBY7ZC\n",
            "B004051BLS\n",
            "B000H7LVKY\n",
            "B001KWEZTO\n",
            "B000KNB0OW\n",
            "B001E5E10K\n",
            "B000BBY7XY\n",
            "B00622CYTK\n",
            "B001GBEFYO\n",
            "B001VNGK6I\n",
            "B000ER6YGI\n",
            "B001VNGMPM\n",
            "B001EO5Q14\n",
            "--------------------------------------------------------------------\n",
            "Based on  reviews, for user is  AT9U5ZE5OO84C\n",
            "The first similar user is  AJB5P7GVR0MT8 .\n",
            "He/She likes following products\n",
            "B0017I753O\n",
            "B002EE5G72\n",
            "B001PICXJC\n",
            "B0036R7HGE\n",
            "B0047UOVN6\n",
            "B00016XLWC\n",
            "B00282YCMA\n",
            "B001EO5U3I\n",
            "--------------------------------------------------------------------\n",
            "Based on  reviews, for user is  ATJN4KEHJBOC8\n",
            "The first similar user is  A1I85Y08VRZ32Q .\n",
            "He/She likes following products\n",
            "B001RVFDOO\n",
            "B0029O0XGQ\n",
            "B0061W1L4K\n",
            "B000LDRWWU\n",
            "B0041L3MAE\n",
            "B002WWRLP6\n",
            "B001EPR0US\n",
            "B005GIF5WY\n",
            "B005GIF5WY\n",
            "B0018CJZJQ\n",
            "B004LOIEVS\n",
            "B001E52YO0\n",
            "B000LTLJU0\n",
            "B00009ZJ48\n",
            "B000XEAWNS\n",
            "--------------------------------------------------------------------\n",
            "Based on  reviews, for user is  AVFA1JB08RG8G\n",
            "The first similar user is  AF3BYMPWKWO8F .\n",
            "He/She likes following products\n",
            "B0009ETA6W\n",
            "--------------------------------------------------------------------\n",
            "Based on  reviews, for user is  AWKZAUC0D8DYL\n",
            "The first similar user is  A1WE8KTC20NY65 .\n",
            "He/She likes following products\n",
            "B00451U9Q0\n",
            "B004OA5XUE\n",
            "B000RMTOVW\n",
            "B0019MYXXI\n",
            "B000X21LT4\n",
            "B0018CFNFG\n",
            "B001IZ866Q\n",
            "B003XBBAUM\n",
            "B000PKL5WC\n",
            "B000M72L80\n",
            "B000633UO4\n",
            "B004PX9JQ4\n",
            "B000GT3HPK\n",
            "B001CD7AUC\n",
            "B002FYW4D0\n",
            "--------------------------------------------------------------------\n",
            "Based on  reviews, for user is  AXO4PQU0XG3TG\n",
            "The first similar user is  A3UCN2RGY7O6S1 .\n",
            "He/She likes following products\n",
            "B004ASGJ5S\n",
            "B0017WFN98\n",
            "B001GVIS6K\n",
            "B004HGMBHS\n",
            "B0012AOJ0O\n",
            "B000E7UJJ6\n",
            "B0002NYOJ8\n",
            "B003118SAE\n",
            "B000HQRCCG\n",
            "B001BZ7N1M\n",
            "B000R8ZYLK\n",
            "B001EPPC8K\n",
            "B001P22GHC\n",
            "B0017WE01K\n",
            "B001QXYZ4M\n",
            "B000BTD0PC\n",
            "B003LVW23I\n",
            "B00501TR9O\n",
            "B005YD2SDA\n",
            "B003S6ONQA\n",
            "B006VRTQZG\n",
            "B004I41J8G\n",
            "--------------------------------------------------------------------\n",
            "Based on  reviews, for user is  AY12DBB0U420B\n",
            "The first similar user is  A3FKGKUCI3DG9U .\n",
            "He/She likes following products\n",
            "B007K449CE\n",
            "B000EPUPSS\n",
            "B000F4DKAS\n",
            "B001OCBT3U\n",
            "B000EMM9WG\n",
            "B0014X5O1C\n",
            "B004158VLU\n",
            "B0018SMUVA\n",
            "B004BKLHOS\n",
            "B000F4J76E\n",
            "B000YCJRIU\n",
            "B008RWUHA6\n",
            "B000MPQ4Q2\n",
            "B000ETVRQS\n",
            "B001E6IUMY\n",
            "B000EMK4CS\n",
            "B0027MIP9C\n",
            "B001OCKIBY\n",
            "B004FQU4CE\n",
            "B000JVCBO8\n",
            "B002LMXFCU\n",
            "B007JT7ARQ\n",
            "--------------------------------------------------------------------\n",
            "Based on  reviews, for user is  AY1EF0GOH80EK\n",
            "The first similar user is  AKMEY1BSHSDG7 .\n",
            "He/She likes following products\n",
            "B000E5AO8O\n",
            "B0001UZTJG\n",
            "B0009XQSAY\n",
            "B000GWHFZA\n",
            "B000WHPNI0\n",
            "B001EQ55RW\n",
            "B000EXMP74\n",
            "B000NQ6TRY\n",
            "B000FA38ZE\n",
            "B000BLNU6E\n",
            "B001EQ4J42\n",
            "B00469PHX6\n",
            "B000CQ4D3C\n",
            "B001OCKI5U\n",
            "B003ZXHB7E\n",
            "B000STZRTW\n",
            "B0007R9L4M\n",
            "B000CBR2FS\n",
            "B000E1FZJG\n",
            "B000EXKS14\n",
            "B0043OX51U\n",
            "B001E5E060\n",
            "B001EQ4HM6\n",
            "B000OBYNQW\n",
            "B000E1FZBY\n",
            "B007TGO1U8\n",
            "B000E67210\n",
            "B000KNHFKU\n",
            "B005G2FCNM\n",
            "B0014X5O1C\n",
            "B000YPMKY0\n",
            "B000YW7Q0Q\n",
            "B004BKLHOS\n",
            "B000I60JUW\n",
            "B001EQ4IKW\n",
            "B001FA1KLW\n",
            "B000FKQD5G\n",
            "B000LKXNG2\n",
            "B0014ET0OI\n",
            "B000CQ4D50\n",
            "B001M0A6C4\n",
            "B000EDDSE8\n",
            "B004FEN3GK\n",
            "B001M0AKSE\n",
            "B001D3Q4DA\n",
            "B005NIBIWS\n",
            "B000EMK56I\n",
            "B0006004C8\n",
            "B000FMZO90\n",
            "B001EQ4DUM\n",
            "B000MFJLZS\n",
            "B000MFJLZS\n",
            "B006VC0ZYM\n",
            "B000EPR1KI\n",
            "B000EPR1KI\n",
            "B000633Y40\n",
            "B000EUG1SG\n",
            "B000P54HZY\n",
            "B000E65OQA\n",
            "B000NU4VSO\n",
            "B000E63LDS\n",
            "B000KEPBBY\n",
            "B000P52FLW\n",
            "B002AQKYEE\n",
            "B000HBIHK2\n",
            "B001EO5W2M\n",
            "B004E4HUMY\n",
            "B000E1FXNY\n",
            "B003EYXUXS\n",
            "B001CTJOQY\n",
            "B003HKY4R0\n",
            "B000MRTSB8\n",
            "B003G1ZRTY\n",
            "B0032GHHRS\n",
            "B004YGQPAK\n",
            "B001E6K6F8\n",
            "B0069QQTWC\n",
            "B0031QKZP0\n",
            "B008ATDIDE\n",
            "B003VZBFTG\n",
            "B001E4Q5GO\n",
            "B00028Q8V0\n",
            "B001SAXPEO\n",
            "B00094D202\n",
            "B001EO5U3I\n",
            "--------------------------------------------------------------------\n",
            "Based on  reviews, for user is  AYB4ELCS5AM8P\n",
            "The first similar user is  A1K82R24ROO2I7 .\n",
            "He/She likes following products\n",
            "B000E1HVF2\n",
            "B001EPQ4HS\n",
            "B001VNEII0\n",
            "B0049D9H4Y\n",
            "B001EO5U60\n",
            "B00122AN6Q\n",
            "B001KUWENU\n",
            "B00445RVP4\n",
            "B003NROMC4\n",
            "B00286KM8E\n",
            "B003Z7VYXW\n",
            "B00060OHZS\n",
            "B000R8YIDA\n",
            "B004YZ4382\n",
            "B001VNGM2K\n",
            "B001VNKWO4\n",
            "B004TDU0SG\n",
            "B001M23XK4\n",
            "B001VNGLEY\n",
            "B004JR67XE\n",
            "B000QF7KK2\n",
            "B001KUWEOO\n",
            "B001SAWLU8\n",
            "B004Q3WIPC\n",
            "B001VNGJ5K\n",
            "B00444X8MU\n",
            "B004S04X56\n",
            "B001VNGOF0\n",
            "B000UZZICA\n",
            "B005G2FCGY\n",
            "B001VNGHSO\n",
            "B005258AZU\n",
            "B003ZI5U2W\n",
            "B001E5E2BS\n",
            "B0006Z7NOK\n",
            "B004LWRH0O\n",
            "B004R9DF70\n",
            "B001397WYY\n",
            "B0040PYXHW\n",
            "B004ACBL98\n",
            "B002603Q8U\n",
            "B0040PUPQ0\n",
            "B000R8YIIA\n",
            "B001VNO0FG\n",
            "B000G33N3W\n",
            "--------------------------------------------------------------------\n",
            "Based on  reviews, for user is  AYGJ96W5KQMUJ\n",
            "The first similar user is  A132ETQPMHQ585 .\n",
            "He/She likes following products\n",
            "B00113SKZW\n",
            "B001HXJP2S\n",
            "B000EN2WJU\n",
            "B000FDDESC\n",
            "B003POD8O8\n",
            "B001EO5Q64\n",
            "B000NMDVEW\n",
            "B001L4COIK\n",
            "B00113ZTVK\n",
            "B0008DI8QW\n",
            "B000NMCOYK\n",
            "B000LKVHZG\n",
            "B001FA1DKA\n",
            "B000EHL3HI\n",
            "B004SEUA40\n",
            "B004XAPIOQ\n",
            "B000LKVHYC\n",
            "B001GZ7SP8\n",
            "B000H2227K\n",
            "B005HGAV8I\n",
            "B003IRJTCC\n",
            "B001ONVOC0\n",
            "B003JYEJR4\n",
            "B000F9Z1ZK\n",
            "B00488N8KY\n",
            "B0039KERRK\n",
            "B000DZDJ0K\n",
            "B001E4S8GO\n",
            "B000FKQD42\n",
            "B001P3PR5Y\n",
            "B001P3PR5O\n",
            "B000YHLS8W\n",
            "--------------------------------------------------------------------\n",
            "Based on  reviews, for user is  AYOMAHLWRQHUG\n",
            "The first similar user is  A2W9I628I6SE1U .\n",
            "He/She likes following products\n",
            "B000AYFC22\n",
            "B0002BKIRW\n",
            "B008JHZ150\n",
            "B0051COPH6\n",
            "B007JT7AEY\n",
            "B0016861NU\n",
            "B008JHROIM\n",
            "B00275QDMU\n",
            "B0029JAR4O\n",
            "B00168AAWI\n",
            "B005HG9ET0\n",
            "B000SAOKIU\n",
            "B001E5E2M2\n",
            "B003Z5XW4I\n",
            "B000NWCZXA\n",
            "B004HN3ONQ\n",
            "--------------------------------------------------------------------\n",
            "Based on  reviews, for user is  AZV26LP92E6WU\n",
            "The first similar user is  A22CW0ZHY3NJH8 .\n",
            "He/She likes following products\n",
            "B001EQ5F9K\n",
            "B000PC3A2I\n",
            "B0026LKJHU\n",
            "B0014EOUBQ\n",
            "B00060OHZS\n",
            "B001C90SGY\n",
            "B0000DGF9V\n",
            "B003XZK6C6\n",
            "B001VJ57SO\n",
            "B002GPG6BE\n",
            "B00286BJ90\n",
            "B001NC8HS6\n",
            "B000Y2QCN8\n",
            "B000TTDDWE\n",
            "B0014EUA1U\n",
            "B001D228PY\n",
            "B004T9XDFM\n",
            "B004X8T8DK\n",
            "B0013NHT48\n",
            "B0002APS0A\n",
            "B0024NU5QU\n",
            "B003J5HRZE\n",
            "B002U93J48\n",
            "B001EQ5NHE\n",
            "B005SJJ4GO\n",
            "B0002YB3XC\n",
            "B00164X9SE\n",
            "B001YJ2Y14\n",
            "B00688IENS\n",
            "--------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uJ6YRIE4sr5",
        "colab_type": "code",
        "outputId": "3cb88c98-fc93-4750-ce6c-352f52c6977e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 2.c Predicting Review Score\n",
        "df5_train_target = df3[\"Score\"][:lentrain]\n",
        "df5_test_target = df3[\"Score\"][lentrain:lentrain+lentest]\n",
        "df5_train_target = df5_train_target.astype(int)\n",
        "df5_test_target = df5_test_target.astype(int)\n",
        "\n",
        "n_neighbors = 3\n",
        "knnclf = neighbors.KNeighborsClassifier(n_neighbors, weights='distance')\n",
        "knnclf.fit(df5_train, df5_train_target)\n",
        "knnpreds_test = knnclf.predict(df5_test)\n",
        "print (\"Predicting review score for testset user are : \", knnpreds_test)\n",
        "\n",
        "print(classification_report(df5_test_target, knnpreds_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting review score for testset user are :  [4 3 3 4 4 4 4 3 4 4 4 4 4]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           3       0.33      0.20      0.25         5\n",
            "           4       0.60      0.75      0.67         8\n",
            "\n",
            "    accuracy                           0.54        13\n",
            "   macro avg       0.47      0.47      0.46        13\n",
            "weighted avg       0.50      0.54      0.51        13\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1FjZkvM40zQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nlj7Yq9C-UHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Another method"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6727FvTm-UEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv('Reviews.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNEcYR1D-T_k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "d53cf7f2-3118-4197-ca7d-5dbdbbdc95ca"
      },
      "source": [
        "df"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568449</th>\n",
              "      <td>568450</td>\n",
              "      <td>B001EO7N10</td>\n",
              "      <td>A28KG5XORO54AY</td>\n",
              "      <td>Lettie D. Carter</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1299628800</td>\n",
              "      <td>Will not do without</td>\n",
              "      <td>Great for sesame chicken..this is a good if no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568450</th>\n",
              "      <td>568451</td>\n",
              "      <td>B003S1WTCU</td>\n",
              "      <td>A3I8AFVPEE8KI5</td>\n",
              "      <td>R. Sawyer</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1331251200</td>\n",
              "      <td>disappointed</td>\n",
              "      <td>I'm disappointed with the flavor. The chocolat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568451</th>\n",
              "      <td>568452</td>\n",
              "      <td>B004I613EE</td>\n",
              "      <td>A121AA1GQV751Z</td>\n",
              "      <td>pksd \"pk_007\"</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1329782400</td>\n",
              "      <td>Perfect for our maltipoo</td>\n",
              "      <td>These stars are small, so you can give 10-15 o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568452</th>\n",
              "      <td>568453</td>\n",
              "      <td>B004I613EE</td>\n",
              "      <td>A3IBEVCTXKNOH</td>\n",
              "      <td>Kathy A. Welch \"katwel\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1331596800</td>\n",
              "      <td>Favorite Training and reward treat</td>\n",
              "      <td>These are the BEST treats for training and rew...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568453</th>\n",
              "      <td>568454</td>\n",
              "      <td>B001LR2CU2</td>\n",
              "      <td>A3LGQPJCZVL9UC</td>\n",
              "      <td>srfell17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1338422400</td>\n",
              "      <td>Great Honey</td>\n",
              "      <td>I am very satisfied ,product is as advertised,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>568454 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Id  ...                                               Text\n",
              "0            1  ...  I have bought several of the Vitality canned d...\n",
              "1            2  ...  Product arrived labeled as Jumbo Salted Peanut...\n",
              "2            3  ...  This is a confection that has been around a fe...\n",
              "3            4  ...  If you are looking for the secret ingredient i...\n",
              "4            5  ...  Great taffy at a great price.  There was a wid...\n",
              "...        ...  ...                                                ...\n",
              "568449  568450  ...  Great for sesame chicken..this is a good if no...\n",
              "568450  568451  ...  I'm disappointed with the flavor. The chocolat...\n",
              "568451  568452  ...  These stars are small, so you can give 10-15 o...\n",
              "568452  568453  ...  These are the BEST treats for training and rew...\n",
              "568453  568454  ...  I am very satisfied ,product is as advertised,...\n",
              "\n",
              "[568454 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gmaXjOC-dKz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b2615b5e-0199-473e-fb41-a2b4f1d4dd55"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pylab\n",
        "import re\n",
        "import scipy as sp\n",
        "import seaborn\n",
        "\n",
        "from gensim import corpora, models\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.lda import LDA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
        "# from sklearn.qda import QDA\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "plt.rc('figure', figsize=(10,6))\n",
        "seaborn.set()\n",
        "colors = seaborn.color_palette()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOgExBCJkiE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqZhgBNf_1oz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ddaf6d5e-41be-4f41-95b7-8fabccb60471"
      },
      "source": [
        "%pylab inline"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['pylab']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsriTc3B_KZ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0195b495-02f0-4077-a962-9db2690dd862"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id                         0\n",
              "ProductId                  0\n",
              "UserId                     0\n",
              "ProfileName               16\n",
              "HelpfulnessNumerator       0\n",
              "HelpfulnessDenominator     0\n",
              "Score                      0\n",
              "Time                       0\n",
              "Summary                   27\n",
              "Text                       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR8Vsqr6kwrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJam3CRn_NdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.dropna(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaYbbk6m_SBA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5e3750e-a929-4d01-a099-1250e1d03512"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(568411, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsR_ll0f_TUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop_duplicates(subset=['ProductId','UserId','Score','Time'],inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1VnG9vP_mIl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17e6a384-73e5-44e5-c07f-9877eba8d0f8"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(565082, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnQpvvIJ-iR_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "0b0f0600-dee4-4d03-faa6-5ec713372bdc"
      },
      "source": [
        "bins = [1, 2,3 ,4, 5, 6]\n",
        "df.Score.hist(bins=bins, align='left', width=0.93)\n",
        "xticks(bins)\n",
        "xlabel('Rating stars')\n",
        "ylabel('Number of reviews')\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKRLoaNc_HMB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c07df9c-09ce-4f4a-c083-7c2f67858d41"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(565082, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3uBVTa7ADlA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Assign average rating as the predicted rating.\n",
        "df['predicted_rating'] = round(sum(df.Score)/len(df.index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctRWoEjfAXBP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3c8069bc-67d8-4496-fb37-460832bbf843"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "      <th>predicted_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  ... predicted_rating\n",
              "0   1  ...              4.0\n",
              "1   2  ...              4.0\n",
              "2   3  ...              4.0\n",
              "3   4  ...              4.0\n",
              "4   5  ...              4.0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kALuppHAXp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = df[['Score', 'predicted_rating']].dropna(how='any')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSS-2XyUAqZ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "c947dd35-2134-495e-fc71-99c6afbef2e7"
      },
      "source": [
        "t"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Score</th>\n",
              "      <th>predicted_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568449</th>\n",
              "      <td>5</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568450</th>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568451</th>\n",
              "      <td>5</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568452</th>\n",
              "      <td>5</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568453</th>\n",
              "      <td>5</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>565082 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Score  predicted_rating\n",
              "0           5               4.0\n",
              "1           1               4.0\n",
              "2           4               4.0\n",
              "3           2               4.0\n",
              "4           5               4.0\n",
              "...       ...               ...\n",
              "568449      5               4.0\n",
              "568450      2               4.0\n",
              "568451      5               4.0\n",
              "568452      5               4.0\n",
              "568453      5               4.0\n",
              "\n",
              "[565082 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfK3B1hPArAo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "25a04a9b-b672-4105-b22c-f5a917c31fb2"
      },
      "source": [
        "precision = metrics.precision_score(t.Score, t.predicted_rating,average='weighted')\n",
        "recall = metrics.recall_score(t.Score, t.predicted_rating,average='weighted')\n",
        "f1 = metrics.f1_score(t.Score, t.predicted_rating,average='weighted')\n",
        "accuracy = accuracy_score(t.Score, t.predicted_rating)\n",
        "\n",
        "baselineResult = {}\n",
        "\n",
        "data = {'precision':precision,\n",
        "        'recall':recall,\n",
        "        'f1_score':f1,\n",
        "        'accuracy':accuracy}\n",
        "\n",
        "baselineResult['Baseline'] = data\n",
        "pd.DataFrame(baselineResult).T"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Baseline</th>\n",
              "      <td>0.1421</td>\n",
              "      <td>0.03536</td>\n",
              "      <td>0.020192</td>\n",
              "      <td>0.1421</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          accuracy  f1_score  precision  recall\n",
              "Baseline    0.1421   0.03536   0.020192  0.1421"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EivX2lsRBvwi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4e457173-4d57-4c78-aa4a-d980e9095019"
      },
      "source": [
        "#Avanced model\n",
        "!pip install nlppreprocess"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nlppreprocess\n",
            "  Downloading https://files.pythonhosted.org/packages/66/8d/3a0584b924248c865a8e7ee04a93175551ebcaf156ee9b73346cd62446e6/nlppreprocess-1.0.2-py3-none-any.whl\n",
            "Installing collected packages: nlppreprocess\n",
            "Successfully installed nlppreprocess-1.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH0q3dOGBvtS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nlppreprocess import NLP\n",
        "obj = NLP(replace_words=True, remove_stopwords=True, remove_punctuations=True, lemmatize=True, lemmatize_method='wordnet' )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3ZBdKK0lYcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCZB3Xm2C0ha",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2993aac1-8a59-460a-cbb3-56fc9afc16ae"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewLld7YcBvpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Text'] = df['Text'].apply(obj.process)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGrXOEicLG0m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "663737d5-58f1-4fe1-ffd3-e3d44c3fb74e"
      },
      "source": [
        "df"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>bought several Vitality canned dog food produc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled Jumbo Salted Peanuts t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>confection been around few century light pillo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>you are looking secret ingredient in Robitussi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy great price There wide assortment ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568449</th>\n",
              "      <td>568450</td>\n",
              "      <td>B001EO7N10</td>\n",
              "      <td>A28KG5XORO54AY</td>\n",
              "      <td>Lettie D. Carter</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1299628800</td>\n",
              "      <td>Will not do without</td>\n",
              "      <td>Great sesame chicken this good not better than...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568450</th>\n",
              "      <td>568451</td>\n",
              "      <td>B003S1WTCU</td>\n",
              "      <td>A3I8AFVPEE8KI5</td>\n",
              "      <td>R. Sawyer</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1331251200</td>\n",
              "      <td>disappointed</td>\n",
              "      <td>I m disappointed with flavor chocolate note ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568451</th>\n",
              "      <td>568452</td>\n",
              "      <td>B004I613EE</td>\n",
              "      <td>A121AA1GQV751Z</td>\n",
              "      <td>pksd \"pk_007\"</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1329782400</td>\n",
              "      <td>Perfect for our maltipoo</td>\n",
              "      <td>These star are small you can give those in one...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568452</th>\n",
              "      <td>568453</td>\n",
              "      <td>B004I613EE</td>\n",
              "      <td>A3IBEVCTXKNOH</td>\n",
              "      <td>Kathy A. Welch \"katwel\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1331596800</td>\n",
              "      <td>Favorite Training and reward treat</td>\n",
              "      <td>These are BEST treat training and rewarding yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568453</th>\n",
              "      <td>568454</td>\n",
              "      <td>B001LR2CU2</td>\n",
              "      <td>A3LGQPJCZVL9UC</td>\n",
              "      <td>srfell17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1338422400</td>\n",
              "      <td>Great Honey</td>\n",
              "      <td>am very satisfied product advertised use cerea...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>565082 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Id  ...                                               Text\n",
              "0            1  ...  bought several Vitality canned dog food produc...\n",
              "1            2  ...  Product arrived labeled Jumbo Salted Peanuts t...\n",
              "2            3  ...  confection been around few century light pillo...\n",
              "3            4  ...  you are looking secret ingredient in Robitussi...\n",
              "4            5  ...  Great taffy great price There wide assortment ...\n",
              "...        ...  ...                                                ...\n",
              "568449  568450  ...  Great sesame chicken this good not better than...\n",
              "568450  568451  ...  I m disappointed with flavor chocolate note ar...\n",
              "568451  568452  ...  These star are small you can give those in one...\n",
              "568452  568453  ...  These are BEST treat training and rewarding yo...\n",
              "568453  568454  ...  am very satisfied product advertised use cerea...\n",
              "\n",
              "[565082 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF27hlzfCwzT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Advanced models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfjU5UcaSb1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numTopics = 25"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myeyCU5ASgbp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fde18be9-9ffe-472d-c398-3ad2ec4f8fb2"
      },
      "source": [
        "t = df.dropna(how='all')\n",
        "t.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(565082, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sumS0XnnSnVz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "daae2c60-e1aa-4ff7-83ee-b872de80062a"
      },
      "source": [
        "minReviewLen = 50\n",
        "maxReviewLen = 400\n",
        "\n",
        "print(\"Number of rows selected:\",len(t[t.Text.str.len() > minReviewLen][t.Text.str.len() < maxReviewLen]))\n",
        "df2 = t[t.Text.str.len() > minReviewLen][t.Text.str.len() < maxReviewLen]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of rows selected: 421543\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67Fopc_JT9ny",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e983b8e8-5f49-4dcd-e7ac-4f1105342977"
      },
      "source": [
        "print(\"Number of rows selected:\",len(t[t.Text.str.len() > minReviewLen][t.Text.str.len() < maxReviewLen]))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of rows selected: 240899\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1mcUpG8TMAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2.reset_index(inplace=True,drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N--RMJUTXXV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "3978dd64-ee96-42cf-a995-8213c716d667"
      },
      "source": [
        "df2"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>bought several Vitality canned dog food produc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled Jumbo Salted Peanuts t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>confection been around few century light pillo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>you are looking secret ingredient in Robitussi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy great price There wide assortment ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421538</th>\n",
              "      <td>568450</td>\n",
              "      <td>B001EO7N10</td>\n",
              "      <td>A28KG5XORO54AY</td>\n",
              "      <td>Lettie D. Carter</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1299628800</td>\n",
              "      <td>Will not do without</td>\n",
              "      <td>Great sesame chicken this good not better than...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421539</th>\n",
              "      <td>568451</td>\n",
              "      <td>B003S1WTCU</td>\n",
              "      <td>A3I8AFVPEE8KI5</td>\n",
              "      <td>R. Sawyer</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1331251200</td>\n",
              "      <td>disappointed</td>\n",
              "      <td>I m disappointed with flavor chocolate note ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421540</th>\n",
              "      <td>568452</td>\n",
              "      <td>B004I613EE</td>\n",
              "      <td>A121AA1GQV751Z</td>\n",
              "      <td>pksd \"pk_007\"</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1329782400</td>\n",
              "      <td>Perfect for our maltipoo</td>\n",
              "      <td>These star are small you can give those in one...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421541</th>\n",
              "      <td>568453</td>\n",
              "      <td>B004I613EE</td>\n",
              "      <td>A3IBEVCTXKNOH</td>\n",
              "      <td>Kathy A. Welch \"katwel\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1331596800</td>\n",
              "      <td>Favorite Training and reward treat</td>\n",
              "      <td>These are BEST treat training and rewarding yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421542</th>\n",
              "      <td>568454</td>\n",
              "      <td>B001LR2CU2</td>\n",
              "      <td>A3LGQPJCZVL9UC</td>\n",
              "      <td>srfell17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1338422400</td>\n",
              "      <td>Great Honey</td>\n",
              "      <td>am very satisfied product advertised use cerea...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>421543 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Id  ...                                               Text\n",
              "0            1  ...  bought several Vitality canned dog food produc...\n",
              "1            2  ...  Product arrived labeled Jumbo Salted Peanuts t...\n",
              "2            3  ...  confection been around few century light pillo...\n",
              "3            4  ...  you are looking secret ingredient in Robitussi...\n",
              "4            5  ...  Great taffy great price There wide assortment ...\n",
              "...        ...  ...                                                ...\n",
              "421538  568450  ...  Great sesame chicken this good not better than...\n",
              "421539  568451  ...  I m disappointed with flavor chocolate note ar...\n",
              "421540  568452  ...  These star are small you can give those in one...\n",
              "421541  568453  ...  These are BEST treat training and rewarding yo...\n",
              "421542  568454  ...  am very satisfied product advertised use cerea...\n",
              "\n",
              "[421543 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykzJB-ZITv-9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "305519cc-974c-47a0-ba29-958fd6535d80"
      },
      "source": [
        "bins = [1, 2,3 ,4, 5, 6]\n",
        "df2.Score.hist(bins=bins, align='left', width=0.93)\n",
        "xticks(bins)\n",
        "xlabel('Rating stars')\n",
        "ylabel('Number of reviews')\n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTtODa9cYsZk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "779a4db7-37f6-4a5f-abb5-b318fcc0d654"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "stoplist = set(stopwords.words(\"english\"))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vd4WwNTnY19l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stoplist={}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzQkTC0ZYxfz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "785691cc-adb4-45e1-937b-c943e9062cfe"
      },
      "source": [
        "stoplist"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YZ-Sf9gT3GA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perform_lda(allReviewsTrain, numTopics):\n",
        "    corpus = []\n",
        "    for review in allReviewsTrain:\n",
        "        # Remove punctuations\n",
        "        review = re.sub(r'[^a-zA-Z]', ' ', review)\n",
        "        # To lowercase\n",
        "        review = review.lower()\n",
        "        # Remove stop words\n",
        "        texts = [word for word in review.lower().split() if word not in stoplist]\n",
        "        try:\n",
        "            corpus.append(texts)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # Build dictionary\n",
        "    dictionary = corpora.Dictionary(corpus)\n",
        "    dictionary.save('restaurant_reviews.dict')\n",
        "        \n",
        "    # Build vectorized corpus\n",
        "    corpus_2 = [dictionary.doc2bow(text) for text in corpus]\n",
        "    #corpora.MmCorpus.serialize('LDA/restaurant_reviews.mm', corpus_2)\n",
        "    \n",
        "    lda = models.LdaModel(corpus_2, num_topics=numTopics, id2word=dictionary)\n",
        "    return lda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d6Xog9B4g0_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5ae137e-81e0-4821-a80b-849d7153dd1f"
      },
      "source": [
        "stoplist"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUz7EsaeURgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Process the reviews and generate a topic distribution matrix (to be used as features in classification)\n",
        "import re\n",
        "def process_reviews(dirty_data_set):\n",
        "    clean_data_set = []\n",
        "    for review in dirty_data_set:\n",
        "        # Remove punctuations\n",
        "        review = re.sub(r'[^a-zA-Z]', ' ', review)\n",
        "        # To lowercase\n",
        "        review = review.lower()\n",
        "        # Remove stop words\n",
        "        texts = [word for word in review.lower().split() if word not in stoplist]\n",
        "        try:\n",
        "            clean_data_set.append(' '.join(texts))\n",
        "        except:\n",
        "            pass\n",
        "    return clean_data_set\n",
        "\n",
        "# Generates a matrix of topic probabilities for each document in matrix\n",
        "# Returns topic_dist for the input corpus, and all_dist, a running sum of all the corpuses\n",
        "def generate_topic_dist_matrix(lda, numTopics, corpus, all_dist, star):\n",
        "    topic_dist = [0] * numTopics\n",
        "    dictionary = corpora.Dictionary.load(\"restaurant_reviews.dict\")\n",
        "    for doc in corpus:\n",
        "        vec = dictionary.doc2bow(doc.lower().split())\n",
        "        output = lda[vec]\n",
        "        highest_prob = 0\n",
        "        highest_topic = 0\n",
        "        temp = [0] * numTopics    # List to keep track of topic distribution for each document\n",
        "        for topic in output:\n",
        "            this_topic, this_prob = topic\n",
        "            temp[this_topic] = this_prob\n",
        "            if this_prob > highest_prob:\n",
        "                highest_prob = this_prob \n",
        "                highest_topic = this_topic\n",
        "        temp.append(star)\n",
        "        all_dist.append(temp)\n",
        "        topic_dist[highest_topic] += 1\n",
        "    return topic_dist, all_dist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj47k7C_Ugmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Construct 5 groups for each rating\n",
        "starsGroup = df2.groupby('Score')\n",
        "\n",
        "all_1stars_text = starsGroup.get_group(1.0)['Text']\n",
        "all_2stars_text = starsGroup.get_group(2.0)['Text']\n",
        "all_3stars_text = starsGroup.get_group(3.0)['Text']\n",
        "all_4stars_text = starsGroup.get_group(4.0)['Text']\n",
        "all_5stars_text = starsGroup.get_group(5.0)['Text']\n",
        "\n",
        "all_1stars_labels = [1.0]*len(all_1stars_text)\n",
        "all_2stars_labels = [2.0]*len(all_2stars_text)\n",
        "all_3stars_labels = [3.0]*len(all_3stars_text)\n",
        "all_4stars_labels = [4.0]*len(all_4stars_text)\n",
        "all_5stars_labels = [5.0]*len(all_5stars_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej45piPhU1Ht",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "fb0a90a7-274d-4c4e-c3ba-7b3e3be75986"
      },
      "source": [
        "all_5stars_text"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         bought several Vitality canned dog food produc...\n",
              "4         Great taffy great price There wide assortment ...\n",
              "6         saltwater taffy had great flavor and very soft...\n",
              "7         taffy good very soft and chewy flavor are amaz...\n",
              "8         Right now I m mostly just sprouting my cat can...\n",
              "                                ...                        \n",
              "421537    My only complaint there s much it not use huge...\n",
              "421538    Great sesame chicken this good not better than...\n",
              "421540    These star are small you can give those in one...\n",
              "421541    These are BEST treat training and rewarding yo...\n",
              "421542    am very satisfied product advertised use cerea...\n",
              "Name: Text, Length: 280906, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmXTV_b2U3da",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####Split into training and testing data randomly using sklearn's library\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "all_1stars_text_train, all_1stars_text_test, all_1stars_labels_train, all_1stars_labels_test = train_test_split(all_1stars_text, all_1stars_labels, test_size=0.20)\n",
        "all_2stars_text_train, all_2stars_text_test, all_2stars_labels_train, all_2stars_labels_test = train_test_split(all_2stars_text, all_2stars_labels, test_size=0.20)\n",
        "all_3stars_text_train, all_3stars_text_test, all_3stars_labels_train, all_3stars_labels_test = train_test_split(all_3stars_text, all_3stars_labels, test_size=0.20)\n",
        "all_4stars_text_train, all_4stars_text_test, all_4stars_labels_train, all_4stars_labels_test = train_test_split(all_4stars_text, all_4stars_labels, test_size=0.20)\n",
        "all_5stars_text_train, all_5stars_text_test, all_5stars_labels_train, all_5stars_labels_test = train_test_split(all_5stars_text, all_5stars_labels, test_size=0.20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdfisqmvWKrN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a20b1ffa-b159-48ce-cde3-74ae2d937575"
      },
      "source": [
        "all_4stars_text_train"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "363850    wouldn t call these almond sweet but they just...\n",
              "385566    By flavor too strong and overwhelming after fe...\n",
              "332509    bought try and make cola drink like Borders Bo...\n",
              "204352    been week and like product After researching o...\n",
              "53942     PRODUCT TASTES LIKE MILD NUTTY HONEY VERY DIFF...\n",
              "                                ...                        \n",
              "321962    product exactly what wanted Pumpkin not found ...\n",
              "247103    my cat will eat it but arent crazy either cons...\n",
              "318310    great assortment and price I only give star be...\n",
              "416159    not eat red meat sea food get expensive and ch...\n",
              "200141    These are really good My two little cousin cam...\n",
              "Name: Text, Length: 43837, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ONKrn1wXDre",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a576e24d-dc48-4c04-f0f8-72c53efd39fb"
      },
      "source": [
        "all_5stars_text_train"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "343257    Several day ago made decision quit smoking cou...\n",
              "402057    sample pack will give home roaster good sense ...\n",
              "407143    These are my husband s favorite chip love tang...\n",
              "242760    Our Newf Owen Senior citizen now wanted switch...\n",
              "273018    you like making homemade oreo like cooky black...\n",
              "                                ...                        \n",
              "330327    wanted spice after seeing Tyler Florence use i...\n",
              "28943     My daughter limited diet due allergy love eati...\n",
              "166820    not expect chopped into piece I m used using w...\n",
              "4818      HAD USED AND COME LOVE PRODUCT AND SUDDENLY CO...\n",
              "320618    wonderful item yourself and baby Clean up snap...\n",
              "Name: Text, Length: 224724, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-cNW0EAV3qt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "2c206445-8cb3-4901-e3fb-cfdd62b8954b"
      },
      "source": [
        "# Process the reviews\n",
        "corpus_5stars = process_reviews(all_5stars_text_train)\n",
        "corpus_4stars = process_reviews(all_4stars_text_train)\n",
        "corpus_3stars = process_reviews(all_3stars_text_train)\n",
        "corpus_2stars = process_reviews(all_2stars_text_train)\n",
        "corpus_1stars = process_reviews(all_1stars_text_train)\n",
        "\n",
        "print(\"Number of 5-star reviews after processing: \", len(corpus_5stars))\n",
        "print(\"Number of 4-star reviews after processing: \", len(corpus_4stars))\n",
        "print(\"Number of 3-star reviews after processing: \", len(corpus_3stars))\n",
        "print(\"Number of 2-star reviews after processing: \", len(corpus_2stars))\n",
        "print(\"Number of 1-star reviews after processing: \", len(corpus_1stars))"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of 5-star reviews after processing:  224724\n",
            "Number of 4-star reviews after processing:  43837\n",
            "Number of 3-star reviews after processing:  22361\n",
            "Number of 2-star reviews after processing:  16353\n",
            "Number of 1-star reviews after processing:  29956\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNxDHWPS4wd5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d67add20-97c1-4def-8122-60c7ff2cd79b"
      },
      "source": [
        "corpus_5stars[1]"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'stash blended delicious green tea with herb and flavoring just delicious needing no sweetening or very little'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYtwPkWSWFlf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "9a45b416-4bc8-4f15-8823-509369f1c58b"
      },
      "source": [
        "all_5stars_text_train"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "343257    Several day ago made decision quit smoking cou...\n",
              "402057    sample pack will give home roaster good sense ...\n",
              "407143    These are my husband s favorite chip love tang...\n",
              "242760    Our Newf Owen Senior citizen now wanted switch...\n",
              "273018    you like making homemade oreo like cooky black...\n",
              "                                ...                        \n",
              "330327    wanted spice after seeing Tyler Florence use i...\n",
              "28943     My daughter limited diet due allergy love eati...\n",
              "166820    not expect chopped into piece I m used using w...\n",
              "4818      HAD USED AND COME LOVE PRODUCT AND SUDDENLY CO...\n",
              "320618    wonderful item yourself and baby Clean up snap...\n",
              "Name: Text, Length: 224724, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTWeDyHUWdIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_5_4_train = np.append(corpus_5stars, corpus_4stars)\n",
        "all_5_4_3_train = np.append(all_5_4_train, corpus_3stars)\n",
        "all_5_4_3_2_train = np.append(all_5_4_3_train, corpus_2stars)\n",
        "all_text_train = np.append(all_5_4_3_2_train, corpus_1stars)\n",
        "\n",
        "# pickle.dump(all_text_train, open(\"all_text_train.p\", \"wb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXi2uYyX35aH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0aa978c-cd6d-4355-9ff1-787c06ae91dc"
      },
      "source": [
        "all_text_train[1]"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'stash blended delicious green tea with herb and flavoring just delicious needing no sweetening or very little'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4P--eW43-j5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_5stars"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MfoGFSjXVWy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "cb6ab064-cec4-4dce-e13a-f7f1c20c9923"
      },
      "source": [
        "%time lda = perform_lda(all_text_train, numTopics)\n",
        "# pickle.dump(lda, open(\"lda.p\", \"wb\"))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6min 27s, sys: 1.39 s, total: 6min 28s\n",
            "Wall time: 6min 28s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyzxCD_EXauD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(lda, open(\"lda.p\", \"wb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5iWE0GAauPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "Pkl_Filename = \"lda.pkl\"  \n",
        "\n",
        "with open(Pkl_Filename, 'wb') as file:  \n",
        "    pickle.dump(lda, file)\n",
        "\n",
        "# # Load the Model back from file\n",
        "# with open(Pkl_Filename, 'rb') as file:  \n",
        "#     Pickled_Model = pickle.load(file)\n",
        "\n",
        "# Pickled_Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0JjHdl_awHs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "06425a43-c775-46be-f635-2e75ff73ea64"
      },
      "source": [
        "# ### Build the final data frame containing topic distribution for each set of rating\n",
        "\n",
        "topic_dist_list = []\n",
        "\n",
        "# Keep a separate list to count topics\n",
        "topic_dist_5stars = []\n",
        "topic_dist_4stars = []\n",
        "topic_dist_3stars = []\n",
        "topic_dist_2stars = []\n",
        "topic_dist_1stars = []\n",
        "\n",
        "topic_dist_5stars, topic_dist_list = generate_topic_dist_matrix(lda, numTopics, corpus_5stars, topic_dist_list, 5)\n",
        "topic_dist_4stars, topic_dist_list = generate_topic_dist_matrix(lda, numTopics, corpus_4stars, topic_dist_list, 4)\n",
        "topic_dist_3stars, topic_dist_list = generate_topic_dist_matrix(lda, numTopics, corpus_3stars, topic_dist_list, 3)\n",
        "topic_dist_2stars, topic_dist_list = generate_topic_dist_matrix(lda, numTopics, corpus_2stars, topic_dist_list, 2)\n",
        "topic_dist_1stars, topic_dist_list = generate_topic_dist_matrix(lda, numTopics, corpus_1stars, topic_dist_list, 1)\n",
        "\n",
        "cols = []\n",
        "for i in range(1, numTopics+1):\n",
        "    cols.append(\"Topic\"+ str(i))\n",
        "cols.append(\"Star\")\n",
        "\n",
        "topic_dist_train_1_2_3_4_5_df = pd.DataFrame(topic_dist_list, columns=cols)\n",
        "\n",
        "# pickle.dump(topic_dist_train_1_2_3_4_5_df, open(\"topic_dist_train_1_2_3_4_5_df.p\", \"wb\"))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjDrR-U1bPKE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9fa1ce86-018a-4f56-d925-fc0efb1ff312"
      },
      "source": [
        "#Get topic distribution of test data.\n",
        "\n",
        "# Process the test reviews\n",
        "corpus_5stars = process_reviews(all_5stars_text_test)\n",
        "corpus_4stars = process_reviews(all_4stars_text_test)\n",
        "corpus_3stars = process_reviews(all_3stars_text_test)\n",
        "corpus_2stars = process_reviews(all_2stars_text_test)\n",
        "corpus_1stars = process_reviews(all_1stars_text_test)\n",
        "\n",
        "print(\"Number of 5-star reviews after processing: \", len(corpus_5stars))\n",
        "print(\"Number of 4-star reviews after processing: \", len(corpus_4stars))\n",
        "print(\"Number of 3-star reviews after processing: \", len(corpus_3stars))\n",
        "print(\"Number of 2-star reviews after processing: \", len(corpus_2stars))\n",
        "print(\"Number of 1-star reviews after processing: \", len(corpus_1stars))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of 5-star reviews after processing:  56182\n",
            "Number of 4-star reviews after processing:  10960\n",
            "Number of 3-star reviews after processing:  5591\n",
            "Number of 2-star reviews after processing:  4089\n",
            "Number of 1-star reviews after processing:  7490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLmrYKL-m0GU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_5_4_test = np.append(corpus_5stars, corpus_4stars)\n",
        "all_5_4_3_test = np.append(all_5_4_test, corpus_3stars)\n",
        "all_5_4_3_2_test = np.append(all_5_4_3_test, corpus_2stars)\n",
        "all_text_test = np.append(all_5_4_3_2_test, corpus_1stars)\n",
        "\n",
        "# pickle.dump(all_text_test, open(\"all_text_test.p\", \"wb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZiKNcCRnD0X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "fe4160ba-7651-4f81-f783-218691d99084"
      },
      "source": [
        "topic_dist_list = []\n",
        "\n",
        "# Keep a separate list to count topics\n",
        "topic_dist_5stars = []\n",
        "topic_dist_4stars = []\n",
        "topic_dist_3stars = []\n",
        "topic_dist_2stars = []\n",
        "topic_dist_1stars = []\n",
        "\n",
        "\n",
        "topic_dist_5stars, topic_dist_list = generate_topic_dist_matrix(lda, numTopics, corpus_5stars, topic_dist_list, 5)\n",
        "topic_dist_4stars, topic_dist_list = generate_topic_dist_matrix(lda, numTopics, corpus_4stars, topic_dist_list, 4)\n",
        "topic_dist_3stars, topic_dist_list = generate_topic_dist_matrix(lda, numTopics, corpus_3stars, topic_dist_list, 3)\n",
        "topic_dist_2stars, topic_dist_list = generate_topic_dist_matrix(lda, numTopics, corpus_2stars, topic_dist_list, 2)\n",
        "topic_dist_1stars, topic_dist_list = generate_topic_dist_matrix(lda, numTopics, corpus_1stars, topic_dist_list, 1)\n",
        "\n",
        "cols = []\n",
        "for i in range(1, numTopics+1):\n",
        "    cols.append(\"Topic\"+ str(i))\n",
        "cols.append(\"Star\")\n",
        "\n",
        "topic_dist_test_1_2_3_4_5_df = pd.DataFrame(topic_dist_list, columns=cols)\n",
        "\n",
        "# pickle.dump(topic_dist_test_1_2_3_4_5_df, open(\"topic_dist_test_1_2_3_4_5_df.p\", \"wb\"))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01KxP9T8nKCY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6cea600b-aa79-405d-cc1d-8db695cb2c27"
      },
      "source": [
        "topic_dist_test_1_2_3_4_5_df.shape"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(84312, 26)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L1KzGjmnNQx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a72bc31-e8d7-479b-daf4-e7e8f020f20c"
      },
      "source": [
        "topic_dist_train_1_2_3_4_5_df.shape"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(337231, 26)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGBickO1nP9f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "3028fab8-6b9b-49ea-9e87-cc782f0f3d73"
      },
      "source": [
        "topic_dist_train_1_2_3_4_5_df"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic1</th>\n",
              "      <th>Topic2</th>\n",
              "      <th>Topic3</th>\n",
              "      <th>Topic4</th>\n",
              "      <th>Topic5</th>\n",
              "      <th>Topic6</th>\n",
              "      <th>Topic7</th>\n",
              "      <th>Topic8</th>\n",
              "      <th>Topic9</th>\n",
              "      <th>Topic10</th>\n",
              "      <th>Topic11</th>\n",
              "      <th>Topic12</th>\n",
              "      <th>Topic13</th>\n",
              "      <th>Topic14</th>\n",
              "      <th>Topic15</th>\n",
              "      <th>Topic16</th>\n",
              "      <th>Topic17</th>\n",
              "      <th>Topic18</th>\n",
              "      <th>Topic19</th>\n",
              "      <th>Topic20</th>\n",
              "      <th>Topic21</th>\n",
              "      <th>Topic22</th>\n",
              "      <th>Topic23</th>\n",
              "      <th>Topic24</th>\n",
              "      <th>Topic25</th>\n",
              "      <th>Star</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.376765</td>\n",
              "      <td>0.041659</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.135724</td>\n",
              "      <td>0</td>\n",
              "      <td>0.011652</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.074401</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.035298</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.132171</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.103069</td>\n",
              "      <td>0.037894</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.042728</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.064840</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.133611</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.350143</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.177100</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017090</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.150292</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.102587</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.107641</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.613329</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.215404</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.054594</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.243194</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.288203</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.118985</td>\n",
              "      <td>0.165934</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.032950</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.012745</td>\n",
              "      <td>0.013060</td>\n",
              "      <td>0.028959</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.089633</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.027358</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.028210</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.110065</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.164495</td>\n",
              "      <td>0</td>\n",
              "      <td>0.184944</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.18542</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.295486</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>337226</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.061211</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.032708</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.076061</td>\n",
              "      <td>0.264851</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.230471</td>\n",
              "      <td>0.321074</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>337227</th>\n",
              "      <td>0.200798</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.278652</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133894</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.229580</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.042562</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.109611</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>337228</th>\n",
              "      <td>0.131018</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.041838</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.101021</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.084706</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.444631</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.013083</td>\n",
              "      <td>0.014951</td>\n",
              "      <td>0.047959</td>\n",
              "      <td>0.080322</td>\n",
              "      <td>0.019131</td>\n",
              "      <td>0</td>\n",
              "      <td>0.012468</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>337229</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.041936</td>\n",
              "      <td>0.060188</td>\n",
              "      <td>0.022644</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018144</td>\n",
              "      <td>0.221950</td>\n",
              "      <td>0</td>\n",
              "      <td>0.076723</td>\n",
              "      <td>0.331115</td>\n",
              "      <td>0.03242</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.129653</td>\n",
              "      <td>0.017260</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.045995</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>337230</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.417694</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.056353</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.025278</td>\n",
              "      <td>0.157070</td>\n",
              "      <td>0.336708</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>337231 rows × 26 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Topic1    Topic2  Topic3  Topic4  ...  Topic23   Topic24   Topic25  Star\n",
              "0       0.376765  0.041659       0       0  ...        0  0.042728  0.000000     5\n",
              "1       0.000000  0.064840       0       0  ...        0  0.102587  0.000000     5\n",
              "2       0.000000  0.000000       0       0  ...        0  0.000000  0.000000     5\n",
              "3       0.000000  0.000000       0       0  ...        0  0.089633  0.000000     5\n",
              "4       0.000000  0.027358       0       0  ...        0  0.000000  0.000000     5\n",
              "...          ...       ...     ...     ...  ...      ...       ...       ...   ...\n",
              "337226  0.000000  0.000000       0       0  ...        0  0.230471  0.321074     1\n",
              "337227  0.200798  0.000000       0       0  ...        0  0.000000  0.109611     1\n",
              "337228  0.131018  0.000000       0       0  ...        0  0.012468  0.000000     1\n",
              "337229  0.000000  0.000000       0       0  ...        0  0.000000  0.045995     1\n",
              "337230  0.000000  0.000000       0       0  ...        0  0.000000  0.000000     1\n",
              "\n",
              "[337231 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0wBLxgsnn78",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Add sentiment label which will be used to train sentiment classifier\n",
        "def getSentiment(x):\n",
        "    if x < 3.5:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f44mj2Gqn0oc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_dist_train_1_2_3_4_5_df['Sentiment'] = topic_dist_train_1_2_3_4_5_df['Star'].map(getSentiment)\n",
        "topic_dist_test_1_2_3_4_5_df['Sentiment'] = topic_dist_test_1_2_3_4_5_df['Star'].map(getSentiment)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rbij_O2Xn2-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3. LDA Model\n",
        "# To reduce processing of redundant information that we did on term frequency method, we are using topic modeling to extract major topics in a review and using that as features."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyBxHXDXn-6j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "86ba3976-9ca3-4f7c-ebed-92f692af46bc"
      },
      "source": [
        "features = list(topic_dist_train_1_2_3_4_5_df.columns[:numTopics])\n",
        "print(features)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Topic1', 'Topic2', 'Topic3', 'Topic4', 'Topic5', 'Topic6', 'Topic7', 'Topic8', 'Topic9', 'Topic10', 'Topic11', 'Topic12', 'Topic13', 'Topic14', 'Topic15', 'Topic16', 'Topic17', 'Topic18', 'Topic19', 'Topic20', 'Topic21', 'Topic22', 'Topic23', 'Topic24', 'Topic25']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FN6QiIGxr5Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3c6c3cf9-3600-479b-f890-3ba7430d53db"
      },
      "source": [
        "starsGroup"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7fd4a0fcde80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkCBy7hCoCMX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "59e2192f-1e1b-4c8a-c1f8-6a1b55b8bf64"
      },
      "source": [
        "x_train = topic_dist_train_1_2_3_4_5_df[features]\n",
        "y_train = topic_dist_train_1_2_3_4_5_df['Star']\n",
        "\n",
        "x_test = topic_dist_test_1_2_3_4_5_df[features]\n",
        "y_test = topic_dist_test_1_2_3_4_5_df['Star'] \n",
        "\n",
        "clfs = [KNeighborsClassifier(), MultinomialNB(), LogisticRegression(), LDA(), QDA(), RandomForestClassifier(n_estimators=100, n_jobs=2), AdaBoostClassifier(n_estimators=100)]\n",
        "clf_names = ['Nearest Neighbors', 'Multinomial Naive Bayes', 'Logistic Regression', 'LDA', 'QDA', 'Random Forest', 'AdaBoost']\n",
        "\n",
        "LDAResults = {}\n",
        "for (i, clf_) in enumerate(clfs):\n",
        "    clf = clf_.fit(x_train, y_train)\n",
        "    preds = clf.predict(x_test)\n",
        "    \n",
        "    precision = metrics.precision_score(y_test, preds,average=None)\n",
        "    recall = metrics.recall_score(y_test, preds,average=None)\n",
        "    f1 = metrics.f1_score(y_test, preds,average=None)\n",
        "    accuracy = accuracy_score(y_test, preds)\n",
        "    report = classification_report(y_test, preds)\n",
        "    matrix = metrics.confusion_matrix(y_test, preds, labels=np.array(list(starsGroup.groups.keys())))\n",
        "    \n",
        "    data = {'precision':precision,\n",
        "            'recall':recall,\n",
        "            'f1_score':f1,\n",
        "            'accuracy':accuracy,\n",
        "            'clf_report':report,\n",
        "            'clf_matrix':matrix,\n",
        "            'y_predicted':preds}\n",
        "    \n",
        "    LDAResults[clf_names[i]] = data"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjCoeZ9YynGv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "faa5ba7d-0143-4fa7-d709-4fd7cafcd191"
      },
      "source": [
        "np.array(list(starsGroup.groups.keys()))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bey5pQ1v4kv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "305af0ea-071f-4851-86fd-163bc44c7002"
      },
      "source": [
        "starsGroup.groups.keys()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys([1, 2, 3, 4, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si5zl14noGqt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "b38db26d-1ee6-487e-dc03-7a937658e68a"
      },
      "source": [
        "cols = ['precision', 'recall', 'f1_score', 'accuracy']\n",
        "pd.DataFrame(LDAResults).T[cols].T"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Nearest Neighbors</th>\n",
              "      <th>Multinomial Naive Bayes</th>\n",
              "      <th>Logistic Regression</th>\n",
              "      <th>LDA</th>\n",
              "      <th>QDA</th>\n",
              "      <th>Random Forest</th>\n",
              "      <th>AdaBoost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>[0.40271493212669685, 0.4228428213390619, 0.42...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.6663582882626435]</td>\n",
              "      <td>[0.24675324675324675, 0.0, 0.21621621621621623...</td>\n",
              "      <td>[0.31521739130434784, 0.0, 0.18596491228070175...</td>\n",
              "      <td>[0.08726287262872628, 0.04625658023006434, 0.0...</td>\n",
              "      <td>[0.9549893842887474, 0.9867549668874173, 0.968...</td>\n",
              "      <td>[0.3333333333333333, 0.0, 0.5, 0.0, 0.66643732...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>[0.33271028037383177, 0.2888236732697481, 0.31...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "      <td>[0.0025367156208277704, 0.0, 0.002861742085494...</td>\n",
              "      <td>[0.0038718291054739653, 0.0, 0.009479520658200...</td>\n",
              "      <td>[0.02149532710280374, 0.23208608461726585, 0.0...</td>\n",
              "      <td>[0.30026702269692923, 0.29151381755930544, 0.3...</td>\n",
              "      <td>[0.00040053404539385846, 0.0, 0.00017885888034...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1_score</th>\n",
              "      <td>[0.3643807574206755, 0.34321418192385933, 0.36...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.799777926459493]</td>\n",
              "      <td>[0.005021805206819083, 0.0, 0.0056487202118270...</td>\n",
              "      <td>[0.007649696649960433, 0.0, 0.0180394826412525...</td>\n",
              "      <td>[0.034493840385645416, 0.07713879292826663, 0....</td>\n",
              "      <td>[0.4568816658202133, 0.45006607513686997, 0.47...</td>\n",
              "      <td>[0.0008001066808907853, 0.0, 0.000357589844448...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.678029</td>\n",
              "      <td>0.666358</td>\n",
              "      <td>0.666157</td>\n",
              "      <td>0.665575</td>\n",
              "      <td>0.244425</td>\n",
              "      <td>0.766095</td>\n",
              "      <td>0.666382</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Nearest Neighbors  ...                                           AdaBoost\n",
              "precision  [0.40271493212669685, 0.4228428213390619, 0.42...  ...  [0.3333333333333333, 0.0, 0.5, 0.0, 0.66643732...\n",
              "recall     [0.33271028037383177, 0.2888236732697481, 0.31...  ...  [0.00040053404539385846, 0.0, 0.00017885888034...\n",
              "f1_score   [0.3643807574206755, 0.34321418192385933, 0.36...  ...  [0.0008001066808907853, 0.0, 0.000357589844448...\n",
              "accuracy                                            0.678029  ...                                           0.666382\n",
              "\n",
              "[4 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnlO9rtooK4H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "feb71f34-e172-4c40-8afb-bdbc69078c0d"
      },
      "source": [
        "for model, val in LDAResults.items():\n",
        "    print('-------'+'-'*len(model))\n",
        "    print('MODEL:', model)\n",
        "    print('-------'+'-'*len(model))\n",
        "    print('The precision for this classifier is ' + str(val['precision']))\n",
        "    print('The recall for this classifier is    ' + str(val['recall']))\n",
        "    print('The f1 for this classifier is        ' + str(val['f1_score']))\n",
        "    print('The accuracy for this classifier is  ' + str(val['accuracy']))\n",
        "    print('Here is the classification report:')\n",
        "    print(val['clf_report'])"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------\n",
            "MODEL: Nearest Neighbors\n",
            "------------------------\n",
            "The precision for this classifier is [0.40271493 0.42284282 0.42910171 0.45731633 0.76112917]\n",
            "The recall for this classifier is    [0.33271028 0.28882367 0.3101413  0.34361314 0.85424157]\n",
            "The f1 for this classifier is        [0.36438076 0.34321418 0.36004983 0.39239385 0.8050018 ]\n",
            "The accuracy for this classifier is  0.6780292247841351\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.40      0.33      0.36      7490\n",
            "           2       0.42      0.29      0.34      4089\n",
            "           3       0.43      0.31      0.36      5591\n",
            "           4       0.46      0.34      0.39     10960\n",
            "           5       0.76      0.85      0.81     56182\n",
            "\n",
            "    accuracy                           0.68     84312\n",
            "   macro avg       0.49      0.43      0.45     84312\n",
            "weighted avg       0.65      0.68      0.66     84312\n",
            "\n",
            "------------------------------\n",
            "MODEL: Multinomial Naive Bayes\n",
            "------------------------------\n",
            "The precision for this classifier is [0.         0.         0.         0.         0.66635829]\n",
            "The recall for this classifier is    [0. 0. 0. 0. 1.]\n",
            "The f1 for this classifier is        [0.         0.         0.         0.         0.79977793]\n",
            "The accuracy for this classifier is  0.6663582882626435\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00      7490\n",
            "           2       0.00      0.00      0.00      4089\n",
            "           3       0.00      0.00      0.00      5591\n",
            "           4       0.00      0.00      0.00     10960\n",
            "           5       0.67      1.00      0.80     56182\n",
            "\n",
            "    accuracy                           0.67     84312\n",
            "   macro avg       0.13      0.20      0.16     84312\n",
            "weighted avg       0.44      0.67      0.53     84312\n",
            "\n",
            "--------------------------\n",
            "MODEL: Logistic Regression\n",
            "--------------------------\n",
            "The precision for this classifier is [0.24675325 0.         0.21621622 0.         0.66693599]\n",
            "The recall for this classifier is    [0.00253672 0.         0.00286174 0.         0.99907444]\n",
            "The f1 for this classifier is        [0.00502181 0.         0.00564872 0.         0.79989739]\n",
            "The accuracy for this classifier is  0.6661566562292438\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.25      0.00      0.01      7490\n",
            "           2       0.00      0.00      0.00      4089\n",
            "           3       0.22      0.00      0.01      5591\n",
            "           4       0.00      0.00      0.00     10960\n",
            "           5       0.67      1.00      0.80     56182\n",
            "\n",
            "    accuracy                           0.67     84312\n",
            "   macro avg       0.23      0.20      0.16     84312\n",
            "weighted avg       0.48      0.67      0.53     84312\n",
            "\n",
            "----------\n",
            "MODEL: LDA\n",
            "----------\n",
            "The precision for this classifier is [0.31521739 0.         0.18596491 0.         0.66758801]\n",
            "The recall for this classifier is    [0.00387183 0.         0.00947952 0.         0.9973657 ]\n",
            "The f1 for this classifier is        [0.0076497  0.         0.01803948 0.         0.7998173 ]\n",
            "The accuracy for this classifier is  0.6655754815447386\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.32      0.00      0.01      7490\n",
            "           2       0.00      0.00      0.00      4089\n",
            "           3       0.19      0.01      0.02      5591\n",
            "           4       0.00      0.00      0.00     10960\n",
            "           5       0.67      1.00      0.80     56182\n",
            "\n",
            "    accuracy                           0.67     84312\n",
            "   macro avg       0.23      0.20      0.17     84312\n",
            "weighted avg       0.49      0.67      0.53     84312\n",
            "\n",
            "----------\n",
            "MODEL: QDA\n",
            "----------\n",
            "The precision for this classifier is [0.08726287 0.04625658 0.06560738 0.13177019 0.66887509]\n",
            "The recall for this classifier is    [0.02149533 0.23208608 0.04578787 0.43841241 0.25696842]\n",
            "The f1 for this classifier is        [0.03449384 0.07713879 0.05393448 0.20263574 0.37129337]\n",
            "The accuracy for this classifier is  0.24442546731188916\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.09      0.02      0.03      7490\n",
            "           2       0.05      0.23      0.08      4089\n",
            "           3       0.07      0.05      0.05      5591\n",
            "           4       0.13      0.44      0.20     10960\n",
            "           5       0.67      0.26      0.37     56182\n",
            "\n",
            "    accuracy                           0.24     84312\n",
            "   macro avg       0.20      0.20      0.15     84312\n",
            "weighted avg       0.48      0.24      0.28     84312\n",
            "\n",
            "--------------------\n",
            "MODEL: Random Forest\n",
            "--------------------\n",
            "The precision for this classifier is [0.95498938 0.98675497 0.96873255 0.96800914 0.7424891 ]\n",
            "The recall for this classifier is    [0.30026702 0.29151382 0.31032016 0.30921533 0.99722331]\n",
            "The f1 for this classifier is        [0.45688167 0.45006608 0.47006231 0.46870894 0.85120671]\n",
            "The accuracy for this classifier is  0.7660949805484392\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.95      0.30      0.46      7490\n",
            "           2       0.99      0.29      0.45      4089\n",
            "           3       0.97      0.31      0.47      5591\n",
            "           4       0.97      0.31      0.47     10960\n",
            "           5       0.74      1.00      0.85     56182\n",
            "\n",
            "    accuracy                           0.77     84312\n",
            "   macro avg       0.92      0.44      0.54     84312\n",
            "weighted avg       0.82      0.77      0.72     84312\n",
            "\n",
            "---------------\n",
            "MODEL: AdaBoost\n",
            "---------------\n",
            "The precision for this classifier is [0.33333333 0.         0.5        0.         0.66643732]\n",
            "The recall for this classifier is    [4.00534045e-04 0.00000000e+00 1.78858880e-04 0.00000000e+00\n",
            " 9.99964401e-01]\n",
            "The f1 for this classifier is        [8.00106681e-04 0.00000000e+00 3.57589844e-04 0.00000000e+00\n",
            " 7.99823464e-01]\n",
            "The accuracy for this classifier is  0.6663820096783376\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.33      0.00      0.00      7490\n",
            "           2       0.00      0.00      0.00      4089\n",
            "           3       0.50      0.00      0.00      5591\n",
            "           4       0.00      0.00      0.00     10960\n",
            "           5       0.67      1.00      0.80     56182\n",
            "\n",
            "    accuracy                           0.67     84312\n",
            "   macro avg       0.30      0.20      0.16     84312\n",
            "weighted avg       0.51      0.67      0.53     84312\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOGUftTYoYOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is not giving expected accuracy because some topics, though they seem similar have different sentiments. So adding a sentimnt layer."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwBjFPbR3Jkt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a2c3cd5d-2285-4e58-ee12-9bb12aa617d3"
      },
      "source": [
        "all_text_train[1][0]"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'s'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2XCxU9goeRx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "3a7d12ab-de43-47ff-d217-bfb3550ed742"
      },
      "source": [
        "#Adding Sentiment Column using Logistic Regression\n",
        "vectorizer = TfidfVectorizer()\n",
        "sentimentXtrain = vectorizer.fit_transform(all_text_train)\n",
        "sentimentXtest = vectorizer.transform(all_text_test)\n",
        "\n",
        "sentimentYtrain = topic_dist_train_1_2_3_4_5_df['Sentiment']\n",
        "sentimentYtest = topic_dist_test_1_2_3_4_5_df['Sentiment']\n",
        "\n",
        "nb_classifier = LogisticRegression().fit(sentimentXtrain, sentimentYtrain)\n",
        "\n",
        "ySentimentTrain = nb_classifier.predict(sentimentXtrain)\n",
        "ySentimentTest = nb_classifier.predict(sentimentXtest)\n",
        "\n",
        "topic_dist_train_1_2_3_4_5_df['Sentiment_Predicted'] = ySentimentTrain\n",
        "topic_dist_test_1_2_3_4_5_df['Sentiment_Predicted'] = ySentimentTest"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSrM34mmotKO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "outputId": "ca8a549f-9c4d-48e8-9ae2-da83d471d57b"
      },
      "source": [
        "clfs = [KNeighborsClassifier(), MultinomialNB(), LogisticRegression()]\n",
        "clf_names = ['Nearest Neighbors', 'Multinomial Naive Bayes', 'Logistic Regression']\n",
        "\n",
        "SentimentResults = {}\n",
        "for (i, clf_) in enumerate(clfs):\n",
        "    clf = clf_.fit(sentimentXtrain, sentimentYtrain)\n",
        "    preds = clf.predict(sentimentXtest)\n",
        "    \n",
        "    precision = metrics.precision_score(sentimentYtest, preds,average=None)\n",
        "    recall = metrics.recall_score(sentimentYtest, preds,average=None)\n",
        "    f1 = metrics.f1_score(sentimentYtest, preds,average=None)\n",
        "    accuracy = accuracy_score(sentimentYtest, preds)\n",
        "    report = classification_report(sentimentYtest, preds)\n",
        "    matrix = metrics.confusion_matrix(sentimentYtest, preds, labels=np.array(list(starsGroup.groups.keys())))\n",
        "    \n",
        "    data = {'precision':precision,\n",
        "            'recall':recall,\n",
        "            'f1_score':f1,\n",
        "            'accuracy':accuracy,\n",
        "            'clf_report':report,\n",
        "            'clf_matrix':matrix,\n",
        "            'y_predicted':preds}\n",
        "    \n",
        "    SentimentResults[clf_names[i]] = data\n",
        "    \n",
        "cols = ['precision', 'recall', 'f1_score', 'accuracy']\n",
        "pd.DataFrame(SentimentResults).T[cols].T"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Nearest Neighbors</th>\n",
              "      <th>Multinomial Naive Bayes</th>\n",
              "      <th>Logistic Regression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>[0.0, 0.7963516462662492]</td>\n",
              "      <td>[0.0, 0.7963516462662492]</td>\n",
              "      <td>[0.0, 0.7963516462662492]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>[0.0, 1.0]</td>\n",
              "      <td>[0.0, 1.0]</td>\n",
              "      <td>[0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1_score</th>\n",
              "      <td>[0.0, 0.8866322447739908]</td>\n",
              "      <td>[0.0, 0.8866322447739908]</td>\n",
              "      <td>[0.0, 0.8866322447739908]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.796352</td>\n",
              "      <td>0.796352</td>\n",
              "      <td>0.796352</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Nearest Neighbors  ...        Logistic Regression\n",
              "precision  [0.0, 0.7963516462662492]  ...  [0.0, 0.7963516462662492]\n",
              "recall                    [0.0, 1.0]  ...                 [0.0, 1.0]\n",
              "f1_score   [0.0, 0.8866322447739908]  ...  [0.0, 0.8866322447739908]\n",
              "accuracy                    0.796352  ...                   0.796352\n",
              "\n",
              "[4 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xis4JxfqozQg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "7e65e30a-e35b-414c-d377-f8299d58845c"
      },
      "source": [
        "for model, val in SentimentResults.items():\n",
        "    print('-------'+'-'*len(model))\n",
        "    print('MODEL:', model)\n",
        "    print('-------'+'-'*len(model))\n",
        "    print('The precision for this classifier is ' + str(val['precision']))\n",
        "    print('The recall for this classifier is    ' + str(val['recall']))\n",
        "    print('The f1 for this classifier is        ' + str(val['f1_score']))\n",
        "    print('The accuracy for this classifier is  ' + str(val['accuracy']))\n",
        "    print('Here is the classification report:')\n",
        "    print(val['clf_report'])"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------\n",
            "MODEL: Nearest Neighbors\n",
            "------------------------\n",
            "The precision for this classifier is [0.         0.79635165]\n",
            "The recall for this classifier is    [0. 1.]\n",
            "The f1 for this classifier is        [0.         0.88663224]\n",
            "The accuracy for this classifier is  0.7963516462662492\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00     17170\n",
            "           1       0.80      1.00      0.89     67142\n",
            "\n",
            "    accuracy                           0.80     84312\n",
            "   macro avg       0.40      0.50      0.44     84312\n",
            "weighted avg       0.63      0.80      0.71     84312\n",
            "\n",
            "------------------------------\n",
            "MODEL: Multinomial Naive Bayes\n",
            "------------------------------\n",
            "The precision for this classifier is [0.         0.79635165]\n",
            "The recall for this classifier is    [0. 1.]\n",
            "The f1 for this classifier is        [0.         0.88663224]\n",
            "The accuracy for this classifier is  0.7963516462662492\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00     17170\n",
            "           1       0.80      1.00      0.89     67142\n",
            "\n",
            "    accuracy                           0.80     84312\n",
            "   macro avg       0.40      0.50      0.44     84312\n",
            "weighted avg       0.63      0.80      0.71     84312\n",
            "\n",
            "--------------------------\n",
            "MODEL: Logistic Regression\n",
            "--------------------------\n",
            "The precision for this classifier is [0.         0.79635165]\n",
            "The recall for this classifier is    [0. 1.]\n",
            "The f1 for this classifier is        [0.         0.88663224]\n",
            "The accuracy for this classifier is  0.7963516462662492\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00     17170\n",
            "           1       0.80      1.00      0.89     67142\n",
            "\n",
            "    accuracy                           0.80     84312\n",
            "   macro avg       0.40      0.50      0.44     84312\n",
            "weighted avg       0.63      0.80      0.71     84312\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obTEPdP7ozJC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LDA with sentiment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gct-znH2ozDq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "cede6aad-ce69-4a4c-af96-7b6b6e9858ef"
      },
      "source": [
        "features = list(topic_dist_train_1_2_3_4_5_df.columns[:numTopics])\n",
        "features.append(topic_dist_train_1_2_3_4_5_df.columns[numTopics+2])\n",
        "print(features)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Topic1', 'Topic2', 'Topic3', 'Topic4', 'Topic5', 'Topic6', 'Topic7', 'Topic8', 'Topic9', 'Topic10', 'Topic11', 'Topic12', 'Topic13', 'Topic14', 'Topic15', 'Topic16', 'Topic17', 'Topic18', 'Topic19', 'Topic20', 'Topic21', 'Topic22', 'Topic23', 'Topic24', 'Topic25', 'Sentiment_Predicted']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83urZm61_sqV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "2556a63c-db9b-4d4e-8af2-c4c2cfb08a91"
      },
      "source": [
        "x_train = topic_dist_train_1_2_3_4_5_df[features]\n",
        "y_train = topic_dist_train_1_2_3_4_5_df['Star']\n",
        "\n",
        "x_test = topic_dist_test_1_2_3_4_5_df[features]\n",
        "y_test = topic_dist_test_1_2_3_4_5_df['Star'] \n",
        "\n",
        "clfs = [KNeighborsClassifier(), MultinomialNB(), LogisticRegression(), LDA(), QDA(), RandomForestClassifier(n_estimators=100, n_jobs=2), AdaBoostClassifier(n_estimators=100)]\n",
        "clf_names = ['Nearest Neighbors', 'Multinomial Naive Bayes', 'Logistic Regression', 'LDA', 'QDA', 'Random Forest', 'AdaBoost']\n",
        "\n",
        "FinalResults = {}\n",
        "for (i, clf_) in enumerate(clfs):\n",
        "    clf = clf_.fit(x_train, y_train)\n",
        "    preds = clf.predict(x_test)\n",
        "    \n",
        "    precision = metrics.precision_score(y_test, preds,average=None)\n",
        "    recall = metrics.recall_score(y_test, preds,average=None)\n",
        "    f1 = metrics.f1_score(y_test, preds,average=None)\n",
        "    accuracy = accuracy_score(y_test, preds)\n",
        "    report = classification_report(y_test, preds)\n",
        "    matrix = metrics.confusion_matrix(y_test, preds, labels=np.array(list(starsGroup.groups.keys())))\n",
        "    \n",
        "    data = {'precision':precision,\n",
        "            'recall':recall,\n",
        "            'f1_score':f1,\n",
        "            'accuracy':accuracy,\n",
        "            'clf_report':report,\n",
        "            'clf_matrix':matrix,\n",
        "            'y_predicted':preds}\n",
        "    \n",
        "    FinalResults[clf_names[i]] = data"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYEiYinpAEf3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "690680d0-22e9-446e-aa01-8bae525d22f3"
      },
      "source": [
        "cols = ['precision', 'recall', 'f1_score', 'accuracy']\n",
        "pd.DataFrame(FinalResults).T[cols].T"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Nearest Neighbors</th>\n",
              "      <th>Multinomial Naive Bayes</th>\n",
              "      <th>Logistic Regression</th>\n",
              "      <th>LDA</th>\n",
              "      <th>QDA</th>\n",
              "      <th>Random Forest</th>\n",
              "      <th>AdaBoost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>[0.5501618122977346, 0.5211267605633803, 0.472...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.6663582882626435]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.6663701384193859]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.666366191837364]</td>\n",
              "      <td>[0.12635692574902302, 0.03966942148760331, 0.0...</td>\n",
              "      <td>[0.998, 0.9929078014184397, 0.9908069458631257...</td>\n",
              "      <td>[1.0, 0.0, 0.5, 0.0, 0.666437316124134]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>[0.04539385847797063, 0.07238933724627049, 0.1...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.9999822007048521]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "      <td>[0.03885180240320427, 0.00586940572267058, 0.1...</td>\n",
              "      <td>[0.06662216288384512, 0.10271460014673514, 0.1...</td>\n",
              "      <td>[0.0012016021361815755, 0.0, 0.000178858880343...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1_score</th>\n",
              "      <td>[0.08386778490379873, 0.12712046381790854, 0.2...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.799777926459493]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.7997807688748746]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.799783619112696]</td>\n",
              "      <td>[0.059430205248647, 0.010225820195994889, 0.09...</td>\n",
              "      <td>[0.12490613266583228, 0.18617021276595747, 0.2...</td>\n",
              "      <td>[0.0024003200426723566, 0.0, 0.000357589844448...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.680283</td>\n",
              "      <td>0.666358</td>\n",
              "      <td>0.666346</td>\n",
              "      <td>0.666358</td>\n",
              "      <td>0.321034</td>\n",
              "      <td>0.723966</td>\n",
              "      <td>0.666429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Nearest Neighbors  ...                                           AdaBoost\n",
              "precision  [0.5501618122977346, 0.5211267605633803, 0.472...  ...            [1.0, 0.0, 0.5, 0.0, 0.666437316124134]\n",
              "recall     [0.04539385847797063, 0.07238933724627049, 0.1...  ...  [0.0012016021361815755, 0.0, 0.000178858880343...\n",
              "f1_score   [0.08386778490379873, 0.12712046381790854, 0.2...  ...  [0.0024003200426723566, 0.0, 0.000357589844448...\n",
              "accuracy                                            0.680283  ...                                           0.666429\n",
              "\n",
              "[4 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "143g46hFAHOd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "34966009-3dbf-4594-86ac-c10d19823dc9"
      },
      "source": [
        "for model, val in FinalResults.items():\n",
        "    print('-------'+'-'*len(model))\n",
        "    print('MODEL:', model)\n",
        "    print('-------'+'-'*len(model))\n",
        "    print('The precision for this classifier is ' + str(val['precision']))\n",
        "    print('The recall for this classifier is    ' + str(val['recall']))\n",
        "    print('The f1 for this classifier is        ' + str(val['f1_score']))\n",
        "    print('The accuracy for this classifier is  ' + str(val['accuracy']))\n",
        "    print('Here is the classification report:')\n",
        "    print(val['clf_report'])"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------\n",
            "MODEL: Nearest Neighbors\n",
            "------------------------\n",
            "The precision for this classifier is [0.55016181 0.52112676 0.47280122 0.44114271 0.71375378]\n",
            "The recall for this classifier is    [0.04539386 0.07238934 0.16633876 0.31560219 0.93145491]\n",
            "The f1 for this classifier is        [0.08386778 0.12712046 0.24609685 0.36795915 0.80820077]\n",
            "The accuracy for this classifier is  0.6802827592750735\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.55      0.05      0.08      7490\n",
            "           2       0.52      0.07      0.13      4089\n",
            "           3       0.47      0.17      0.25      5591\n",
            "           4       0.44      0.32      0.37     10960\n",
            "           5       0.71      0.93      0.81     56182\n",
            "\n",
            "    accuracy                           0.68     84312\n",
            "   macro avg       0.54      0.31      0.33     84312\n",
            "weighted avg       0.64      0.68      0.62     84312\n",
            "\n",
            "------------------------------\n",
            "MODEL: Multinomial Naive Bayes\n",
            "------------------------------\n",
            "The precision for this classifier is [0.         0.         0.         0.         0.66635829]\n",
            "The recall for this classifier is    [0. 0. 0. 0. 1.]\n",
            "The f1 for this classifier is        [0.         0.         0.         0.         0.79977793]\n",
            "The accuracy for this classifier is  0.6663582882626435\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00      7490\n",
            "           2       0.00      0.00      0.00      4089\n",
            "           3       0.00      0.00      0.00      5591\n",
            "           4       0.00      0.00      0.00     10960\n",
            "           5       0.67      1.00      0.80     56182\n",
            "\n",
            "    accuracy                           0.67     84312\n",
            "   macro avg       0.13      0.20      0.16     84312\n",
            "weighted avg       0.44      0.67      0.53     84312\n",
            "\n",
            "--------------------------\n",
            "MODEL: Logistic Regression\n",
            "--------------------------\n",
            "The precision for this classifier is [0.         0.         0.         0.         0.66637014]\n",
            "The recall for this classifier is    [0.        0.        0.        0.        0.9999822]\n",
            "The f1 for this classifier is        [0.         0.         0.         0.         0.79978077]\n",
            "The accuracy for this classifier is  0.6663464275547964\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00      7490\n",
            "           2       0.00      0.00      0.00      4089\n",
            "           3       0.00      0.00      0.00      5591\n",
            "           4       0.00      0.00      0.00     10960\n",
            "           5       0.67      1.00      0.80     56182\n",
            "\n",
            "    accuracy                           0.67     84312\n",
            "   macro avg       0.13      0.20      0.16     84312\n",
            "weighted avg       0.44      0.67      0.53     84312\n",
            "\n",
            "----------\n",
            "MODEL: LDA\n",
            "----------\n",
            "The precision for this classifier is [0.         0.         0.         0.         0.66636619]\n",
            "The recall for this classifier is    [0. 0. 0. 0. 1.]\n",
            "The f1 for this classifier is        [0.         0.         0.         0.         0.79978362]\n",
            "The accuracy for this classifier is  0.6663582882626435\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00      7490\n",
            "           2       0.00      0.00      0.00      4089\n",
            "           3       0.00      0.00      0.00      5591\n",
            "           4       0.00      0.00      0.00     10960\n",
            "           5       0.67      1.00      0.80     56182\n",
            "\n",
            "    accuracy                           0.67     84312\n",
            "   macro avg       0.13      0.20      0.16     84312\n",
            "weighted avg       0.44      0.67      0.53     84312\n",
            "\n",
            "----------\n",
            "MODEL: QDA\n",
            "----------\n",
            "The precision for this classifier is [0.12635693 0.03966942 0.08455772 0.13461923 0.67797581]\n",
            "The recall for this classifier is    [0.0388518  0.00586941 0.10087641 0.55337591 0.35817522]\n",
            "The f1 for this classifier is        [0.05943021 0.01022582 0.09199902 0.21655687 0.46872343]\n",
            "The accuracy for this classifier is  0.3210337792959484\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.13      0.04      0.06      7490\n",
            "           2       0.04      0.01      0.01      4089\n",
            "           3       0.08      0.10      0.09      5591\n",
            "           4       0.13      0.55      0.22     10960\n",
            "           5       0.68      0.36      0.47     56182\n",
            "\n",
            "    accuracy                           0.32     84312\n",
            "   macro avg       0.21      0.21      0.17     84312\n",
            "weighted avg       0.49      0.32      0.35     84312\n",
            "\n",
            "--------------------\n",
            "MODEL: Random Forest\n",
            "--------------------\n",
            "The precision for this classifier is [0.998      0.9929078  0.99080695 0.9754522  0.70769347]\n",
            "The recall for this classifier is    [0.06662216 0.1027146  0.17349311 0.27554745 0.99907444]\n",
            "The f1 for this classifier is        [0.12490613 0.18617021 0.29528158 0.42970973 0.82851154]\n",
            "The accuracy for this classifier is  0.7239657462757377\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.07      0.12      7490\n",
            "           2       0.99      0.10      0.19      4089\n",
            "           3       0.99      0.17      0.30      5591\n",
            "           4       0.98      0.28      0.43     10960\n",
            "           5       0.71      1.00      0.83     56182\n",
            "\n",
            "    accuracy                           0.72     84312\n",
            "   macro avg       0.93      0.32      0.37     84312\n",
            "weighted avg       0.80      0.72      0.65     84312\n",
            "\n",
            "---------------\n",
            "MODEL: AdaBoost\n",
            "---------------\n",
            "The precision for this classifier is [1.         0.         0.5        0.         0.66643732]\n",
            "The recall for this classifier is    [1.20160214e-03 0.00000000e+00 1.78858880e-04 0.00000000e+00\n",
            " 9.99928803e-01]\n",
            "The f1 for this classifier is        [2.40032004e-03 0.00000000e+00 3.57589844e-04 0.00000000e+00\n",
            " 7.99812070e-01]\n",
            "The accuracy for this classifier is  0.6664294525097257\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.00      0.00      7490\n",
            "           2       0.00      0.00      0.00      4089\n",
            "           3       0.50      0.00      0.00      5591\n",
            "           4       0.00      0.00      0.00     10960\n",
            "           5       0.67      1.00      0.80     56182\n",
            "\n",
            "    accuracy                           0.67     84312\n",
            "   macro avg       0.43      0.20      0.16     84312\n",
            "weighted avg       0.57      0.67      0.53     84312\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH-IqXHJAVeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv9x1rrVF6rN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Another aproach"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEikV7zBkaYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv('Reviews.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG2NtslOkaUY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "aa88c0e3-3658-4bf0-884a-8d06eada93b9"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pylab\n",
        "import re\n",
        "import scipy as sp\n",
        "import seaborn\n",
        "\n",
        "from gensim import corpora, models\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.lda import LDA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
        "# from sklearn.qda import QDA\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "plt.rc('figure', figsize=(10,6))\n",
        "seaborn.set()\n",
        "colors = seaborn.color_palette()\n",
        "%pylab inline"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['pylab']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9UppQ1KkaPS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4a7115ae-68c9-4b03-ed1a-16a30399dc04"
      },
      "source": [
        "df.isnull().sum()\n",
        "df.dropna(inplace=True)\n",
        "print(df.shape)\n",
        "print('\\n')\n",
        "\n",
        "df.drop_duplicates(subset=['ProductId','UserId','Score','Time'],inplace=True)\n",
        "print(df.shape)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(568411, 10)\n",
            "\n",
            "\n",
            "(565082, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9JkegCxkaLJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "8193cc92-bc29-4db3-c803-ff1bc47f5fd5"
      },
      "source": [
        "bins = [1, 2,3 ,4, 5, 6]\n",
        "df.Score.hist(bins=bins, align='left', width=0.93)\n",
        "xticks(bins)\n",
        "xlabel('Rating stars')\n",
        "ylabel('Number of reviews')\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaUAAAEMCAYAAABkwamIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAb/UlEQVR4nO3de5QlVX3o8W/3kMyMzPCwaUDeiM5Pg0QR8c5VQFg3GmMc0UiMRBhiREVEV5RcUUR85XqJDF5UMBAJioCoRAVfCcaliCOQKHFEIP4YCY9BBZoeXqMMj+m+f1Q1Hke6u3rm1KnqPt/PWmfNObWrTv324XB+vXft2ntgfHwcSZLaYLDpACRJmmBSkiS1hklJktQaJiVJUmuYlCRJrbFF0wHMMvOB/YFfAhsajkWSZot5wJOAHwAPTbWjSWlm9ge+13QQkjRLHQisnGoHk9LM/BLgnnt+xdhY++/vGhpaxOjouqbD6Il+qav1nFv6pZ6DgwNsu+2WUP6GTsWkNDMbAMbGxmdFUgJmTZzd0C91tZ5zS7/UszTtZQ8HOkiSWsOkJElqDZOSJKk1TEqSpNYwKUmSWsOkJElqDZOSJKk1vE9JkoDFWy1kwfze/yQODy+u9f3XP/QoD9z/YK3n6CaTkiQBC+ZvwbLjL206jK776mmH8kDTQcyA3XeSpNboWUspIi4B9gTGgHXAWzJzVUTcAqwvHwAnZOZl5TFLgbOBhcAtwBGZeVddZZKkZvWypXRUZj4zM/cFVgDndpQdlpnPKh8TCWkQuAB4c2YuAa4ATqmrTJLUvJ4lpcy8r+Pl1hQtpqnsB6zPzIlpzs8CXlVjmSSpYT0d6BAR5wAvAgaAF3cUXRgRAxTrbJyYmfcCuwG3TuyQmXdHxGBEPLGOssxcW7UeQ0OLZlbxBtU9sqdN+qWu1lMzNZs+y54mpcw8GiAijgROBV4CHJiZayJiPnA6cAZwRC/jmqnR0XWzYrr54eHFjIzMpnE3m65f6mo96z3nXNX0d2ZwcKDyH/ONjL7LzPOBQyJiKDPXlNseAj4BPL/c7TZg94ljImI7YKxs0dRRJklqWE+SUkQsiohdO14vA9YC6yNi63LbAPBqYFW52zXAwog4oHx9DHBxjWWSpIb1qvtuS+DiiNiSYuXBtcAyYAfgixExD5gH3AAcC5CZY2U339kRsYBy+HZdZZKk5vUkKWXmncDSSYr3neK4K4F9elUmSWqWMzpIklrDpCRJag2TkiSpNUxKkqTWMClJklrDpCRJag2TkiSpNUxKkqTWMClJklrDpCRJag2TkiSpNUxKkqTWMClJklrDpCRJag2TkiSpNUxKkqTWMClJklrDpCRJag2TkiSpNbbo1Yki4hJgT2AMWAe8JTNXRcQS4DxgCBgFlmfm6vKYnpZJkprVy5bSUZn5zMzcF1gBnFtuPws4MzOXAGcCZ3cc0+sySVKDetZSysz7Ol5uDYxFxPbAs4EXltsvAs6IiGFgoJdlmTnSzfpKkmaup9eUIuKciLgN+D/AUcCuwM8zcwNA+e8vyu29LpMkNaxnLSWAzDwaICKOBE4F3tPL83fL0NCipkOobHh4cdMh9Ey/1NV6aqZm02fZ06Q0ITPPj4h/BG4Hdo6IeZm5ISLmATsBayi62npZVtno6DrGxsa78VHUanh4MSMjDzQdRk/0S12tZ73nnKua/s4MDg5U/mO+J913EbEoInbteL0MWAvcBawCDi+LDgd+lJkjmdnTsu7XWpI0U71qKW0JXBwRWwIbKBLSsswcj4hjgPMi4mTgHmB5x3G9LpMkNagnSSkz7wSWTlL2U+B/tKFMktQsZ3SQJLWGSUmS1BomJUlSa2xSUoqIhRExv9vBSJL6W6WkFBErIuK55fM/pRg9d085tFuSpK6o2lJ6DXBd+fxk4AjgZcCH6ghKktSfqg4Jf0Jm/joihoAnZ+YXASJi9/pCkyT1m6pJ6caIeA3wFODfACJiO+DBugKTJPWfqknpzcDpwMPA68ptfwx8s46gJEn9qVJSysz/AJ630bYLgQvrCEqS1J8qJaWI+BLwXeDyzPxxvSFJkvpV1e67rwEvAN4WEVsBKymS1BWZ+YO6gpMk9Zeq3XfnAufCYyPu3kAxNHwRMK+26CRJfaVq993TgYMoWksHAHcAZ1O0liRJ6oqq3XfXAzcB/xd4Q2auqy8kSVK/qpqUjqRoKf0t8I6IuILfXFOa0VLikiRNpuo1pceGf0fEjsBbgE/gNSVJUhdVvaa0L3AwxTWlAylmcvgaXlOSJHVR1e67L1MkoK8Ax2fmTfWFJEnqV1W77/aoOQ5Jkip33w0ARwOHA9tl5h9GxEHAjpn5hQrHDwHnA3tRzJ+3GnhjZo5ExDjwE2Cs3P3IzPxJedwy4NQyzmuA12bmr+sqkyQ1q+p6Sh+gmIj1H4Hdym23AydUPH4c+HBmRmbuQzG8/JSO8udl5rPKx0RCWgR8EliWmU8BHqAY/VdLmSSpeVWT0l8BL83Mz1EkGICbgSdXOTgz12bm5R2brgamW4vpT4AfZubq8vVZwF/UWCZJaljVgQ7zgIkbZieS0qKObZVFxCDwJopBExMuj4gtgH8B3peZD1G0yG7t2Oc2YNfyeR1lkqSGVU1K3wA+EhFvg8euMX0Q+OomnPPjFMnsjPL1bpm5ppzo9XzgPcBJm/C+PTM0tKjpECobHl7cdAg90y91tZ6aqdn0WVZNSm8HzgPuA36PIql8E1g+k5NFxArgqRTXdMYAJmaEyMz7I+Kc8lxQtGIO6Th8N2BNjWWVjY6uY2xsfPodGzY8vJiRkQeaDqMn+qWu1rPec85VTX9nBgcHKv8xX+maUmben5mvoLgOtBTYKzNfkZmVaxoRHwL2A15eds8REdtGxMLy+RbAYcCq8pB/BfaPiKeWr48BvlBjmSSpYZMmpbKLbuL5YHktaIRiGPVdHdumFRF7A+8CdgKujIhVEfFl4GnAv0fEj4FrgUcouu8oE94bgK9FxM+ArYEVdZVJkpo3VffdfcBW5fNH+c0AhwkD5bZp577LzOvL/R/PH05x3KXApb0qkyQ1a6qktHfH8z3rDkSSpEmT0kZLUmybmasm21eSpG6oOvrumxExAlwEfDYz/7vGmCRJfapqUnoS8GKKue9WRcT1wGeBz2fmXXUFJ0nqL1VnCd8AfB34ejmE+1CKWRlWAPPrC0+S1E+qzn0HQEQsAF5KMV/cc4Dv1RGUJKk/VV264iXAXwIvA24APge8KTPvqDE2SVKfqXpNaQXFIId9XXVWklSXqteU/qDuQCRJqtp9Nx84mWL03VBmbh0RLwKWZOYZUx8tSVI1VQc6nA48A3gNv5lu6HqKEXiSJHVF1aT0cuAvM/MqYGLJiZ8DO9cVmCSp/1RNSg+zUVdfRAwDo12PSJLUt6ompYuB8yJiT4CIeBLFyrGfqyswSVL/qZqUTgRuBn4CbAOsBn4BvL+muCRJfWja0XcRMQ84CXhnZr6t7La7OzPbvx64JGlWmbalVM57dyzFqrBk5ogJSZJUh6rdd58BjqkzEEmSqk4z9FzgLRHxDmANHUujZ+ZBdQQmSeo/VZPSJ8uHJEm1qTr33Xmbc5KIGALOB/aiuOdpNfDGzByJiKXA2cBC4BbgiImFA3tdJklq1ozWU9oM48CHMzMycx/gJuCUiBgELgDenJlLgCuAUwB6XSZJal5PklJmrs3Myzs2XQ3sDuwHrM/MleX2s4BXlc97XSZJalivWkqPKVsrbwK+AuwG3DpRlpl3A4MR8cQGyiRJDZv0mlJEXJ2ZS8vn783Mbs3e8HFgHcU0Ra/o0nv21NDQoqZDqGx4eHHTIfRMv9TVemqmZtNnOdVAhyURsSAz1wPH04UphSJiBfBUYFlmjkXEbRTdeBPl2wFjmbm212Uzqcfo6DrGxtp///Dw8GJGRh5oOoye6Je6Ws96zzlXNf2dGRwcqPzH/FTdd5cCN0bEFcDCiLji8R5Vg4qID1Fc03l5Zj5Ubr6mfO8DytfHUEz+2kSZJKlhk7aUMvO15Y/3HsD+wD9t6kkiYm/gXcCNwJURAXBzZr4iIo4Ezo6IBZRDtMvzj/WyTJLUvIHx8em7oSLirzPz3B7E03Z7ADfbfdc+/VJX61nvOZcdf2lPz9kLXz3t0Ma/Mx3dd3tSNAYmVfXm2XMj4mBgOcVqsz8Hzs/M72xWpJIkdag0JDwijga+ANwBfAn4JXBRRLy+xtgkSX2m6tx37wBemJk/ntgQEZ8Hvohz4kmSuqTqzbNDwA0bbUvAm04lSV1TNSmtBD4SEU8AiIgtgVOBK+sKTJLUf6ompWOAZwL3RcSdwL3l6zfWFZgkqf9UHX33S+CgiNgF2An4RWbeXmtkkqS+U3WgAwBlIjIZSZJq0fNZwiVJmoxJSZLUGtN235XrHx0MrMzMh2uPSJLUt6ZtKWXmGHCpCUmSVLeq3XdXRMTSWiORJPW9qqPvbgX+JSIuBdYAj02RnZkn1xGYJKn/VE1KC4FLyue71BSLJKnPVb159rV1ByJJUuWbZyPiacCfAztk5nFRLB87PzOvrS06SVJfqbqe0p8D36NY4G95uXkx8JGa4pIk9aGqo+8+APxRZh4DbCi3/ZhiUlZJkrqialLaHpjophvv+Hf88XeXJGnmql5TugY4EvhMx7ZXA/9R9UQRsQJ4JbAHsE9mXlduvwVYXz4ATsjMy8qypcDZFKP/bgGOyMy76iqTJDWrakvprcDfRcR3gS0j4jLgg8DbZnCuS4CDKO552thhmfms8jGRkAaBC4A3Z+YS4ArglLrKJEnNq5SUMvOnwNOAM4GTgE9RtHZWVz1RZq7MzDUziG0/YH1mrixfnwW8qsYySVLDKg8Jz8xfR8T3gZspFvlb18U4LoyIAYpl10/MzHuB3ehoVWXm3RExGBFPrKMsM9dWDXZoaNGm17THhocXNx1Cz/RLXa2nZmo2fZaVklJE7AZcCCwF7gG2jYirKa7HPF533EwcmJlrImI+cDpwBnDEZr5nrUZH1zE21v4xHsPDixkZeaDpMHqiX+pqPes951zV9HdmcHCg8h/zVa8pnUcx2GGbzNwe2Bb4Ybl9s0x06WXmQ8AngOeXRbcBu0/sFxHbAWNli6aOMklSw6ompf2A/52ZvwIou+5OKLdvsojYMiK2Lp8PUIzoW1UWXwMsjIgDytfHABfXWCZJaljVpHQ18NyNtj0HuKrqiSLiYxFxO8WErt+KiOuBHYDLI+Ja4DpgCXAsPLaO05HAP0TEauAFwDvrKpMkNW/Sa0oR8YGOlzcB34iIr1MsXbEr8BLgs1VPlJlvpRhavrF9pzjmSmCfXpVJkpo11UCHXTd6/aXy3+2Bh4AvAwvqCEqS1J8mTUouVyFJ6rWZLF3xBOApwG+N6yu7wyRJ2mxV71NaTnH/0MPAgx1F4xQ3pEqStNmqtpQ+DLwyM/+tzmAkSf2t6pDwh4HLa4xDkqTKSek9wEfKGRAkSapF1e67GylWnz02Iia2DQDjmTmvjsAkSf2nalI6n2KBv8/z2wMdJEnqmqpJaQg4OTPbPzW2JGnWqnpN6VMUc8ZJklSbqi2l5wLHRcS7gTs7CzLzoK5HJUnqS1WT0ifLhyRJtamUlDJzsxfzkyRpOlWnGfrrycoy89zuhSNJ6mdVu+82HuSwI7AX8H3ApCRJ6oqq3XeHbLytbD09vesRSZL6VtUh4Y/n08DruhSHJEmVryltnLyeABwB3Nv1iCRJfavqNaVHKdZO6vRz4PVVDo6IFcArgT2AfTLzunL7EuA8ihkjRoHlmbm6iTJJUvOqdt/tCTy547FDZu6WmZdVPP4S4CDg1o22nwWcmZlLgDOBsxsskyQ1rOpAh42TyYxk5kqAjhnGiYjtgWcDLyw3XQScERHDFDOQ96wsM0c2p36SpO6YMilFxHf43W67TuOZ+b828dy7Aj/PzA0AmbkhIn5Rbh/ocZlJSZJaYLqW0gWTbN8ZeCvFgIe+MzS0qOkQKhseXtx0CD3TL3W1npqp2fRZTpmUMvOfOl9HxBDwLooBDp+nWPhvU60Bdo6IeWWrZR6wU7l9oMdlMzI6uo6xsfav4jE8vJiRkQeaDqMn+qWu1rPec85VTX9nBgcHKv8xX2mgQ0RsFREfBH4G7AA8OzPfkJm3b2qQmXkXsAo4vNx0OPCjzBzpddmm1kGS1F3TXVNaCPwNcDxwOXBAZl4/05NExMeAP6OYnuhbETGamXsDxwDnRcTJwD3A8o7Del0mSWrYwPj45N1QEXEnRWvqVOCHj7dPZn67ntBaaQ/gZrvv2qdf6mo96z3nsuMv7ek5e+Grpx3a+Hemo/tuT+CWqfadbqDDgxSj7940Sfk4xX1LkiRttukGOuzRozgkSdqsCVklSeoqk5IkqTVMSpKk1jApSZJao+rSFZL61OKtFrJgfu9/KuqeYWH9Q4/ywP0P1noOzZxJSdKUFszfYs7evzP37/iafey+kyS1hklJktQaJiVJUmuYlCRJrWFSkiS1hklJktQaJiVJUmuYlCRJrWFSkiS1hklJktQaJiVJUmuYlCRJrdGKCVkj4hZgffkAOCEzL4uIpcDZwELgFuCIzLyrPKbrZZKkZrWppXRYZj6rfFwWEYPABcCbM3MJcAVwCkAdZZKk5rUpKW1sP2B9Zq4sX58FvKrGMklSw1rRfVe6MCIGgJXAicBuwK0ThZl5d0QMRsQT6yjLzLV1Vs6F0iRpem1JSgdm5pqImA+cDpwBfLnhmCY1NLRok46bqwulLag58VVVdwJui36pZy/0y2c5m+rZiqSUmWvKfx+KiE8AXwE+Cuw+sU9EbAeMZebaiLit22UziXd0dB1jY+MzquNs+lLM1MhI8+t3Dg8vbkUcdWuinv3y3e2XejZhcHCg8h/zjV9TiogtI2Lr8vkA8GpgFXANsDAiDih3PQa4uHxeR5kkqWGNJyVgB+DyiLgWuA5YAhybmWPAkcA/RMRq4AXAOwHqKJMkNa/x7rvM/G9g30nKrgT26VWZNBMOXpG6r/GkJM1WC+ZvMWcHr8z9q3NqqzZ030mSBJiUJEktYlKSJLWGSUmS1BomJUlSazj6Tl3V1DBpcKi0NBeYlNRVc3WYNDhUWuoFu+8kSa1hUpIktYZJSZLUGiYlSVJrmJQkSa1hUpIktYZJSZLUGiYlSVJrmJQkSa1hUpIktYZJSZLUGiYlSVJr9OWErBGxBDgPGAJGgeWZubrZqCRJ/dpSOgs4MzOXAGcCZzccjySJPmwpRcT2wLOBF5abLgLOiIjhzByZ5vB5AIODA5t07u23XbhJx7Xdxp/HXK0n9E9drefcsqm/WTWcf950+w6Mj4/XG03LRMR+wGcyc++ObTcAR2Tmf05z+AHA9+qMT5LmsAOBlVPt0Hctpc30A4oP9ZfAhoZjkaTZYh7wJIrf0Cn1Y1JaA+wcEfMyc0NEzAN2KrdP5yGmyfKSpMd1U5Wd+m6gQ2beBawCDi83HQ78qML1JElSzfrumhJARDyNYkj4tsA9FEPCs9moJEl9mZQkSe3Ud913kqT2MilJklrDpCRJag2TkiSpNfrxPqU5LyJWAK8E9gD2yczrmo2oHhExBJwP7AU8DKwG3jgXh/dHxCXAnsAYsA54S2auajaq+kTEe4H3Mbe/v7cA68sHwAmZeVljAdUkIhYA/w/4I4q6XpWZb5hsf5PS3HQJ8FHm/pRI48CHM/NygIg4FTgFeF2TQdXkqMy8DyAiDgXOpZjDcc6JiGcDS4Fbm46lBw6bq0m3w4cpktGSzByPiB2m2tmkNAdl5kqAiGg6lFpl5lrg8o5NVwNvaiaaek0kpNLWFC2mOSci5lPM3H84v/3fVrNQRCwClgO7ZOY4QGbeOdUxJiXNCRExSJGQvtJ0LHWJiHOAFwEDwIsbDqcuHwAuyMxb5vofVaULI2KAYvqyEzPz3qYD6rK9KNase29EHELR9XzSxB/Oj8eBDporPk7xhT+j6UDqkplHZ+ZuwInAqU3H020R8T+B5wCfaDqWHjkwM58J7E/xh8Zc/O7OA55MMZXbc4ATgC9FxFaTHWBS0qxXDux4KvAXmTknu7U6Zeb5wCHlQI+55AXA04Gby0EAuwCXRcSLmgyqLpm5pvz3IYpE/PxmI6rFbcCjFOvWkZn/DtwNLJnsALvvNKtFxIeA/YA/Lf/nnnPKfvltJ37EImIZsLZ8zBmZeQrFQBXgsdFpL52LAwEiYktgi8y8r+y+ezXFRNFzSmbeHRHfoVhU9ZsRsQTYHvjZZMeYlOagiPgY8GfAjsC3ImK0c1HDuSIi9gbeBdwIXFleg7g5M1/RaGDdtyVwcflDtoEiGS2buHCsWWkH4Ivl0jnzgBuAY5sNqTbHAOdGxGnAI8CRU107c0JWSVJreE1JktQaJiVJUmuYlCRJrWFSkiS1hklJktQaJiWpRSLirIh4T9NxSE1xSLi0GcobPHeguH9oHfCvwHGZua7CsX8FHJ2ZB9QY4rQi4nKK+ebOaTIOCWwpSd2wLDMXAc8C9qW4obdvRIQ34atr/DJJXZKZd0TEZRTJCYCIeCfweoqpVdYA787ML0fE04GzgN+LiHXAo5m5TUR8Grg9M0+KiIOBCygWSDuBojV2YmZ+qnzvIeDTFHPGJXAZcPDjtbzKhdbOAf6EYgaB1cBLgbcCBwJLI+J04NOZeVxEfJRiVpCty33/JjO/V77X+4BnUKyR8zLg7RFxLcX8bUuAB4ELM/Ptm/eJqh/ZUpK6JCJ2ofjR75zX6yaKH/2tgfcDF0TEkzLzvyimX7kqMxdl5jaTvO2O5bE7UyxeeGZEbFuWnQn8qtznqPIxmaPK99kVGCrP/WBmvptiMcjjyjiOK/f/AUVyfSLwWYppjhZ0vN+hwD8D2wAXUiwq+dHM3IpiuYIvTBGLNClbStLmuyQixoFFwLeB904UZObFHft9PiLeBTwXuLTiez8CfCAzHwW+UbaqIiJ+QLHk/TMy89fADRFxHnDwFO8zBDwlM68FrpnqpJl5QcfL0yLiJCCAH5fbrsrMS8rnD0bEI8BTImK7zLybYsFFacZMStLme3lmfisiXkDRqtgOuBcgIpYDbwf2KPddVJZXNVompAm/Lt9jmOL/3zUdZZ3PN3Y+RSvpcxGxDUW34Lsz85HH2zki/paiZbYTxbLzW20U98bneh3FAn0/jYibgfdn5temqZv0O+y+k7okM79LcY1nBUBE7A58EjgOGCq76K6jWNANih/7TTVCsU7NLh3bdp0itkcy8/2Z+QfA8yiuJy1/vDgi4kDgHcCrKJbM2Aa4ryPu3zkmM1dn5uEU187+HvjnclZzaUZMSlJ3nQ68MCKeSbHkxDhFAiEiXksxQGDCncAuEfH7Mz1JZm4AvgS8LyKeEBFP4zdJ5ndExCERsU+5VML9FN15Ewsi3kmxOuiExRQJbwTYIiJOpmgpTSoijoiI4XKRxYllCeb8govqPpOS1EWZOQJ8Bjg5M28ATgOuovjh3wf4fsfu3wauB+6IiLs34XTHUQxeuIOie+4iYLKFDnekGJhwP/BfwHfLY6AYpHBYRNxTrsV1GcX9VjcCt1KMspuqaxDgxcD15TWvjwKvzswHN6FO6nPePCvNERHx98COmTnVKDyp1RzoIM1SZZfd7wM/AfanGGxwdKNBSZvJpCTNXospuux2ougePI3qQ82lVrL7TpLUGg50kCS1hklJktQaJiVJUmuYlCRJrWFSkiS1hklJktQa/x+a8RiTXg4F7AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FGnMXqdkaHO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c23eef31-5512-4944-dc2f-dd3697482400"
      },
      "source": [
        "#Avanced model\n",
        "!pip install nlppreprocess\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nlppreprocess import NLP\n",
        "obj = NLP(replace_words=True, remove_stopwords=True, remove_punctuations=True, lemmatize=True, lemmatize_method='wordnet' )\n",
        "\n",
        "df['Text'] = df['Text'].apply(obj.process)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nlppreprocess in /usr/local/lib/python3.6/dist-packages (1.0.2)\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2-NQ_0BlUM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('Reviews_after_nlppreprocess.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld3BDGQUlUIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv('Reviews_after_nlppreprocess.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeAI_Zx0lUD4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a8663d0c-b2f9-4f18-cd32-1a69f8e7b211"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id                        0\n",
              "ProductId                 0\n",
              "UserId                    0\n",
              "ProfileName               0\n",
              "HelpfulnessNumerator      0\n",
              "HelpfulnessDenominator    0\n",
              "Score                     0\n",
              "Time                      0\n",
              "Summary                   0\n",
              "Text                      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLoe11BplT9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvuguxzckaBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn_KKRtCF6l0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(df['Text'], df['Score'], random_state = 0, test_size=0.3, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT0aEBzYF6eZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "8b341122-e3ab-4bd6-de48-cacb80cc4d19"
      },
      "source": [
        "df['Text']"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         bought several Vitality canned dog food produc...\n",
              "1         Product arrived labeled Jumbo Salted Peanuts t...\n",
              "2         confection been around few century light pillo...\n",
              "3         you are looking secret ingredient in Robitussi...\n",
              "4         Great taffy great price There wide assortment ...\n",
              "                                ...                        \n",
              "568449    Great sesame chicken this good not better than...\n",
              "568450    I m disappointed with flavor chocolate note ar...\n",
              "568451    These star are small you can give those in one...\n",
              "568452    These are BEST treat training and rewarding yo...\n",
              "568453    am very satisfied product advertised use cerea...\n",
              "Name: Text, Length: 565082, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_mxQ21TNeYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "review_lines = list()\n",
        "lines = df['Text'].values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tkdxZInWch2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7d5dc3a7-2d5d-4c69-8b12-923b571329e7"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5MSwS3up5Mv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "551bf6de-055b-4157-facc-4055e087b8f6"
      },
      "source": [
        "review_lines"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccRGLckWWk59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZQx4yxGqJtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df.isnull().sum()\n",
        "# df.dropna(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5CO7UudqzgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2wLalmgW-If",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cb2fdb86-aaff-471f-9df6-ecf288c4158c"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "for line in lines:\n",
        "  tokens = word_tokenize(line)\n",
        "  #convert to lower case\n",
        "  tokens = [w.lower() for w in tokens]\n",
        "  #remove punctuation from each word\n",
        "  table = str.maketrans('','',string.punctuation)\n",
        "  stripped = [w.translate(table) for w in tokens]\n",
        "  #remove remaining tokens that are not alphabetic\n",
        "  words = [word for word in stripped if word.isalpha()]\n",
        "  words = [w for w in words if not w in stop_words]\n",
        "  review_lines.append(words)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z08EjCRX8IS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3aa7a63a-e036-4705-9715-114fc320d596"
      },
      "source": [
        "len(review_lines)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "565082"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwFdNNJyYCZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gensim's word2vec API requires some parameters for initialization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goQvTzSPYMk5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "\n",
        "EMBEDDING_DIM=100\n",
        "\n",
        "# #train word2vec model\n",
        "model = gensim.models.Word2Vec(sentences=review_lines, size=EMBEDDING_DIM,window=5,workers=4,min_count=1)\n",
        "#vocab size\n",
        "words = list(model.wv.vocab)\n",
        "print('Vocabulary size %d' % len(words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hosUac1GZQeb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "dc365241-3532-4a33-a9d1-e674dce8e9a5"
      },
      "source": [
        "# The most similar words for word horrible are:\n",
        "model.wv.most_similar('horrible')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('terrible', 0.9341647028923035),\n",
              " ('awful', 0.9024513363838196),\n",
              " ('horrid', 0.8217014074325562),\n",
              " ('nasty', 0.801866888999939),\n",
              " ('disgusting', 0.7888876795768738),\n",
              " ('foul', 0.7702139019966125),\n",
              " ('horrendous', 0.7360975742340088),\n",
              " ('aweful', 0.7318627834320068),\n",
              " ('gross', 0.7207281589508057),\n",
              " ('repulsive', 0.7196914553642273)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L5mH55yZ5JG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The next step is to use the word embeddings directly in the embedding layer in our classification model. we can save the model to be used later.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i14ZLT1pZ5C-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "cb052e81-ae5d-4de2-861c-d0b065b7a026"
      },
      "source": [
        "# save model\n",
        "filename = 'Amazon_reviews_embedding_word2vec.txt'\n",
        "model.wv.save_word2vec_format(filename,binary=False)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA0m2BIwZ4-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use Pre-trained Embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbI3EEguZ45n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "607541d8-b747-4035-f420-e84f47f5427d"
      },
      "source": [
        "#The next step is to load the word embedding as a directory of words to vectors.\n",
        "\n",
        "import os\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join('','Amazon_reviews_embedding_word2vec.txt'), encoding = \"utf-8\")\n",
        "for line in f:\n",
        "  values = line.split()\n",
        "  word = values[0]\n",
        "  coefs = np.asarray(values[1:])\n",
        "  embeddings_index[word] = coefs\n",
        "f.close"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function TextIOWrapper.close>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ9EyUq-agJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The next step is to convert the word embedding into tokenized vector. Recall that the review documents are integer encoded prior to passing them to the Embedding layer. The integer maps to the index of a specific vector in the embedding layer. Therefore, it is important that we lay the vectors out in the Embedding layer such that the encoded words map to the correct vector."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAtagwVqeiE8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "528a0400-9d82-4b5c-d2e2-9b62921637cd"
      },
      "source": [
        "total_reviews = df['Text']\n",
        "total_reviews"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         bought several Vitality canned dog food produc...\n",
              "1         Product arrived labeled Jumbo Salted Peanuts t...\n",
              "2         confection been around few century light pillo...\n",
              "3         you are looking secret ingredient in Robitussi...\n",
              "4         Great taffy great price There wide assortment ...\n",
              "                                ...                        \n",
              "568449    Great sesame chicken this good not better than...\n",
              "568450    I m disappointed with flavor chocolate note ar...\n",
              "568451    These star are small you can give those in one...\n",
              "568452    These are BEST treat training and rewarding yo...\n",
              "568453    am very satisfied product advertised use cerea...\n",
              "Name: Text, Length: 565082, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PhXPoXieRkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_length = max([len(s.split()) for s in total_reviews])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJqAnEO3eaGB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97b1ae58-88fc-45b1-bfd1-e68ba5077d70"
      },
      "source": [
        "max_length"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2626"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoSQoVLzagF6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4ab9ec76-a91b-44c8-cc13-8c01383f5003"
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# vectorize the text samples into a 2D integer tensor\n",
        "tokenizer_obj = Tokenizer()\n",
        "tokenizer_obj.fit_on_texts(review_lines)\n",
        "sequences = tokenizer_obj.texts_to_sequences(review_lines)\n",
        "\n",
        "# pad sequences\n",
        "word_index = tokenizer_obj.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "\n",
        "\n",
        "review_pad = pad_sequences(sequences, maxlen=max_length)\n",
        "Score = df['Score'].values\n",
        "print('Shape of review tensor:', review_pad.shape)\n",
        "print('Shape of score tensor:', Score.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 120846 unique tokens.\n",
            "Shape of review tensor: (565082, 2626)\n",
            "Shape of score tensor: (565082,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BszrxJdagAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now we will map embeddings from the loaded word2vec model for each word to the tokenizer_obj.word_index vocabulary and create a matrix with of word vectors."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzLnB4Mjaf73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_words = len(word_index) + 1\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "\n",
        "for word,i in word_index.items():\n",
        "  if i > num_words:\n",
        "    continue\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    #words not found in embedding index will be all-zeros.\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXxEHeQWaf0R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "035f1ac8-1e05-4cd6-c3ca-1dc3a738dd8a"
      },
      "source": [
        "print(num_words)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "120847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKLe2qazf5T3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We are now ready with the trained embedding vector to be used directly in the embedding layer. In the below code, the only change from previous model is using the embedding_matrix as input to the Embedding layer and setting trainable = False, since the embedding is already learned."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ4kZ_ftgGlP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e3b70be-6f08-4a8d-8339-a2b9ce120b66"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, GRU\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.initializers import  Constant\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "embedding_layer = Embedding(num_words,\n",
        "                            EMBEDDING_DIM,\n",
        "                            embeddings_initializer=Constant(embedding_matrix),\n",
        "                            input_length=max_length,\n",
        "                            trainable=False)\n",
        "model.add(embedding_layer)\n",
        "model.add(GRU(units=32,dropout=0.2,recurrent_dropout=0.2))\n",
        "model.add(Dense(5,activation='softmax'))\n",
        "\n",
        "#\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1BdYcQZhyfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split data into a training set and a validation set\n",
        "VALIDATION_SPLIT = 0.2\n",
        "\n",
        "indices = np.arange(review_pad.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "review_pad = review_pad[indices]\n",
        "Score = Score[indices]\n",
        "num_validation_samples = int(VALIDATION_SPLIT * review_pad.shape[0])\n",
        "\n",
        "X_train_pad = review_pad[:-num_validation_samples]\n",
        "y_train = Score[:-num_validation_samples]\n",
        "X_test_pad = review_pad[-num_validation_samples:]\n",
        "y_test = Score[-num_validation_samples:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTJZ4g-ejQT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Shape of X_train_pad tensor:', X_train_pad.shape)\n",
        "print('Shape of y_train tensor':, y_train.shape)\n",
        "print('\\n')\n",
        "print('Shape of X_test_pad tensor', X_test_pad.shape)\n",
        "print('Shape of y_test tensor:', y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNcnLOsnj0yd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Print('Training....')\n",
        "\n",
        "model.fit(X_train_pad, y_train, batch_size=120, epochs=10, validation_data=(X_test_pad,y_test), verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQP12SDCj0uo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NghILWA5j0qj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-W9AC-Nj0mS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqMEWOWcj0hX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}